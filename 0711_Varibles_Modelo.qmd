# ¿Por qué las variables que se incluyen en el modelo no necesariamente son las más correlacionadas con la respuesta? {.unnumbered}

Es muy fácil de entender con un ejemplo. Suponga que tiene que presentarse al examen de una asignatura cuyo programa consta de 100 temas y resulta que usted no sabe ninguno. Pero no todo está perdido, las reglas de este examen dicen que usted puede llevar compañeros de clase como asesores y, además, puestos a suponer, supondremos que usted sabe qué temas conoce cada uno de sus compañeros.

Si pudiera llevar un solo asesor ¿a cuál elegiría? La respuesta es fácil: al que más temas sepa. Supongamos que ese es Pablo, que sabe 85 temas.

A la hora de elegir el segundo, una opción que parece razonable es elegir al segundo que más sabe, por ejemplo, Alberto, que sabe 75 temas. El problema de esta estrategia es que puede ocurrir que los 75 temas de Alberto ya estén incluidos entre los 85 que sabe Pablo y, por tanto, que Alberto no aporte nada cuando ya se cuenta con Pablo.

Una estrategia mejor para seleccionar al segundo es buscar el que más sabe pero no de todo el temario, sino de lo que le falta por saber al primero. Seguro que el lector estará de acuerdo con nosotros. Incluso puede ocurrir que en la mejor pareja de asesores no esté el que más sabe, ya que pueden haber dos que se complementen perfectamente, de modo que uno sepa 55 temas y el otro los 45 restantes, mientras que el que más sabe no se complemente bien con ningún otro.

El símil con la obtención del modelo de regresión está claro. La primera variable en ser elegida es la más correlacionada con la respuesta $Y$, es decir, la que mejor explica su comportamiento. Pero la segunda no necesariamente será la segunda más correlacionada con $Y$, ya que lo que explica esta quizá ya lo explicaba la primera. Una vez seleccionada una variable el criterio es: seleccionar la que mejor explica lo que falta por explicar.

También hará falta que cumpla con otros requisitos, como que una vez en el modelo su coeficiente supere un cierto nivel de significación. La selección y el descarte de variables siguiendo estos criterios lo resuelven muy bien los paquetes de software estadístico utilizando la estrategia de selección de modelos denominada “paso a paso” ("Stepwise").

Los paquestes de software estadístico también permiten identificar el modelo que interesa a base de fuerza bruta. Se trata de la estrategia que denominan "Best subsets". Simplemente se trata de calcular todos los modelos posibles junto a sus medidas de calidad del ajuste y presentar la lista de los mejores para que el usuario elija. El problema es que si entre las variables candidatas las hay que están muy correlacionadas entre ellas esta estrategia no funciona porque el algoritmo se atasca cuando quiere colocar a dos de esas en un modelo, mientras que el *Stepwise* esquiva bien esas situaciones. Otro problema para la fuerza bruta es tener muchas variables candidatas. Si $k$ es el número de esas variables, el número de modelos posibles es $2^k$ de forma que crece de forma exponencial con el número de variables consideradas. A partir de $k=30$ el tiempo de computación es muy alto y los programas que conocemos no dejan que se sobrepase ese valor.
