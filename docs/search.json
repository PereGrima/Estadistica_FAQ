[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística. Preguntas frecuentes",
    "section": "",
    "text": "PRESENTACIÓN\nRespondemos a preguntas que suelen surgir en un curso general de estadística. Se refieren tanto al contenido propio del curso como a cuestiones que aparecen habitualmente en discusiones sobre qué es la estadística, cuáles son sus dificultades y cuáles son sus aplicaciones.\nEste libro es el resultado de nuestra experiencia en este ámbito y esperamos que sea útil a estudiantes, a profesores que se inician en la docencia y a personas interesadas en la estadística en general. Cualquier comentario o sugerencia será bienvenido.\n\n\n\n\nVersión 4.0 (Marzo de 2026)\n\nAutores\n\nRoberto Behar, profesor en la Universidad del Valle, en Cali, Colombia.\nPere Grima, profesor en la Universitat Politècnica de Catalunya, en Barcelona, España\n\n\n\nLibro impreso\nSe puede comprar en Amazon.es o Amazon.com. Está impreso en color, encuadernado con tapa blanda e incluye prólogo, índices y referencias.\n\n\nLicencia\nSe publica bajo una licencia Creative Commons: CC BY-NC-ND 4.0.",
    "crumbs": [
      "PRESENTACIÓN"
    ]
  },
  {
    "objectID": "0213_Software.html",
    "href": "0213_Software.html",
    "title": "2.13 ¿Cuales son los mejores programas para analizar datos gráficamente?",
    "section": "",
    "text": "En Internet hay muchas páginas donde se explica cuáles son los mejores paquetes para la representación gráfica de datos. Sin tener un conocimiento exhaustivo de todo lo que existe –que además va cambiando–, creemos que vale la pena tener presentes las siguientes opciones:\n\nHojas de cálculo\nA menudo injustamente ignoradas en los ambientes universitarios más allá del ámbito de la gestión de empresas. Tienen muchas posibilidades y vale la pena dedicar tiempo a conocer sus posibilidades. Los recursos para el filtrado de datos y la realización de las llamadas “tablas dinámicas” permiten realizar análisis detallados con bastante facilidad.\n\n\nSoftware para la construcción de cuadros de control (dashboards)\nUno de los más conocidos es Power BI, que se relaciona muy bien con Excel y tiene muchas posibilidades para la creación de gráficos interactivos: se hace clic sobre una parte del gráfico y se abren otros gráficos que detallan esa parte. Existen otros programas de este tipo (como Tableau) pero son caros y solo están al alcance de las empresas. Power BI es gratuito si se instala localmente, es decir, solo analiza datos que están en el mismo ordenador donde se ha instalado. Esto es útil para aprender su funcionamiento y también para usarlo en el ámbito académico. Las empresas tienen sus datos en bases de datos centralizadas (o eso quisieran) y necesitan la versión de pago.\n\n\nLenguajes de programación para análisis estadísticos\nEl más usado en el ámbito universitario –y nunca defrauda– es R. Existen numerosas librerías que se pueden instalar fácilmente y que amplían las posibilidades del paquete base. Cabe destacar la librería Shiny que permite crear interfaces amigables e interactivas que se pueden distribuir como una página web. La ventaja de R es que es gratuito y que tiene muchas posibilidades pero hay que dedicar tiempo a dominarlo y, si no se usa, se olvida rápido. Una alternativa a R es el lenguaje Python, también con muchas librerías para realizar análisis estadísticos.\n\n\nPaquetes de software estadístico gratuitos\nUna buena opción son los paquetes de software que utilizan el lenguaje y los algoritmos de R añadiendo una presentación con menús, de forma que el proceso de aprendizaje es muy corto y toda la energía se puede dedicar al análisis de los datos. De este tipo tenemos, entre otros:\n\nBlueSky Statistics: Tiene muchas posibilidades de análisis gráfico e incluye también una gran variedad de técnicas estadísticas. Tiene un aspecto muy profesional, con una versión gratuita (más que suficiente para los objetivos de un curso introductorio) y también una versión de pago, con más servicios, para empresas.\nJamovi: Es el que más nos gusta para un curso introductorio. Limpio y claro, prácticamente no necesita explicación. Permite realizar las representaciones gráficas más habituales y aplicar las técnicas de análisis que se incluyen los primeros cursos. Presenta también la peculiaridad de que se pueden añadir “paquetes” desarrollados por otras personas –igual que con R– lo que puede darle mucho recorrido.\nJASP: Es intuitivo y fácil de usar. Vale la pena tenerlo en cuenta. Con muchas posibilidades de análisis –incluyendo estadística bayesiana– que van más allá de los contenidos de un curso introductorio.\nR Comander: Ha sido durante muchos años la interfaz utilizada para facilitar el uso de R en cursos introductorios. Se ha convertido en un estándar pero creemos que ahora existen mejores alternativas.",
    "crumbs": [
      "Estadística descriptiva",
      "2.13 ¿Cuales son los mejores programas para analizar datos gráficamente?"
    ]
  },
  {
    "objectID": "0101_Estadistica_Matematicas.html",
    "href": "0101_Estadistica_Matematicas.html",
    "title": "1.1 ¿La estadística es una parte de las matemáticas?",
    "section": "",
    "text": "La materia prima de los análisis estadísticos son los datos –en general numéricos– y como los números pertenecen al reino de las matemáticas, muchas veces se considera que la estadística es una parte de las matemáticas. Los métodos estadísticos, por supuesto, usan las matemáticas, pero la estadística tiene un enfoque, unos objetivos y una metodología que son diferentes.\nEl pensamiento matemático es deductivo. Se parte de unos axiomas y mediante la lógica se deducen teoremas que se cumplen siempre. Este proceso deductivo persigue la resolución de problemas que se sitúan en el ámbito de los modelos abstractos, de lo teórico, y exige prestar mucha atención a la notación que se usa y a la aplicación de las reglas, propiedades y otros teoremas demostrados previamente.\nEl pensamiento estadístico, en cambio, es inductivo. Se parte de unos datos y a partir de ellos se estiman características de la población de la que provienen. El cómo seleccionar y evaluar la calidad de esos datos forma también parte del problema. Mientras que las matemáticas buscan encontrar soluciones exactas en el mundo de lo simbólico, la estadística persigue soluciones aproximadas pero útiles en contextos reales. En matemáticas un solo caso que no se cumpla ya es suficiente para declarar que una proposición es falsa. En estadística sabemos que el hecho de que un fumador de cajetilla diaria llegue a los 90 años no invalida la teoría de que el tabaco perjudica la salud.\nLa estadística sirve para responder preguntas en el terreno de la investigación empírica, preguntas del tipo: ¿cuál de las resinas disponibles da mejores resultados en una depuradora de agua? ¿qué principio activo es más eficaz para curar una enfermedad? ¿qué porcentaje de ciudadanos está de acuerdo con la política del gobierno? Estas preguntas no se pueden responder desde las matemáticas. Hay que hacer un experimento o una encuesta y sabemos que las conclusiones que se extraigan no serán un teorema matemático. Si se repite el experimento/encuesta se obtendrán otros resultados, pero tenemos herramientas matemáticas que, bajo ciertos supuestos, nos permiten responder a las preguntas planteadas informando también sobre la confianza con la que damos nuestras respuestas.\nDesde luego, la estadística tiene en las matemáticas una de sus herramientas más útiles. La teoría de la probabilidad –uno de los pilares de la estadística– se desarrolla íntegramente con el proceso deductivo de la matemática. La teoría de la probabilidad sí es una parte de las matemáticas. Necesitamos la teoría de las distribuciones de probabilidad para calcular probabilidades en el terreno de lo práctico.\nPero el enfoque y las prioridades de la estadística no son los mismos que los de las matemáticas. No son lo mismo, ni la estadística es una parte de las matemáticas.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "1.1 ¿La estadística es una parte de las matemáticas?"
    ]
  },
  {
    "objectID": "0102_Probabilidad_Estadistica.html",
    "href": "0102_Probabilidad_Estadistica.html",
    "title": "1.2 ¿El cálculo de probabilidades es una parte de la estadística?",
    "section": "",
    "text": "La teoría de la probabilidad y el cálculo de probabilidades son una parte de las matemáticas. Una parte que puede resultar muy útil en el marco de un análisis estadístico, pero no creemos que deba considerarse parte de la estadística.\nEn los problemas de cálculo de probabilidades se suponen conocidas las características de la población (que en muchos casos es una población teórica) y nos preguntamos por las características de una muestra obtenida de esa población. Ejemplos típicos de problemas de cálculo de probabilidades son:\n\n¿Cuál es la probabilidad de que realizando una apuesta nos toque el primer premio de la Lotería Primitiva (una lotería de tipo 6/49)?\nSi una máquina fabrica un 3 % de piezas defectuosas ¿cuál es la probabilidad de que en un lote de 30 piezas haya alguna defectuosa?\n\nEn estadística nos ocupamos justo de lo contrario. Conocemos las características de una muestra que consideramos representativa de su población, y lo que interesa es estimar –“hacernos una idea de”– las características de esa población. Ni que decir tiene que la muestra no viene dada y hay que pensar en la mejor manera de elegirla con los recursos disponibles. Después habrá que analizar los valores obtenidos para realizar las estimaciones. Todo este proceso, desde plantear claramente las preguntas que se desea responder hasta explicar las conclusiones a las que se ha llegado, está lleno de dificultades que no tienen nada que ver con el cálculo de probabilidades. Problemas de estadística serían:\n\nCon base en los resultados de un sondeo electoral, estimar el número de escaños que obtendrá un partido en las próximas elecciones.\nA partir de los resultados de un estudio clínico, determinar si un nuevo medicamento es más eficaz que el usado habitualmente.\n\nClaro que nuestras estimaciones o nuestras conclusiones nunca son apuestas seguras, y ahí es donde aparece el lenguaje de la probabilidad: informamos sobre la probabilidad de que el número de escaños se encuentre entre determinados valores, o afirmamos que con una determinada probabilidad de error (que se fija de antemano y que se designa “nivel de significación”) puede decirse que el nuevo medicamento es eficaz. Pero, en general, el uso que hacemos de la probabilidad no requiere saber resolver problemas complicados de combinatoria o de cálculo de probabilidades. Basta con unas reglas bastante sencillas y al alcance de todos.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "1.2 ¿El cálculo de probabilidades es una parte de la estadística?"
    ]
  },
  {
    "objectID": "0103_Que_es_Estadistica.html",
    "href": "0103_Que_es_Estadistica.html",
    "title": "1.3 ¿Qué es la estadística?",
    "section": "",
    "text": "Existen muchas definiciones de lo que es la estadística. En el ámbito académico, una de las más cortas y acertadas nos la dio un estudiante cuando discutíamos este tema el primer día de clase: “La estadística es una asignatura”. Desde luego, tenía razón.\nSeguramente la estadística es la asignatura que aparece en los planes de estudios de más titulaciones, pero no podemos decir que sea la más apreciada. Muchos estudiantes la consideran una asignatura más bien antipática, en la que se realizan consideraciones ininteligibles que poco o nada tienen que ver con su vocación y sus intereses. Quizá por eso, una vez superada, se produce un cierto desapego y la estadística se queda en eso, en una asignatura.\nY, por si esto fuera poco, en las antípodas de la visión formal y académica, existe también una visión un tanto despectiva en la que la estadística se relaciona con porcentajes tendenciosos, con gráficos manipulados y con números que siempre hay manera de presentar de la forma que convenga y, claro, unas técnicas que sirven lo mismo para justificar que algo es blanco como que es negro, no son nada fiables para saber de que color son las cosas.\n\nUn poco de historia\nLa estadística como “cuentas del Estado” –de ahí su nombre– surgió cuando los gobernantes necesitaron conocer cuantas personas vivían en sus dominios, el volumen de las cosechas o los impuestos que cada familia debía pagar, y de eso hace ya miles de años. Esto significaba recoger datos y ordenarlos, tabularlos y quizá realizar algunos cálculos que estarían dentro de lo que hoy denominamos “estadística descriptiva”. Esto fue la estadística hasta los inicios del siglo XX, hace cuatro días.\nCon unas motivaciones totalmente distintas –en este caso relacionadas con la búsqueda de estrategias en los juegos de azar–, en el siglo XVII se empezó a estudiar seriamente (“matemáticamente”) el cálculo de probabilidades. Más tarde, la estadística clásica encontró en las probabilidades el lenguaje y las herramientas que le permitían hacer estimaciones sobre la población conociendo solo una parte e informando sobre el grado de incertidumbre de sus conclusiones. Esto aumentó enormemente sus posibilidades y su campo de actuación.\nLa estadística que se explica en los cursos introductorios se creó, fundamentalmente, en la primera mitad del siglo XX. Al inicio de esta nueva época los métodos estadísticos se desarrollaron en torno a aplicaciones concretas (seguros de vida, ciencias naturales, industria, agricultura…) pero el interés por crear nuevos métodos para el análisis de los datos (¡estaba todo por hacer!) se despegó de las aplicaciones prácticas, especialmente en el ámbito académico, y se empezaron a crear desarrollos matemáticos que poco o nada tenían que ver con el estudio de la realidad que nos rodea. Esta irrupción de las matemáticas en la estadística también ha tenido repercusiones en la docencia. Muchas veces los profesores de estadística son y actúan como profesores de matemáticas, lo cual seguramente tiene bastante que ver con las causas del desafecto por la asignatura en aquellos estudiantes para los cuales su vocación es otra.\n\n\nEstadística y adquisición de conocimiento\nMejoramos nuestro conocimiento a base de plantearnos preguntas e intentar responderlas. La estadística juega un papel protagonista cuando para responder a esas preguntas se necesitan datos. Ejemplos de preguntas podrían ser:\n\n\nBiología: ¿Cómo evoluciona el número de ejemplares de cierto tipo de ave en un territorio?\nMedicina: ¿Es eficaz una nueva vacuna?\nMedio ambiente: ¿Qué porcentaje de plástico se recicla?\nEconomía: ¿Cuánto están subiendo los precios?\nIngeniería: ¿Qué catalizador aumenta más el rendimiento de una reacción química?\nMarketing: ¿Qué tipo de envoltorio logra mayores ventas?\nPrevisiones: ¿Cuánta electricidad se consumirá mañana?\n\n\nLa estadística trata de cómo recoger y de cómo analizar los datos para responder a las preguntas planteadas. Raramente se consiguen todos los datos que nos gustaría tener, y menos todavía con las características deseadas, pero la estadística tiene herramientas para enfrentarse a estas situaciones y sacar el máximo provecho de los recursos disponibles, todo esto, como ya sabemos, con una medida conocida de la confianza con que podemos ofrecer nuestras conclusiones.\nLa estadística está muy relacionada con el método científico, que se basa en la observación, medición, experimentación, planteamiento y contraste de las hipótesis con datos experimentales… También cabe poner de manifiesto que el “elemento desencadenante”, lo que pone en marcha el proceso, es la pregunta que nos planteamos. No nos gusta analizar datos “para ver lo que sale”, siempre buscamos algo y saber lo que se busca –hacerse la pregunta adecuada– también es importante. Obtener los datos necesarios suele ser la parte más delicada y laboriosa. Una vez se tienen los datos, muchas veces las preguntas se pueden responder con análisis gráficos sencillos, aunque en otros casos hay que recurrir a técnicas más sofisticadas.\n\n\nNuestra definición\nLa estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos en el proceso de adquisición de nuevos conocimientos, en un contexto en el que casi siempre están presentes la variabilidad y la incertidumbre.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "1.3 ¿Qué es la estadística?"
    ]
  },
  {
    "objectID": "0104_DataScience.html",
    "href": "0104_DataScience.html",
    "title": "1.4 ¿Qué es la ciencia de datos (o Data Science)?",
    "section": "",
    "text": "El mantra que tanto hemos repetido en las clases de Estadística de que “los datos son siempre un recurso escaso” dejó de ser cierto en muchos casos, aunque en muchos otros –en los sondeos electorales, sin ir más lejos– sigue siendo tan válido como siempre.\nCada vez es más habitual capturar datos y enviarlos automáticamente a esa nube que parece no tener límites. Por ejemplo, las grandes instalaciones de aire acondicionado pueden colocar sensores que captan la presión del aire o las vibraciones en puntos clave de las máquinas y envían a la nube esos valores, que pueden ser recuperados y analizados desde cualquier lugar. Es también muy típico el ejemplo de los supermercados, que pueden almacenar la información de lo que ha comprado cada uno de sus clientes, pudiendo realizar también un seguimiento detallado de la evolución de las compras de los que tienen tarjeta de fidelidad.\nUna vez que somos capaces de almacenar tantos datos, lo siguiente es intentar sacar provecho de ellos. ¿Cuándo conviene cambiar los filtros o sustituir una pieza que está a punto de romperse? ¿Qué oferta conviene realizar a determinado tipo de clientes? En muchos casos basta con aplicar técnicas clásicas de análisis exploratorio de datos o con la construcción de modelos conceptualmente muy sencillos, pero en otros es necesario utilizar técnicas más sofisticadas y, en todos los casos, el manejo y la gestión de grandes volúmenes de datos entraña unas dificultades específicas.\nBásicamente, lo que se ha dado en llamar “Ciencia de Datos” es un conjunto de conocimientos relacionados con la captación, almacenamiento y análisis de datos para crear algoritmos que permitan identificar patrones, casi siempre con el objetivo de hacer previsiones. Algunos de estos algoritmos son capaces de reajustarse automáticamente aprendiendo de sus errores (machine learning). En terrenos como la identificación de imágenes (reconocimiento facial) o de sonidos (“Alexa, ¿qué hora es?”), estos métodos son excelentes. También en otros casos, como la previsión de valores que evolucionan en el tiempo, el uso de unos algoritmos llamados redes neuronales suele ofrecer mejores resultados que los métodos clásicos.\nTambién es verdad que no es oro todo lo que reluce. Seguramente algunas de sus posibilidades han sido sobrevaloradas por empresas consultoras que ven en estas técnicas con nombre sugerente (machine learning, deep learning…) la posibilidad de vender nuevos productos.\nUna peculiaridad de esos algoritmos es que actúan como ``cajas negras’’ en las que se tienen unas variables de entrada \\(X\\), y otras de salida \\(Y\\), y lo que se pretende es obtener buenas previsiones de los valores de \\(Y\\), dado un conjunto de valores de \\(X\\), pero sin llegar a entender cómo esos valores de \\(X\\) están afectando a los de \\(Y\\). El hecho de no conocer las relaciones causa-efecto limita sus posibilidades en la solución de problemas cuando es necesario conocer cuales son las causas que los provocan para poder plantear soluciones eficaces. Por otra parte, el esfuerzo que se realiza intentando obtener información de grandes volúmenes de datos de dudosa calidad (muchas veces misión imposible) sería mejor reorientarlo a plantearse qué datos se necesitan y planificar su recogida con el rigor y la estructura adecuadas para que de manera transparente y fiable se pueda obtener la información deseada así como un mejor conocimiento del proceso en estudio.\nEs un tema controvertido si la “Ciencia de Datos” debe ser considerada una parte de la estadística o si se trata de una nueva disciplina. Nuestra opinión es que depende de lo que entendamos por estadística. Si la estadística es la parte de las matemáticas que se dedica a crear métodos estadísticos, entonces realmente la ciencia de datos es una nueva disciplina, mucho más orientada a la resolución de problemas prácticos. Si, tal como nosotros pensamos, la estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos, no hay ninguna duda de que la ciencia de datos encaja perfectamente en esa definición.\nEn cualquier caso, entender el funcionamiento de esos algoritmos, ser capaces de programar y de interactuar con grandes volúmenes de datos, así como conocer las posibilidades de almacenamiento y computación en la nube son habilidades muy demandadas y con un gran futuro.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "1.4 ¿Qué es la ciencia de datos (o *Data Science*)?"
    ]
  },
  {
    "objectID": "0201_Mediana.html",
    "href": "0201_Mediana.html",
    "title": "2.1 ¿Para qué sirve la mediana si ya tenemos la media aritmética?",
    "section": "",
    "text": "La media aritmética es una excelente medida de tendencia central, muy utilizada y también muy apreciada, a veces demasiado, como cuando se pretende resumir en ella toda la información que contienen los datos. La mediana tiene propiedades de las que carece la media, por lo que es un buen complemento informativo e incluso puede resultar una medida más útil en algunos casos. Vamos a ver estas propiedades.\n\nEs más robusta que la media frente a la presencia de valores anómalos. Supongamos que nuestros datos son:\n\\[2;\\; 5;\\; 6;\\; 7\\; \\text{y}\\; 9\\]\nLa media es 5,6 y la mediana es 6. Si al introducir los datos en el ordenador cometemos un error y en último lugar en vez de 9 introducimos 99, la media pasa a ser 23,8 mientras que la mediana sigue siendo 6.\nPor su propia definición, la mediana deja un 50 % de las observaciones por debajo y otro 50% por encima y esto le da unas ventajas que la media no tiene. Si queremos saber si en nuestra empresa estamos entre los que cobran más o entre los que cobran menos, debemos comparar nuestro salario con la mediana, no con la media. Si solo hay 10 trabajadores y los salarios son (en las unidades que corresponda):\n\\[0.8;\\; 0.8;\\; 0.9;\\; 0.9;\\; 1.0;\\; 1.0;\\; 1.1;\\; 1.1;\\; 1.2\\; \\text{y}\\; 10\\]\ntodos menos uno (en este caso el 90 %) están por debajo de la media, que es 1,88. Esto no ocurre nunca con la mediana: si estamos por encima de la mediana, estamos con el 50% de los que más cobran. Otro ejemplo: si en un examen las notas van de 0 a 10 y se aprueba sacando una nota igual o superior a 5, si la nota media es 5 no sabemos cuántos han aprobado. Si se han examinado 50 estudiantes, puede ser que 41 hayan suspendido con un 4; 8 hayan sacado un 10 y uno haya obtenido un 6. Esto da media 5, aunque el 82 % ha suspendido. En cambio, si la mediana es 5, podemos asegurar que al menos la mitad han aprobado.\n\nSi la distribución de los datos es simétrica, la media y la mediana coinciden y entonces todo son ventajas. En una distribución Normal, la media y la mediana son iguales, por tanto, si los valores que tenemos provienen de una Normal, la media y la mediana no andarán muy lejos una de otra. En cualquier caso, siempre podemos calcular las dos y aprovechar lo mejor de cada una.",
    "crumbs": [
      "Estadística descriptiva",
      "2.1 ¿Para qué sirve la mediana si ya tenemos la media aritmética?"
    ]
  },
  {
    "objectID": "0202_Media_geometrica.html",
    "href": "0202_Media_geometrica.html",
    "title": "2.2 ¿Tiene alguna aplicación práctica la media geométrica?",
    "section": "",
    "text": "Sí la tiene, aunque muchas menos que la media aritmética. Un caso típico de uso de la media geométrica lo tenemos en el cálculo del valor medio de una tasa de crecimiento. Si una población tenía 10.000 habitantes en el año cero, creció el primer año a una tasa del 5 %, el segundo a una tasa del 20 % y el tercero al 50 % ¿A qué tasa promedio ha crecido durante estos tres años?\n\n\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacion\ninicial\nTasa de\ncrecimiento\nFactor de\nexpansión\nPoblación al\nfinal del año\n\n\n\n\n1\n10.000\n0,05\n1,05\n10.500\n\n\n2\n10.500\n0,20\n1,20\n12.600\n\n\n3\n12.600\n0,50\n1,50\n18.900\n\n\n\n\n\nSi calculamos la media aritmética de la tasa de crecimiento tenemos: \\((0,05 + 0,20 + 0,50)/3 = 0,25\\) y el factor medio de expansión sería \\(1,25\\). Sin embargo, si la población hubiera crecido los tres años de esta forma, no se llegaría al mismo resultado final:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacion\ninicial\nTasa de\ncrecimiento\nFactor de\nexpansión\nPoblación al\nfinal del año\n\n\n\n\n1\n10.000\n0,25\n1,25\n12.500\n\n\n2\n12.500\n0,25\n1,25\n15.625\n\n\n3\n15.625\n0,25\n1,25\n19.531\n\n\n\n\n\nPor tanto, la media aritmética no es un buen indicador de la tasa media de crecimiento.\nSi la población creciera a una tasa constante \\(i\\), para que al final del tercer año produjera el mismo efecto que las tasas del ejemplo, se debe verificar que:\n\\[ 10\\,000(1+i)(1+i)(1+i)=10\\,000(1+0,05)(1+0,20)(1+0,50) \\]\nDe donde:\n\\[(1+i)= \\sqrt[3]{1,05 \\cdot 1,20 \\cdot 1,50}=1,2364\\]\nSi se hubiera tenido este factor de expansión cada año (nótese que se trata de la media geométrica), se habría llegado exactamente a la misma población final.\nCuriosidades sobre la media geométrica son:\n\nA diferencia de la media aritmética, la media geométrica sólo se define para números positivos.\nLa media geométrica nunca es mayor que la media aritmética. La demostración para el caso de dos valores es fácil por reducción al absurdo. Supongamos que: \\(\\sqrt{ab} &gt; (a+b)/2\\), entonces \\(ab &gt; (a^2+2ab+b^2)/4\\), de donde se deduce: \\(0 &gt;a^2-2ab+b^2\\). Como \\(a^2-2ab+b^2=(a-b)^2\\) es imposible que este valor sea negativo, luego es imposible que \\(\\sqrt{ab}&gt;(a+b)/2\\).\n\nY ya puestos a hablar de otras medias, podemos hacer un comentario sobre la media armónica, mucho menos conocida pero también útil en algunos casos.\nSe define la media armónica de \\(x_1, x_2, \\ldots..., x_N\\) como:\n\\[Mh = \\frac{N}{\\large{\\frac{1}{x_1}+\\frac{1}{x_2}+...+\\frac{1}{x_N}}}\\]\nParece que esto sea un retorcimiento sin ningún interés, pero no. Si un coche recorre cierta distancia a una velocidad de 100 km/h y vuelve por el mismo camino a 120 km/h, la velocidad media del viaje es:\n\\[Mh = \\frac{2}{\\large{\\frac{1}{100}+\\frac{1}{120}}} = 109,1 \\text{ km/h}\\]\ny no 110 km/h como en principio se podría pensar.\nObserve que la velocidad es igual a la distancia recorrida dividida por el tiempo tardado en recorrerla,\nes decir \\(v=d/t\\) y por tanto \\(t=d/v\\). En nuestro caso, si la distancia a recorrer es \\(d\\), el tiempo tardado en la ida es \\(t_1 =d/100\\) y el tiempo tardado en el regreso es \\(t_2 =d/120\\). De esta manera el tiempo total invertido en todo el recorrido \\((2d)\\) será \\(t=t_1+t_2\\) y la velocidad media se calcula de la forma:\n\\[ \\text{Velocidad media} = \\frac{\\text{Distancia total recorrida}}{\\text{Tiempo total empleado}} = \\frac{2d}{\\large{\\frac{d}{100}+\\frac{d}{120}}} \\]\nOtro ejemplo: un avión recorre 3000 km. Los 1000 primeros a 700 km/h, los 1000 siguientes a 800 km/h, y los 1000 restantes a 900 km/h ¿Cuál ha sido su velocidad media? No ha sido 800 km/h sino 791,6 km/h.",
    "crumbs": [
      "Estadística descriptiva",
      "2.2 ¿Tiene alguna aplicación práctica la media geométrica?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html",
    "href": "0203_Variabilidad.html",
    "title": "2.3 ¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "Porque considerar la variabilidad es fundamental para describir la realidad, para entenderla y para tomar mejores decisiones.\nEs muy conocido el chiste que dice que si un señor se come un pollo y otro no come nada, la estadística lo explicará diciendo que, en promedio, se han comido medio pollo cada uno. Hace gracia por lo descabellado que es contar así las cosas, pero lo hacemos con más frecuencia de la que creemos. Por ejemplo, cuando se habla de la renta per cápita de un país se está hablando del “medio pollo” que se come cada uno, sin hacer ninguna referencia a si todos comen más o menos lo mismo o si unos comen mucho y otros prácticamente nada. En el terreno de la educación, cuando se dan los resultados de las pruebas PISA se dan unos valores por países y pocos se preguntan sobre las diferencias dentro de cada país, lo cual también es una información relevante.\nEn el ámbito de la gestión de empresas, supongamos que debe elegir entre dos proveedores que son iguales en todo (precio, calidad, etc.) excepto en el plazo de entrega: uno tarda un promedio de 4,25 días y el otro de 5,75. ¿Con cuál se quedaría? Seguramente habrá pensado que con el que sirve más rápido, pero 4,25 es el promedio de: \\[3,\\; 5,\\; 4,\\; 3,\\; 7,\\; 4,\\; 2\\;\\, \\text{y}\\;\\, 6\\] mientras que 5,75 lo es de: \\[6,\\; 5,\\; 6,\\; 6,\\; 6,\\; 5\\;\\,\\text{y}\\;\\, 6\\] Qué piensa ahora? El proveedor que tarda 5,75 días es más previsible y seguro que usted se podrá organizar mejor con este. Con el otro deberá hacer los pedidos un mínimo de 7 días antes, y alguna vez lo recibirá a los 2 días y no sabrá donde ponerlo.\nEn el mundo industrial ignorar la variabilidad también conduce a una visión equivocada del funcionamiento de las cosas. Veamos un ejemplo donde usaremos la ley de Ohm (Recuerde: I=V/R, si esto no le suena de nada puede saltarse este párrafo). Supongamos que le encargan fabricar un lote de circuitos muy sencillos que solo constan de una fuente de alimentación (V) y de una resistencia (R). Vamos a suponer que el voltaje de la fuente de alimentación siempre es igual a 100 V mientras que las resistencias presentan una cierta variabilidad y tienen un valor real que es igual al valor nominal ±5 \\(\\Omega\\). Se desea que en cada circuito la intensidad sea de 10 A y se considerará defectuoso si esa intensidad está fuera del intervalo 10±3 A. ¿Qué valor nominal debe pedir para las resistencias con el fin de minimizar la proporción de circuitos defectuosos? Quizá esté pensando que para tener I=10 A, si V=100 V debe pedir R=10 \\(\\Omega\\). Esto sería verdad si no hubiera variabilidad pero en nuestro caso habría que pedirlas de 11 \\(\\Omega\\)1.\nEn el ámbito de la medicina, para que una vacuna o un nuevo medicamento sean aprobados deben probarse en una amplia muestra de las personas a que va dirigido. Si todos fuéramos iguales -si no hubiera variabilidad- bastaría hacer la prueba en una sola persona, una cualquiera, y si en esa funciona funcionaría en todas.\nEn fin, si no existiera la variabilidad no habría estadística. Ni estadística, ni evolución de las especies ni muchas otras cosas. Tampoco estaríamos nosotros.",
    "crumbs": [
      "Estadística descriptiva",
      "2.3 ¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html#footnotes",
    "href": "0203_Variabilidad.html#footnotes",
    "title": "2.3 ¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "El circuito es defectuoso si su intensidad está por debajo de 7 A o por encima de 13 A, es decir, si la resistencia que se coloca está por encima de 14,3 \\(\\Omega\\) o por debajo de 7,7 \\(\\Omega\\). Para huir de esos valores lo mejor es pedir un valor nominal que esté en el centro, es decir: (7,7+14,3)/2 = 11 \\(\\Omega\\). &lt;&gt;↩︎",
    "crumbs": [
      "Estadística descriptiva",
      "2.3 ¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0204_Varianza_cuadrado.html",
    "href": "0204_Varianza_cuadrado.html",
    "title": "2.4 ¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?",
    "section": "",
    "text": "Cuando se calcula la varianza, las diferencias entre cada valor y la media se elevan al cuadrado para evitar que se compensen las positivas con las negativas. Esto provoca que sus unidades sean el cuadrado de las que tienen los datos, lo cual resulta poco intuitivo y difícil de interpretar (no parece natural medir la variabilidad de longitudes en unidades de superficie). Este problema se resuelve usando una nueva medida que es la raíz cuadrada de la varianza: la desviación típica. Todos hemos pensado alguna vez que se podría evitar tener esas dos medidas usando el valor absoluto de las diferencias en vez de su cuadrado. Así ya estaríamos midiendo la variabilidad en las mismas unidades que los datos.\nNo lo hacemos porque saldríamos perdiendo. La varianza tiene unas propiedades extraordinarias que ni de lejos presenta esa nueva medida usando el módulo. Vamos a desarrollar unas ideas que nos permitirán justificarlo.\nUtilizaremos los datos representados en la figura 2 en la cual también hemos representado un valor (a), en principio arbitrario, con el propósito de descubrir dónde conviene colocarlo para que sea un “buen representante” de este conjunto de datos.\n\n\n\n\n\n\nFigura 1: ¿Dónde colocar un “buen representante” de estos datos?\n\n\n\nEn principio \\(a\\) puede ser cualquier número real pero le vamos a exigir algunos requisitos asociados con nuestra idea de lo que significa “buen representante”, lo cual restringirá el conjunto de valores que puede asumir. Veamos dos criterios para seleccionar el valor de \\(a\\).\n\nCriterio 1\nEscoger el que minimiza la función \\(f(a)\\), definida de la forma:\n\\[f(a)=\\frac{ \\sum_{i=1}^{N} \\left| x_i-a\\right| } {N} \\]\ndonde \\(N\\) es el número de datos y los \\(x_i\\) son sus valores. Como la distancia promedio depende sólo de \\(a\\) le hemos llamado \\(f(a)\\). El valor que minimiza esta función y que por tanto es el mejor representante de los datos con el criterio aplicado no es la media sino la mediana.\nAl valor mínimo de \\(f(a)\\) le llamamos desviación media \\(DM\\) con respecto a la mediana, y su fórmula es: \\[DM=\\frac{ \\sum_{i=1}^{N} \\left| x_i-Me\\right| } {N} \\] En nuestro ejemplo, la mediana es 15,5. Esto significa que de todos los números reales, 15,5 es el que está más cerca de los datos de acuerdo con este criterio. Por tanto, la desviación media para nuestros datos es: \\[ DM = \\frac{\\left|10-15,5\\right|+\\left|12-15,5\\right|+...+\\left|20-15,5\\right|}{10}=2,3 \\]\n\n\nCriterio 2\nEscoger el que hace menor la media de los cuadrados de la distancia de los datos al valor \\(a\\). Es decir, el que minimiza la función:\n\\[g(a)=\\frac{ \\sum_{i=1}^{N} ( x_i-a)^2 } {N} \\]\nEn este caso el mejor valor de \\(a\\) puede deducirse derivando \\(g(a)\\) con respecto a \\(a\\), igualando a cero y despejando su valor. Veamos:\n\\[\\frac{\\text{d} g(a)}{\\text{d} a} = \\frac{-2}{N} \\sum_{i=1}^{N}(x_i-a) = 0\\] Por tanto \\(\\sum_{i=1}^{N}(x_i-a) = 0\\), de donde se deduce que \\(\\sum x_i =N \\cdot a\\) y despejando \\(a\\) tenemos: \\[ a = \\sum_{i=1}^{N} \\frac{x_i}{N} \\]\nObserve que en este caso el valor de \\(a\\) sí coincide con la media aritmética (le llamamos \\(\\mu\\)). Si hacemos la segunda derivada vemos que siempre es positiva, lo cual confirma que el punto crítico es \\(a=\\mu\\) y que el valor mínimo de \\(g(a)\\) es la varianza de \\(X\\) (le llamamos \\(\\sigma^2\\)). Con los datos de nuestro ejemplo \\(\\mu\\) = 15,1 y el valor mínimo que toma \\(g(a)\\) es \\(\\sigma^2\\)= 7,89. Sacando raíz cuadrada se obtiene la desviación típica \\(\\sigma\\) = 2,81.\n¿Por qué se prefiere usar la varianza, deducida a través del criterio 2, en lugar de la desviación media, deducida aplicando el criterio 1? Veamos algunas razones:\n\nLos desarrollos anteriores ponen de manifiesto que la media, medida descriptiva por excelencia, está asociada de forma más natural con la varianza que con la \\(DM\\).\nLa \\(DM\\) incluye en su expresión la función valor absoluto que se comporta mal desde un punto de vista matemático, mientras que la función cuadrática es muy fácilmente tratable. Observe, por ejemplo, que la demostración de que la media hace mínimo el promedio de los cuadrados se ha realizado de forma casi inmediata, mientras que probar que la mediana hace mínima la media de las distancias es bastante más complejo.\nLa desviación estándar \\(\\sigma\\) de la población es usada para definir la distribución más famosa y útil, como es la Normal. Esto posibilita la construcción de intervalos de confianza para estimar, por ejemplo, la media de la población, lo que sería mucho más complejo si se usara la \\(DM\\).\nLa varianza es una suma de cuadrados que se puede descomponer en diversos sumandos dando origen al llamado “Análisis de la Varianza”. El desarrollo de la teoría de los modelos lineales está basado en gran parte en el criterio de los mínimos cuadrados, que es el mismo en que está basada la varianza. Cuando la población origen de los datos es Normal, el cociente de varianzas muestrales sigue una distribución conocida, llamada \\(F\\) de Snedecor.\nLa varianza de una suma de variables aleatorias se calcula de una forma muy fácil, especialmente si las variables son independientes. Por ejemplo, en un proceso de envasado, si el peso del envase tiene una varianza \\(V(X)\\) y la varianza del contenido es \\(V(Y)\\), la varianza del conjunto es \\(V(X+Y) = V(X) + V(Y)\\).\n\nNada de esto podríamos hacer si intentamos usar la desviación media como medida de dispersión. En síntesis, la teoría estadística desarrollada en base a la varianza es muy rica, y no se conoce nada parecido para la desviación media.",
    "crumbs": [
      "Estadística descriptiva",
      "2.4 ¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?"
    ]
  },
  {
    "objectID": "0205_Dividir_n_1.html",
    "href": "0205_Dividir_n_1.html",
    "title": "2.5 ¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?",
    "section": "",
    "text": "Para facilitar la explicación trabajaremos con un ejemplo en el que suponemos que conocemos la población completa, un lujo que no tendremos en la práctica.. Los elementos que componen la población, junto con sus mediciones respectivas, son:\n\n\n\n\n\n(A)\n(B)\n(C)\n(D)\n(E)\n(F)\n\n\n2\n6\n8\n10\n10\n12\n\n\n\n\n\nEn primer lugar ilustraremos la propiedad de insesgamiento de un estimador en el caso de la media, con la cual estamos más familiarizados, y luego repetiremos el razonamiento para el caso que nos ocupa, el de la varianza.\nLa media poblacional \\(\\mu\\), correspondiente a los datos del ejemplo, es:\n\\[\\mu = \\frac{2+6+8+10+10+12}{6}=8\\]\nSupongamos que queremos estimar (“hacernos una idea”) el valor \\(\\mu\\), usando una muestra aleatoria de \\(n = 2\\) unidades. En este caso, como la población consta sólo de 6 unidades, podemos hacer un listado de todas las muestras que pueden resultar al escoger dos unidades al azar. Estas muestras aparecen enumeradas en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\nUnidades de la muestra\nA\nB\nA\nC\nA\nD\nA\nE\nA\nF\nB\nC\nB\nD\nB\nE\nB\nF\nC\nD\nC\nE\nC\nF\nD\nE\nD\nF\nE\nF\n\n\nValores en la muestra\n2\n6\n2\n8\n2\n10\n2\n10\n2\n12\n6\n8\n6\n10\n6\n10\n6\n12\n8\n10\n8\n10\n8\n12\n10\n10\n10\n12\n10\n12\n\n\nMedia muestral\n4\n5\n6\n6\n7\n7\n8\n8\n9\n9\n9\n10\n10\n11\n11\n\n\n\n\nCuando se seleccione al azar una muestra de dos unidades, el resultado será necesariamente alguna de estas 15 posibles combinaciones de 2 elementos, con su media \\(\\bar{x}\\) correspondiente.\nDecimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\) si el promedio de todas las posibles medias coincide exactamente con la media de la población. Para verificarlo, hagamos el promedio de nuestras 15 posibles medias: \\[ \\frac{4+5+6+6+7+7+8+8+9+9+9+10+10+11+11}{15}=8 \\]\nEl promedio coincide con \\(\\mu\\). Esto ocurre en todos los casos, independientemente del tipo de población o del tamaño de la muestra, por eso decimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\).\nVeamos ahora si el estadístico: \\[  S_{n}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n} \\]\ndonde \\(n\\) es el tamaño de las muestras, es un estimador insesgado para la varianza \\(\\sigma_{N}^{2}\\), calculada como: \\[  \\sigma_{N}^{2}= \\frac{ \\sum_{i=1}^{N}{(x_i-\\mu)^2} }{N} \\]\ndonde \\(N\\) es el tamaño de la población. Queremos saber si el promedio de los valores de \\(S_{n}^{2}\\), para cada una de las posibles muestras, coincide con el valor de \\(\\sigma_{N}^{2}\\) y para averiguarlo, en primer lugar vamos a calcular la varianza poblacional:\n\\[  \\sigma_{N}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6} = 10,67 \\]\nAhora calculamos la varianza para cada muestra de 2 unidades, con la fórmula: \\[  S_{n}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2} \\]\nobteniéndose los resultados que aparecen en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\nValores en la muestra\n2\n6\n2\n8\n2\n10\n2\n10\n2\n12\n6\n8\n6\n10\n6\n10\n6\n12\n8\n10\n8\n10\n8\n12\n10\n10\n10\n12\n10\n12\n\n\nVarianza muestral\n4\n9\n16\n16\n25\n1\n4\n4\n9\n1\n1\n4\n0\n1\n1\n\n\n\n\nVeamos si el promedio de las posibles varianzas muestrales, coincide con 10,67 que es el valor obtenido para \\(\\sigma_{N}^{2}\\).\n\\[ \\bar{S}^2 = \\frac{4+9+16+16+25+1+4+4+9+...+1}{15} = 6,4 \\]\nNo coincide y, por tanto, \\(S_{n}^{2}\\) no es un estimador insesgado de \\(\\sigma_{N}^{2}\\). Sin embargo \\(S_{n-1}^{2}\\), definido de la forma: \\[  S_{n-1}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n-1} \\]\naunque tampoco es un estimador insesgado para \\(\\sigma_{N}^{2}\\), sí lo es de \\(\\sigma_{N-1}^{2}\\) definido como: \\[  \\sigma_{N-1}^{2}= \\frac{ \\sum_{i=1}^{N-1}{(x_i-\\mu)^2} }{N-1} \\]\nEfectivamente, \\(\\sigma_{N-1}^2\\) tiene el valor: \\[  \\sigma_{N-1}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6-1} = 12,8 \\]\nY si calculamos \\(S_{n-1}^{2}\\) para cada una de nuestras muestras deberemos aplicar la fórmula:\n\\[  S_{n-1}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2-1} = \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{1}  \\]\nEs decir que todos los valores de la varianza que aparecen en la tabla anterior, quedan ahora multiplicados por 2 y por lo tanto la media de las varianzas queda también multiplicada por 2, es decir:\n\\[ \\bar{S}_{n-1}^{2}= 2\\cdot 6,4 = 12,8 \\]\nQuizá este resultado decepcione, y hasta sorprenda, porque seguramente lo esperado era que \\(S_{n-1}^{2}\\) fuera un estimador insesgado de \\(\\sigma_{N}^{2}\\) y no de \\(\\sigma_{N-1}^{2}\\), pero no hay que preocuparse demasiado. A efectos prácticos es casi lo mismo cuando la población es grande, y no vamos a estimar, a partir de muestras, las características de una población de 6 elementos (en nuestro ejemplo esta ha sido una población “de juguete” para entender el razonamiento).\nCuando estimemos la varianza de una población se tratará de una población grande, en la que \\(\\sigma_{N}^{2}\\) será prácticamente igual a \\(\\sigma_{N-1}^{2}\\). En realidad, el caso más frecuente es tener poblaciones teóricas (infinitas), en las que es exactamente lo mismo \\(\\sigma_{N}^{2}\\) que \\(\\sigma_{N-1}^{2}\\).",
    "crumbs": [
      "Estadística descriptiva",
      "2.5 ¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?"
    ]
  },
  {
    "objectID": "0206_Desviacion_tipica.html",
    "href": "0206_Desviacion_tipica.html",
    "title": "2.6 ¿Por qué la desviación típica es la medida típica de dispersión?",
    "section": "",
    "text": "Existen diversas razones por las que la desviación típica –o desviación estándar– es tan valorada y tan necesaria en el ámbito de la estadística. Una de esas razones es que, junto con la media, forman una “pareja perfecta” para describir el comportamiento de muchas variables aleatorias. Otra podría ser el formar parte del “ADN” de la distribución Normal. Veamos algunos de sus méritos.\n\nRelación con la media y con la distribución Normal}\nSi una variable aleatoria tiene distribución Normal, basta conocer su media y su desviación típica para calcular cualquier probabilidad relacionada con los valores que puede tomar. Si el peso de unos paquetes de azúcar sigue una distribución Normal con una media de 1000 g y una desviación típica de 15 g, podemos decir que aproximadamente el 95 % de los paquetes tendrán un peso comprendido entre 970 y 1030 g, y también podemos decir que el 68 % tendrá un peso comprendido entre 985 y 1015 g. Además, podríamos responder cualquier pregunta similar, por ejemplo qué porcentaje de paquetes tendrá un peso por debajo de 980 g (será el 9 %).\n\n\nImportancia en otras distribuciones\nSi la variable considerada no sigue una distribución Normal ¿sigue siendo útil la desviación típica? La respuesta es sorprendente. Si la variable sigue un modelo de probabilidad exponencial, o de Poisson, o una distribución Gamma, o una Beta, entre otras, también podemos usar la media y la desviación típica para responder preguntas de naturaleza similar a las planteadas antes.\n\n\nCuando no se conoce la distribución\n¿Sirve la desviación típica para hacer cálculos aproximados de probabilidades asociadas a una variable aleatoria si no tenemos ni idea de cuál es su distribución? Esta pregunta la respondió el matemático ruso Pafnuty Chebyshev (su apellido se puede ver escrito de distintas formas) en la conocida como desigualdad de Chebyshev. La idea es que para una amplia variedad de distribuciones, en el intervalo \\(\\mu \\pm k\\sigma\\) se tiene como mínimo una proporción de observaciones igual a \\(1-1/k^2\\). Es decir, si \\(k=\\sqrt{2}\\), el intervalo es \\(\\mu \\pm \\sqrt{2}\\sigma\\) y podemos afirmar que, con independencia del tipo de distribución, tendremos como mínimo el 50 % de las observaciones dentro de ese intervalo, y si \\(k=2\\) tendremos como mínimo el 75 %. Una curiosa propiedad en la que nuestra pareja media–desviación típica también es protagonista.\n\n\nSu papel en la estimación de la media poblacional\nEn muchas situaciones nuestro interés está en estimar la media poblacional \\(\\mu\\). Para ello tomamos una muestra y calculamos su media \\(\\bar{x}\\) para hacernos una idea del valor desconocido del parámetro \\(\\mu\\).\nCada vez que se tome una muestra, el valor de la media muestral \\(\\bar{x}\\) cambiará, pero sabemos que si tomamos muchas muestras de tamaño \\(n\\), sus medias estarán alrededor del verdadero valor de la media poblacional \\(\\mu\\). Pero decir que están alrededor de \\(\\mu\\) no significa que estén cerca de \\(\\mu\\). ¿Cómo podemos saber qué tan cerca están? En la respuesta a esta pregunta la desviación típica también tiene un papel protagonista. La desviación típica de esas medias muestrales se llama error típico y es igual a la desviación típica de la población dividida por \\(\\sqrt{n}\\). Esto es verdad para las distribuciones, no solo para la Normal.\n\n\nEstandarización de los datos\nSi le dicen que una vaca pesa 600 kg, a no ser que usted sea ganadero, probablemente ese valor no le dirá si la vaca está muy delgada o si tiene el peso correcto. Sin embargo, si le dicen que su peso está a 0,6 desviaciones típicas por encima de la media podrá deducir que el 73 % de las vacas de ese tipo tienen un peso por debajo y un 27 % por encima, luego la vaca no está delgada.\nUsando un ejemplo más académico, lo mismo ocurre con los residuos que se obtienen después de ajustar una ecuación de regresión. Que un residuo sea igual a 10 no nos dice si es grande o pequeño, es mucho más informativo que nos digan a cuantas desviaciones típicas está de la media, que en este caso siempre es cero. A ese valor se le llama residuo estandarizado.\nEn definitiva, la desviación típica aparece en muchos contextos y con mucha relevancia. El calificativo “típica” resulta en este caso apropiado y bien merecido.",
    "crumbs": [
      "Estadística descriptiva",
      "2.6 ¿Por qué la desviación típica es la medida típica de dispersión?"
    ]
  },
  {
    "objectID": "0207_Cuartiles_correcta.html",
    "href": "0207_Cuartiles_correcta.html",
    "title": "2.7 ¿Cuál es la forma correcta de calcular los cuartiles?",
    "section": "",
    "text": "Existen diferentes criterios para determinar los valores de los cuartiles y no todos dan el mismo resultado. Veamos algunos ejemplos.\nJohn Tukey, creador de los boxplots, identifica los cuartiles buscando las medianas de los valores que quedan por encima y por debajo de la mediana global. En la determinación de las medianas de cada mitad de datos incluye la mediana global si el número de datos es impar, pero no la incluye si es par. Por ejemplo, para los datos 2, 4, 6, 8 y 10 (número impar) tenemos:\n\n\n\n\n\n\n\nY si los datos son 2, 4, 6 y 8 (número par):\n\n\n\n\n\n\n\nDavid Moore y George McCabe en su libro “Introduction to the Practice of Statistics”, muy valorado por su carácter pedagógico e innovador, proponen un método similar al de Tukey, pero sin incluir la mediana global en la determinación de las medianas de cada una de las mitades. Cuando el número de datos es par el valor de los cuartiles coincide con el método de Tukey, pero en general no coincide cuando el número de datos es impar.\n\n\n\n\n\n\n\nEl paquete de software estadístico Minitab utiliza las expresiones \\(0.25(n+1)\\) y \\(0.75(n+1)\\) para determinar las posiciones de \\(Q_1\\) y \\(Q_3\\) respectivamente. Si la posición obtenida para \\(Q_1\\) es, por ejemplo, 1,25, su valor estará comprendido entre \\(x_1\\) y \\(x_2\\) interpolando de la forma: \\(Q_1 = x_1 + 0,25(x_2-x_1)\\). Utilizando los mismos datos que en los ejemplos anteriores resulta:\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8, 10  Posición de \\(Q_1\\): \\(\\;0.25 \\cdot 6 = 1.5\\); \\(\\;\\) Valor de \\(Q_1\\): \\(\\; 2  +0.5(4-2) = 3\\)  Posición de \\(Q_3\\): $;0.75 = 4.5); \\(\\;\\) Valor de \\(Q_3\\): \\(\\; 8 + 0.5(10-8) = 9\\)\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8  Posición \\(Q_1\\): \\(\\;0.25 \\cdot 5 = 1.25)\\); \\(\\;\\) Valor \\(Q_1\\): \\(\\; 2 + 0.25(4-2) = 2.5\\)  Posición \\(Q_3\\): \\(\\;0.75 \\cdot 5 = 3.75)\\); \\(\\;\\) Valor \\(Q_3\\): \\(\\; 6 + 0.75(8-6) = 7.5\\)\nExcel dispone de la función CUARTIL que identifica la posición de los cuartiles mediante las expresiones: \\(0.25(n-1)+1\\) y \\(0.75(n-1)+1\\) y los calcula interpolando igual que hace Minitab. Seguramente no satisfechos con su forma de identificar los cuartiles, en las últimas versiones se ha mantenido esa función (se indica que por compatibilidad con versiones anteriores) y se han añadido:\n\n\nCUARTIL.INC: Coincide con la función CUARTIL.\nCUARTIL.EXC: Identifica los cuartiles de la misma forma que Minitab.\n\n\nEn la figura 1 se muestran los cuartiles de nuestros datos con las funciones de Excel (versión 2019).\n\n\n\n\n\n\nFigura 1: Cálculo de los cuartiles con Excel\n\n\n\nEn resumen, los valores obtenidos con los métodos comentados han sido:\n\n\n\n\n\n\n\n\n\n\n\n\nMétodo\n  Datos: 2, 4, 6, 8\nDatos: 2, 4, 6, 8, 10\n\n\n    Q1\nQ3    \n    Q1\nQ3    \n\n\n\n\nTukey\nMoore y McCabe\nMinitab\nExcel, CUARTIL.INC\nExcel, CUARTIL.EXC\n    3\n    3\n    2.5\n    3.5\n    2.5\n7  \n7  \n7.5  \n6.5  \n7.5  \n    4\n    3\n    3\n    4\n    3\n8  \n9  \n9  \n8  \n9  \n\n\n\n\n\n\n¿Qué método es el correcto? ¿Cuál debemos utilizar? En la práctica no importa demasiado. Solo se está interesado en conocer los cuartiles cuando el conjunto de datos es grande (nunca si tenemos solo 4 o 5 datos) y en este caso las diferencias entre los distintos métodos no son relevantes. Por ejemplo, si tenemos 500 valores, la posición del primer cuartil con el método de Minitab es 125,25 y con la función CUARTIL.INC de Excel es 125,75. Como habrá poca diferencia entre los valores que ocupan las posiciones 125 y 126, la diferencia en el valor del cuartil no será relevante.",
    "crumbs": [
      "Estadística descriptiva",
      "2.7 ¿Cuál es la forma correcta de calcular los cuartiles?"
    ]
  },
  {
    "objectID": "0208_Anomalias_boxplot.html",
    "href": "0208_Anomalias_boxplot.html",
    "title": "2.8 ¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?",
    "section": "",
    "text": "A primera vista, ese 1,5 puede parecer un número caprichoso. También el 1 o el 2 podrían ser buenos candidatos con la ventaja de ser más sencillos, pero veamos qué ocurriría si fueran estos los elegidos.\nEn primer lugar debemos tener en cuenta que los valores que aparecen en la zona de anomalías de un boxplot tienen sentido como tales anomalías si la población de la que proceden es Normal. Consideremos por tanto una distribución Normal, y puestos a elegir una tomaremos \\(Z \\sim N(0;1)\\) ya que los cálculos serán más sencillos y no va a restringir nuestras conclusiones. Para determinar los cuartiles buscamos el valor de \\(z\\) que deja un área de cola de 0,25 y resulta ser: \\(Z_{0,25} = 0,674\\). Por tanto, el rango intercuartílico de una distribución \\(N(0;1)\\) es: \\(IQR = 0,674 - (-0,674) = 1,348\\).\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1 \\cdot IQR}\\)\nEn este caso, fijándonos en el lado derecho, la zona de anomalías empieza en \\(Q_3 + 1 \\cdot IQR = 0,674 + 1,348 = 2,022\\), y \\(P(Z&gt;2,022) = 0,02\\). Por tanto, la probabilidad total de que un valor extraído de la distribución considerada aparezca en la zona de anomalías es del 4 % (2 % por cada lado).\n\n\n\n\n\n\nFigura 1: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 2 \\cdot IQR}\\)\nSi en vez de 1 tomamos el valor 2 como multiplicador del rango intercuartílico, tendremos que: \\(Q_3 + 2 \\cdot IQR = 0,674 + 2 \\cdot 1,348 = 3,37\\) y \\(P(Z&gt;3,37) = 0,0004\\), por lo que la probabilidad de que un valor aparezca como anomalía en alguno de los dos extremos es 0,0008.\n\n\n\n\n\n\nFigura 2: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\nJohn Tukey, fue el primero en plantear el uso de los boxplots y ya contempló la posibilidad de usar los valores 1 o 2, pero consideró que 1 es demasiado pequeño ya que la zona de anomalías con este criterio incluye valores que no merecen ser considerados como tales, y el valor 2 resulta excesivamente grande ya que aleja demasiado esta zona y por tanto pueden pasar desapercibidos valores que deben ser considerados como anómalos.\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1,5 \\cdot IQR}\\)\nDescartados los valores 1 y 2, y dado que el multiplicador adecuado debe situarse entre ambos, aparece la opción del 1,5 como número más sencillo. Este valor define una zona de anomalías con probabilidades muy razonables (p = 0,007) así que este fue el valor que se propuso y así se ha quedado.",
    "crumbs": [
      "Estadística descriptiva",
      "2.8 ¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?"
    ]
  },
  {
    "objectID": "0209_Valores_atipicos.html",
    "href": "0209_Valores_atipicos.html",
    "title": "2.9 ¿Qué hay que hacer cuando nos encontramos con valores atípicos?",
    "section": "",
    "text": "Para empezar vamos a decir dos cosas que : 1) ignorarlos como si no existieran o 2) eliminarlos inmediatamente sin más consideraciones.\nSeguramente el error más frecuente es no preocuparse de su posible existencia y lanzarse directamente a realizar el test que corresponda. Actuando de esta forma se corre el riesgo de trabajar con algún dato erróneo, ya sea por problemas de formato, porque está en unidades que no corresponden, porque ha habido un error en la medida, o por otras razones. Realizar el test con datos erróneos puede conducir a unas conclusiones totalmente equivocadas.\nTambién puede darse el caso de que los valores sean correctos pero no convenga tomarlos en consideración. Supongamos que se desea analizar si un coche de policía aparcado en la orilla de la carretera recuerda a los conductores cuál es la velocidad máxima en ese tramo. Para ello, con un radar oculto, se mide la velocidad de los vehículos en una zona en la que la máxima permitida es de 60 km/h. Las velocidades obtenidas (también en km/h) son:\n\n\n\n\n\n65\n66\n80\n57\n57\n74\n55\n58\n65\n60\n77\n\n\n72\n63\n55\n74\n67\n63\n25\n57\n20\n68\n22\n\n\n61\n59\n77\n72\n23\n67\n58\n66\n71\n56\n63\n\n\n\n\n\nA continuación se hacen las mismas mediciones pero colocando un coche de la policía aparcado de forma visible al lado de la carretera. En este caso las velocidades son:\n\n\n\n\n\n55\n55\n63\n58\n62\n57\n59\n70\n22\n58\n56\n63\n\n\n55\n61\n58\n60\n24\n55\n75\n58\n61\n63\n20\n63\n\n\n62\n55\n25\n80\n61\n61\n60\n59\n73\n60\n50\n60\n\n\n\nSi realizamos el test de la \\(t\\) de Student para muestras independientes contrastando la hipótesis nula de que las velocidades medias son iguales frente a la alternativa de que con el coche de la policía son menores, se obtiene un p-valor de 0,167, por lo que a partir de estos datos no se podría deducir que el coche de policía tiene efecto disuasorio.\nSin embargo, realizando el análisis exploratorio de los datos, se obtiene el gráfico de la figura 1 en el que se observan unos valores atípicos, tanto con coche de la policía como sin él, que corresponden a vehículos que han pasado a unos 20-25 km/h. ¿Qué hay que hacer con estos valores? Lo primero es preguntarse a qué corresponden y cómo se han producido. En este caso se llega a la conclusión de que corresponden a vehículos de transporte agrícola que siempre van a esta velocidad, porque no pueden ir a más. Está claro que la posible influencia del método disuasorio no va con este tipo de vehículos y lo más razonable es excluirlos del estudio.\n\n\n\n\n\n\nFigura 1: Velocidades de paso (km/h) con valores atípicos (1)\n\n\n\nAl eliminar estos valores disminuye la variabilidad de las muestras y la diferencia de medias pasa a ser claramente significativa.\nPero tampoco hay que caer en la tentación de eliminar las anomalías automáticamente. Si los valores obtenidos hubieran sido los que se reflejan en la figura 2, que son iguales que los anteriores añadiendo 115, 118, 120 y 117 a la velocidad sin coche de policía, tendríamos que en este grupo hay dos conjuntos de valores atípicos, ambos aproximadamente a la misma distancia del centro de los datos, pero aunque hemos visto que era razonable quitar el conjunto de los valores bajos, no hay ninguna razón para quitar el de los altos, que corresponden a coches que circulan a una velocidad mucho mayor que la permitida.\n\n\n\n\n\n\nFigura 2: Velocidades de paso (km/h) con valores atípicos (2)\n\n\n\nOtro aspecto a tener en cuenta es que el análisis de las anomalías puede ser la parte más interesante del estudio. El gráfico de la figura 3 muestra la relación entre el rendimiento y la temperatura en una reacción química. Aparecen unos valores claramente anómalos, ¿qué hacer con estos valores? ¿eliminarlos y olvidarse de ellos?\n\n\n\n\n\n\nFigura 3: Rendimiento en función de la temperatura\n\n\n\nSi lo hiciéramos así nos perderíamos la oportunidad de incorporar información valiosa a nuestro conocimiento del proceso. Lo más adecuado sería preguntarnos: ¿Por qué se han dado estas situaciones?, ¿qué ha ocurrido a 185 grados para que se hayan producido unos rendimientos tan anormalmente altos?, ¿por qué a 205 grados y se obtuvo un rendimiento tan bajo? Es posible que la respuesta a estas preguntas aporte una información que puede ser muy útil para tener un mayor dominio del proceso.\nEn definitiva, ante un valor atípico lo que hay que hacer es intentar averiguar por qué se ha producido. Si está claro que la causa es un error se elimina y asunto resuelto. Si no es un error habrá que valorar la conveniencia de incluirlo en el estudio, según sea la razón por la cual se ha producido y la frecuencia con que se esperan valores similares.\nTambién es verdad que en algunos casos uno no sabe si mantener el valor atípico o quitarlo. Cuando se da esta situación una buena idea es realizar el análisis con y sin la presunta anomalía. Si se obtienen las mismas conclusiones la disyuntiva deja de tener importancia. En caso contrario el resultado va a ser dudoso hagamos lo que hagamos, a no ser que podamos recoger más datos.",
    "crumbs": [
      "Estadística descriptiva",
      "2.9 ¿Qué hay que hacer cuando nos encontramos con valores atípicos?"
    ]
  },
  {
    "objectID": "0210_Curtosis.html",
    "href": "0210_Curtosis.html",
    "title": "2.10 ¿Para qué sirve la curtosis?",
    "section": "",
    "text": "La curtosis es una medida de las llamadas “de forma” que cuantifica lo esbelta o aplanada que es una distribución de probabilidad (versión poblacional) o su equivalente cuando se refiere a un conjunto de datos (versión muestral). Se toma como referencia el valor que corresponde a la distribución Normal. Si una distribución tiene una curtosis mayor que la Normal hay que interpretarlo como que su parte central es más picuda (con más “apuntamiento”), y si el valor es menor será más plana, lo cual se traduce en que sus colas son más “pesadas”, es decir, que es más probable encontrar valores alejados de la media.\nSobre cuál es el valor de la curtosis para la distribución Normal existen dos criterios. Su fórmula definida de forma natural es: \\(E[(X-\\mu)^4]/\\sigma^4\\) y para la Normal, con independencia del valor de sus parámetros, da un valor igual a 3. Para tomar este valor como referencia, también se define como la expresión anterior menos 3, de forma que para la Normal es igual a cero. Cuando se dan valores de la curtosis, no siempre está claro cuál es el criterio con que se ha calculado. Algunos textos se refieren a la curtosis como el resultado de aplicar la expresión anterior y al como ese valor menos 3.\nA pesar de que la curtosis está relacionada con la forma de la distribución, no es una medida de variabilidad. Una distribución uniforme definida en el intervalo (\\(-\\sqrt{3};\\; \\sqrt{3}\\)) tiene \\(\\mu\\) = 0 y \\(\\sigma\\) = 1, al igual que una N(0; 1), pero la uniforme tiene una curtosis de 9/5, mientras que en la Normal es igual a 3.\nEn la mayoría de paquetes estadísticos cuando se piden las estadísticas descriptivas, además de las típicas medidas de tendencia central y de dispersión se obtiene la curtosis y su inseparable compañero, el coeficiente de asimetría (en inglés ), que seguramente son las medidas menos atendidas.\n¿Para qué sirven? Ambas son útiles para caracterizar las distribuciones de probabilidad a nivel teórico, especialmente en campos como los mercados financieros, o en hidrología, donde los valores extremos se dan con mayor probabilidad que en la distribución Normal y pueden tener consecuencias muy importantes. También juegan un papel destacado en algunas situaciones en las que para evaluar la robustez de un método o de un estimador, conviene probar con distribuciones de colas livianas y de colas pesadas, es decir, con distinta curtosis.\nSin embargo, tienen poco interés para describir la forma que presentan los valores de una muestra. Es mejor hacer un gráfico, como un diagrama de puntos o un histograma. El gráfico no puede ser sustituido por estas medidas, que tampoco aportan nada relevante cuando ya se tiene.\nAdemás, son malos estimadores de los valores correspondientes a la población. La figura 1 muestra los valores de la curtosis obtenidos por simulación de muestras de tamaño 10, 20, 50 y 100, de una población exponencial con \\(\\lambda\\)=1, a la que corresponde una curtosis igual a 9. Ya se ve que la estimación es sesgada, especialmente con muestras pequeñas, pero incluso con muestras tan grandes como n=100, un porcentaje muy alto de las estimaciones subestiman la curtosis verdadera. También se observa mucha variabilidad en los resultados, ya que los valores extremos afectan mucho al aparecer en la fórmula elevados a la cuarta potencia.\n\n\n\n\n\n\n\nFigura 1: Valores de la curtosis en muestras del tamaño n que se indica obtenidas de una distribución exponencial (curtosis = 9).\n\n\n\n\nSi lo que pretendemos es utilizar los valores de la curtosis y el coeficiente de asimetría para predecir el tipo de distribución de la que provienen los datos, también lo tenemos mal. La figura 2 muestra los valores de ambas medidas calculadas para 100 muestras de tamaño \\(n = 50\\) de la misma distribución exponencial que hemos usado antes. Los verdaderos valores de la distribución (Curtosis = 9; Asimetría = 2) están marcados con un cuadrado rojo. Ya se ve que los valores muestrales no permiten identificar este punto como aquel que representa los parámetros que se están estimando.\n\n\n\n\n\n\nFigura 2: Valores de la curtosis y del coeficiente de asimetría de 100 muestras de tamaño 50 de una distribución exponencial. Los valores de la población están marcados con un cuadrado rojo.\n\n\n\n\nEn resumen tanto la curtosis como el coeficiente de asimetría forman parte de las señas de identidad de una distribución de probabilidad y tienen interés en el marco de la caracterización de los modelos teóricos, pero como medidas descriptivas son muy poco fiables.",
    "crumbs": [
      "Estadística descriptiva",
      "2.10 ¿Para qué sirve la curtosis?"
    ]
  },
  {
    "objectID": "0211_Graficos_usar.html",
    "href": "0211_Graficos_usar.html",
    "title": "2.11 ¿Qué gráfico debo usar para representar mis datos?",
    "section": "",
    "text": "Naturalmente, depende del tipo de datos y de las características que queramos observar. Veamos algunas recomendaciones para las situaciones más habituales.\n\nVariabilidad\nEl histograma es una buena opción cuando el interés se centra en la variabilidad de los datos, la forma de su distribución, el valor en que están centrados y el rango en que se mueven. La figura 1 compara la producción de dos máquinas que elaboran un producto con un peso que debe estar en el intervalo 210 \\(\\pm\\) 10 g. Se han añadido unas líneas que muestran el valor objetivo y los límites de tolerancia. Se ve muy claro que se debería ajustar la máquina 1.\n\n\n\n\n\n\nFigura 1: Histogramas de los pesos producidos por dos máquinas\n\n\n\nSi se tienen pocos datos, un diagrama de puntos puede ser más adecuado. La figura 2 muestra que los valores del grupo A se sitúan en torno a 10 mientras que en el grupo B tienden a ser mayores.\n\n\n\n\n\n\nFigura 2: Diagramas de puntos para comparar dos conjutos de datos\n\n\n\n\n\nEvolución\nEl diagrama en serie de tiempo es el más adecuado cuando interesa observar la evolución de una variable. La figura 3 muestra los diámetros de 180 piezas consecutivas fabricadas por dos tornos. Se han añadido los límites de tolerancia y se aprecia claramente que los valores del torno B presentan una tendencia que conduce a la producción de piezas defectuosas.\n\n\n\n\n\n\nFigura 3: Evolución del diámetro de las piezas producidas\n\n\n\n\n\nRelación entre dos variables cuantitativas\nLa mejor forma de visualizar esta relación es a través de un gráfico de dispersión, como los de la figura 4, que ilustran la relación entre la velocidad máxima y la potencia de un conjunto de 30 coches.\n\n\n\n\n\n\nFigura 4: Diagramas de dispersión. Versión clásica e incluyendo también información sobre una tercera variable cuantitativa y otra cualitativa\n\n\n\nA la izquierda tenemos un diagrama clásico en el que todos los puntos son del mismo tamaño y color. En el de la derecha los puntos se han sustituido por círculos de área proporcional a una tercera variable cuantitativa, que en este caso son las emisiones de CO2. Además, cada círculo es de un color que depende de si el motor es de gasolina o diésel. Estos gráficos con círculos de diferente tamaño que incorporan una nueva variable a la representación, se suelen denominar diagramas de burbujas.\n\n\nRelación entre una variable cuantitativa y otra cualitativa\nSe pueden usar diagramas similares al de dispersión: para cada valor de la variable cualitativa -en el eje horizontal- se colocan los puntos que representan los valores de la variable cuantitativa (figura 5, izquierda). Para evitar que los puntos queden superpuestos y se pierda información sobre su cantidad, muchos programas incluyen la opción jitter que les da un cierto “temblor” sacrificando precisión en sus coordenadas pero ganando en visión de cantidad.\nUna alternativa, especialmente recomendable si se tienen muchos puntos, es representar boxplots como en la figura de la derecha.\n\n\n\n\n\n\nFigura 5: Variable cuantitativa en función de los de otra cualitativa\n\n\n\n\n\nFrecuencias para variables discretas o cualitativas\nEl uso de diagramas de barras suele ser la forma más clara de representar estos datos. Son similares al histograma pero las barras no se tocan, ya que no hay continuidad en la variable que representan. Los programas que realizan este tipo de gráficos también permiten estratificar las barras tal como se muestra en la figura 6 derecha.\n\n\n\n\n\n\nFigura 6: Volumen de ventas en distintas zonas del país. A la derecha, estratificado por tipo de producto.",
    "crumbs": [
      "Estadística descriptiva",
      "2.11 ¿Qué gráfico debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0212_Graficos_NO_usar.html",
    "href": "0212_Graficos_NO_usar.html",
    "title": "2.12 ¿Qué gráficos NO debo usar para representar mis datos?",
    "section": "",
    "text": "Los gráficos que no se deben usar pueden ser muchos. Aquí comentamos algunas tentaciones que conviene evitar, especialmente en contextos científicos y técnicos donde el objetivo es transmitir la información de la forma más clara y fidedigna posible.\n\nGráficos con tres dimensiones\nDeben evitarse porque la profundidad no aporta ninguna información y en cambio dificulta la interpretación de las escalas. Algunas veces se utilizan en contextos publicitarios en los que se prioriza el impacto visual.\n\n\n\n\n\n\n\n\n\n\n\nFigura 1: Gráficos con una tercera dimensión y sin ella. En estos últimos la información se percibe de forma más clara y directa.\n\n\n\n\n\nDiagramas de pastel, especialmente con tres dimensiones\nLos diagramas de pastel (circulares o de queso, o pizza, si lo prefiere) son representaciones muy utilizadas, aunque no tan apreciadas en contextos científico-técnicos, donde en general se prefieren los diagramas de barras. Si se representan en tres dimensiones y desgajando un sector que se quiere destacar ya entramos en el terreno de los gráficos tendenciosos. Una alternativa similar que transmite la información de forma más clara son los llamados gráficos de donut.\n\n\n\n\n\n\nFigura 2: En el gráfico de la izquierda parece que el mayor sector corresponde a la sanidad, cuando en realidad no es así.\n\n\n\n\n\nGráficos que ocupan mucho espacio y contienen poca información\nDedicar media página de un informe, o toda la pantalla de una presentación, a un gráfico de pastel que solo da un porcentaje (de la población con acceso a internet, por ejemplo) no parece una buena forma de aprovechar el papel o las pantallas de la presentación. Es más grave si se van presentando este tipo de gráficos de forma repetitiva (un diagrama para cada región, por ejemplo).\n\n\nGráficos con escalas tendenciosas\nAdaptar la escala del eje vertical según convenga es un conocido recurso para influir en la impresión que da el gráfico. La figura 3 podría representar las medidas de audiencia de cuatro cadenas de televisión. En el gráfico de la izquierda se observan unas diferencias muy claras y TV1 parece tener la mitad de la audiencia que TV4. Sin embargo, si la escala parte de cero, que es lo correcto cuando se realizan comparaciones, apenas se aprecian esas diferencias.\n\n\n\n\n\n\nFigura 3: En las comparaciones, lo correcto es partir de cero.\n\n\n\nEn los gráficos en serie temporal, si la escala vertical cubre todo el rango de variación de los datos, dará la impresión de que se ha producido un gran cambio, pero si se parte de cero, puede ocurrir que ese cambio -poco o mucho- apenas se note. En este caso, un buen criterio es que el rango de variación ocupe unos \\(2/3\\) de la amplitud de la escala.\n\n\n\n\n\n\nFigura 4: En los diagramas temporales se recomienda que el rango de variación de los datos ocupe 2/3 de la amplitud de la escala.\n\n\n\n\n\nComparar situaciones usando distintas escalas\nObserve los histogramas de la figura 5. Parece que la máquina 2 produce con más variabilidad que la 1 pero no es así. Los dos histogramas se han construido con los mismos datos. El problema está en que las escalas son distintas.\n\n\n\n\n\n\nFigura 5: No es lo que parece. Ojo con las escalas.\n\n\n\n\n\nRectas de tendencia\nNo deben añadirse líneas de tendencia cuando la mayoría de los puntos están amontonados en poco espacio. En la figura 6 hay 50 puntos en el intervalo 1 \\(\\leq\\) X \\(\\leq\\) 10 que no muestran ninguna relación entre X e Y (gráfico de la derecha). Solo 3 puntos apartados del resto, que seguramente son valores singulares o anómalos, no pueden marcar la tendencia de todo el conjunto de datos.\n\n\n\n\n\n\nFigura 6: La recta no representa la relación entre X e Y.",
    "crumbs": [
      "Estadística descriptiva",
      "2.12 ¿Qué gráficos NO debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0301_Frecuencia_densidad.html",
    "href": "0301_Frecuencia_densidad.html",
    "title": "3.1 ¿Cómo se pasa de la frecuencia a la densidad de probabilidad?",
    "section": "",
    "text": "Al construir un histograma lo habitual es colocar la frecuencia en el eje vertical, pero también se puede usar la densidad de frecuencia. Para cada intervalo \\(i\\), la densidad de frecuencia \\(f_i^*\\) es igual a su frecuencia relativa \\(f_i\\) dividida por su anchura \\(c_i\\). Es decir: \\(f_i^\\ast= f_i/c_i\\). De esta forma el área de cada barra \\((c_i\\cdot f_i/c_i)\\) es igual a la frecuencia relativa. Si todos los intervalos tienen la misma anchura usar la densidad de frecuencia es una complicación innecesaria ya que tanto la altura de las barras como su área son proporcionales a la frecuencia y es más directo fijarse en la altura. Sin embargo, si los intervalos tienen distinta anchura resulta más apropiado usar la densidad.\nVamos a suponer que una empresa toma una muestra de 500 empleados con el fin de analizar la antigüedad en su puesto de trabajo y que, por razones de índole administrativa, desea considerar los intervalos que se indican en la siguiente tabla (los años de antigüedad deben leerse como: de más de … hasta …).\n\n\n\n\n\n\n\n\n\n\n\n\n\nAños de\nantigüedad\nAnchura del\nintervalo ci\nFrecuencia\nabsoluta ni\nFrecuencia\nrelativa fi\nDensidad de\nfrecuencia fi/ci\n\n\n\n\n0 – 2\n2\n50\n0,10\n0,05\n\n\n2 – 3\n1\n25\n0,05\n0,05\n\n\n3 – 5\n2\n200\n0,40\n0,20\n\n\n5 – 10\n5\n200\n0,40\n0,08\n\n\n10 – 20\n10\n25\n0,05\n0,005\n\n\nTotal\n20\n500\n1\n\n\n\n\n\n\nRealizar el histograma con esos intervalos y las frecuencias absolutas (o relativas) no es una buena idea porque se tiende a comparar las frecuencias sin tener en cuenta la diferencia en la anchura de los intervalos. No es lo mismo tener 200 observaciones en un intervalo ancho (por ejemplo, de 5 a 10 años) que en otro más estrecho (de 3 a 5). Usar la densidad de frecuencia da una visión de los datos más acorde con la realidad.\nLa forma de calcular la densidad de frecuencia para cada intervalo es muy fácil. Para el primer intervalo tenemos \\(f_1^\\ast=f_1/c_1=0,10/2 = 0,05\\) y así la calculamos para todos. El área sobre el segundo intervalo deberá ser la mitad del área sobre el primero, porque tiene la mitad de observaciones, y el área sobre el tercero deberá ser cuatro veces el área sobre el primero.\n\n\n\n\n\n\nFigura 1: Histograma con intervalos desiguales\n\n\n\nEs intuitivamente claro que si el primer intervalo contiene el 10 % de los datos y estos están distribuidos en una anchura de 2 unidades, en promedio tenemos un 5 % en cada unidad. En el cuarto intervalo, por ejemplo, sus 5 años contienen el 40 % de los empleados, así que en promedio tenemos un 8 % de los empleados cada año, o lo que es lo mismo: \\(f_4^*=0,08/año\\). En las ordenadas tenemos la frecuencia relativa por unidad de intervalo, por eso se denomina densidad de frecuencia.\nDe esta forma, la estimación de un porcentaje relacionado con la antigüedad se convierte en el cálculo de un área. Así, por ejemplo, si se está interesado en estimar el porcentaje de empleados con una antigüedad menor o igual a 4 años, digamos \\(P(X \\le 4)\\), bastará con calcular el área del histograma comprendida entre 0 y 4 tal como muestra la figura 2 (izquierda).\nObserve que el área sombreada se calcula sumando por un lado las áreas de los primeros rectángulos (0,10 + 0,05) y por otro lado la parte del tercer rectángulo comprendida entre 3 y 4. Como en este tercer rectángulo se conoce su densidad, que es de 0,20, y se requiere un año, el porcentaje de empleados entre 3 y 4 años será 0,20·1 = 0,20. Finalmente, tenemos que la proporción de empleados con una antigüedad de 4 años o menos se estima en: \\(P(X\\le4)=0,10+0,05+0,20=0,35\\).\nAnálogamente, si se desea estimar la proporción con una antigüedad entre 4 y 7,5 años habrá que calcular el área entre dichos valores, tal como muestra la figura 2 (derecha). Haciendo el cálculo se obtiene: \\(P(4\\le X\\le7.5)=0,40\\).\n\n\n\n\n\n\nFigura 2: Cálculo de frecuencias a través de áreas\n\n\n\n\nDe la densidad de frecuencias a la función densidad de probabilidad\nSupongamos ahora que tenemos una muestra de 10.000 valores de una cierta variable \\(X\\). En el lado izquierdo de la figura 3 tenemos su histograma y en el derecho ese mismo histograma pero con la densidad de frecuencias en el eje de ordenadas y superponiendo dos líneas que es razonable considerar que representan a la población de la que provienen estos datos.\n\n\n\n\n\n\nFigura 3: Histograma con frecuencias absolutas (izquierda) y con densidad de frecuencia (derecha)\n\n\n\nLa función que describe esas líneas que hemos añadido es la función densidad de probabilidad. Respecto a las muestras hablamos de frecuencia, mientras que en el contexto de las poblaciones usamos el término probabilidad.\nEn este caso la función densidad de probabilidad \\(f(x)\\) es:\n\\[\\begin{equation*}\n\n   f(x) = \\left \\{\n\n   \\begin{aligned}\n\n       x\\;\\; & \\quad\\text{para}\\;\\; 0&lt;x \\leq 1 \\\\\n\n       2-x & \\quad\\text{para}\\;\\; 1&lt;x \\leq 2\n\n   \\end{aligned}\n\n   \\right.\n\n\\end{equation*}\\]\nEn la muestra, la frecuencia entre 0,5 y 1,5 será igual a la suma de las áreas de las barras que se encuentran en esos valores. Para la población, la probabilidad de que \\(x\\) se encuentre entre esos valores será igual al área que definen en el triángulo:\n\\[P(0,5 \\leq x \\leq 1,5) = \\int_{0,5}^1 x \\; dx + \\int_1^{1,5}(2-x) \\; dx =\\frac{3}{4}\\] \nSi en vez de una distribución triangular tenemos -por ejemplo- una distribución Normal, la expresión de \\(f(x)\\) es más complicada, pero el planteamiento es exactamente el mismo.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.1 ¿Cómo se pasa de la frecuencia a la densidad de probabilidad?"
    ]
  },
  {
    "objectID": "0302_Que_Distribucion.html",
    "href": "0302_Que_Distribucion.html",
    "title": "3.2 ¿Cómo se sabe qué distribución sigue una variable aleatoria?",
    "section": "",
    "text": "Preámbulo: ¿qué es una distribución de probabilidad?\nParece que si un valor depende del azar poco se puede hacer para describir su comportamiento: depende del azar y listo. Azar suena a impredecible, a lotería. En un juego de azar solo afecta la suerte y no hay manera de prever qué resultado saldrá.\nPero no es cierto que al decir que un valor depende del azar ya esté todo dicho. El azar se puede clasificar en familias y cada una tiene un patrón de comportamiento específico (aunque también en este caso las grandes familias están emparentadas entre ellas). Los que no entendemos de carpintería decimos que un mueble es de madera sin entrar en más consideraciones, pero el carpintero sabe que maderas hay de muchos tipos, caras y baratas, con unas propiedades u otras, y que no todas sirven para todo. Los que nos dedicamos a la estadística no hace falta que sepamos de maderas, pero sí debemos conocer las clases de azar y si la variable que nos ocupa pertenece a una de las familias conocidas podemos aplicar sus propiedades -sin tener que deducirlas- y todo se hace mucho más fácil. Claro que no hablamos de familias sino de distribuciones de probabilidad, o de distribuciones, sin más.\n\n\n¿Cómo seleccionar la distribución que mejor se adapta a nuestra variable?\nNo se trata de ir haciendo pruebas para ver cual encaja mejor en nuestros datos (si se tienen pocos encajarán casi todas) sino que hay que basarse en las características de esos datos y en la forma en que se han obtenido.\nSi la variable es continua (puede tomar cualquier valor dentro de un intervalo), presenta una distribución simétrica en torno a su valor central y a medida que nos alejamos de ese valor central -por encima y por debajo- disminuye el número de valores observados, como en el caso de las estaturas, seguramente su comportamiento se puede modelar a través de la distribución Normal. Si todos los valores son igualmente probables, entonces la distribución se llama uniforme. Este es el caso de los números aleatorios que genera Excel con la función =ALEATORIO(), que pertenecen a una distribución uniforme entre 0 y 1.\nOtras variables continuas tienen una distribución no simétrica. Esta circunstancia se da cuando los valores se alejan con más libertad hacia un lado que hacia el otro, en el que normalmente hay una frontera que impide el paso. Por ejemplo, la redondez de una pieza se mide como la diferencia entre sus diámetros máximo y mínimo. Si intentamos que las piezas sean perfectamente redondas estos valores se amontonarán contra el cero sin que haya límite para los valores grandes, con lo que se obtiene una distribución asimétrica. En alguna de estas situaciones el logaritmo de los datos sigue una distribución que puede considerarse Normal, por lo que esa distribución se llama lognormal.\nSi la variable es discreta (solo pueden tomar valores a saltos -en general números enteros-) el caso más sencillo es cuando todos los valores tienen la misma probabilidad de aparecer, como el resultado de lanzar un dado, en cuyo caso se llama uniforme discreta}. Otro caso muy típico es el número de “éxitos” al realizar \\(n\\) experimentos siendo \\(p\\) la probabilidad de éxito, como el número de piezas defectuosas en un lote de 100 unidades si la probabilidad de que una pieza sea defectuosa es 0,05. También tenemos una distribución para contar ocurrencias como el número de veces que se estropea un ascensor en un año o el número de visitas diarias a una página web. La primera distribución recibe el nombre de binomial y la segunda es la distribución de Poisson.\nAl principio puede costar distinguir cuándo una variable sigue una distribución binomial o de Poisson, pero es muy fácil fijándose en los detalles que se indican en la siguiente tabla.\n\n\n\n\n\n\n\n\n\n\n\nBinomial\nPoisson\n\n\nForma de contar\nSe pueden contar éxitos o fracasos, piezas correctas o\npiezas defectuosas\nSolo hay una forma de contar las ocurrencias. No se puede contar el número de veces que no se\nestropea un ascensor\n\n\nValor máximo\nExiste un máximo. En un lote\nde 100 piezas como máximo\nhay 100 defectuosas\nNo hay valor máximo (al menos en teoría). No hay máximo en el\nnúmero de veces que se puede\nestropear el ascensor\n\n\n\n\nTambién existen distribuciones teóricas que se utilizan como referencia en los contrastes de hipótesis. Las más conocidas son la t-Student, la Chi-cuadrado y la F de Snedecor. Según sea el test que se realiza, la distribución adecuada será una u otra. En los libros también aparecen distribuciones “para hacer ejercicios”, que solo son expresiones matemáticas en las que no se comenta cuál es el fenómeno a que se refieren ni cuál es el sentido físico de la variable en cuestión. Hay que entender estas distribuciones como instrumentos para practicar las propiedades de las distribuciones de probabilidad, aunque también es verdad que determinadas variables se pueden modelar con funciones específicas, “no catalogadas” como las que aparecen en ese tipo de ejercicios.\nEn cualquier caso, catalogado o no, no hay que confundir el modelo con la realidad. Uno de los ejemplos más socorridos es el de la estatura para ilustrar la distribución Normal, pero si tuviéramos las estaturas de los millones de habitantes adultos del planeta, podríamos comprobar que no se ajustan “exactamente” a la conocida campana de Gauss, y tampoco lo harían si estratificamos por sexo, raza, o lo que sea. Se trata, como en los otros casos, de un buen modelo que permite realizar estimaciones con suficiente precisión a efectos prácticos pero que no deja de ser un modelo teórico que no coincide exactamente con la realidad. Lo mismo ocurre con las otras distribuciones que, aun siendo modelos teóricos (lo de teórico para un modelo es un adjetivo innecesario) son muy útiles en la práctica.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.2 ¿Cómo se sabe qué distribución sigue una variable aleatoria?"
    ]
  },
  {
    "objectID": "0303_Media_var_aleatoria.html",
    "href": "0303_Media_var_aleatoria.html",
    "title": "3.3 ¿Por qué se dice que la media es una variable aleatoria?",
    "section": "",
    "text": "Antes de hablar de medias hablaremos de observaciones individuales y utilizaremos el ejemplo de la distribución de las estaturas.\nLa estatura de una persona concreta es un número. Por ejemplo, Juan mide 1,73 metros, Antonio 1,82 y María 1,76. Estos valores son números fijos y concretos, puesto que Juan, al igual que Antonio y María, siempre mide lo mismo.\nOtra cosa es si nos referimos a la altura de una persona genérica, la que en este momento puede estar pasando delante de la puerta de su casa. ¿Qué estatura tiene? No lo sabemos. La estatura de una persona, así, a nivel general, es una variable aleatoria, que podemos modelar bastante bien a través de una distribución Normal.\nAlgo análogo ocurre con las medias de las muestras. La media de una muestra formada por unos individuos concretos es también un número concreto. Si la muestra está formada por Juan, Antonio y María, su estatura media es 1,77 metros. Pero si hablamos de una muestra de tres individuos tomados al azar, la media de esa muestra es una variable aleatoria, ya que está formada por observaciones individuales que a su vez son también variables aleatorias.\nLo más interesante de este tema es que la media muestral se distribuye siempre con la misma media que las observaciones individuales y con una varianza que es la enésima parte (siendo \\(n\\) el tamaño de la muestra) de la que tienen esas observaciones. Además, si \\(n\\) no es muy pequeño, su distribución es muy próxima a la Normal con independencia de la distribución de la población.\nPensemos, por ejemplo, en la estatura de 20 personas, si representamos sus valores en un diagrama de puntos, podemos obtener un gráfico como el de la figura 1.\n\n\n\n\n\n\nFigura 1: Estaturas de 20 personas\n\n\n\n\nSin embargo, si pensamos en la altura media de grupos de 25 personas, ya no podemos dar valores tan extremos, puesto que aunque es perfectamente posible que una persona mida 1,85 metros, es prácticamente imposible que esta sea la altura media de un grupo de 25 personas tomadas al azar, ya que en este grupo cabe esperar que haya un número parecido de personas por encima y por debajo de la media general, de forma que los valores de sus alturas se compensarán dando un valor medio cercano a la media de la población. En la figura 2 se muestra el diagrama de puntos de unos valores que podrían corresponder a las alturas medias de 20 grupos con 25 individuos cada uno. Estos valores se han obtenido por simulación suponiendo que las alturas individuales siguen una N(1,70 m; 0,07 m). Obsérvese cómo su dispersión es menor que la de las alturas individuales.\n\n\n\n\n\n\nFigura 2: Estaturas medias de 20 grupos de 25 personas cada uno\n\n\n\n\nSi suponemos que la distribución de las estaturas sigue la distribución Normal que hemos comentado, podemos afirmar que las medias de muestras de \\(n\\) individuos seguirán también una distribución Normal, con la misma media que la población, \\(\\mu_{\\bar{x}}\\)=1,70, y una desviación típica que será: \\(\\sigma_{\\bar{x}}=\\sigma/\\sqrt{n}\\), en nuestro caso: \\(0,07/\\sqrt{25} = 0,014\\).\nEn definitiva, la media muestral, protagonista destacada en muchos estudios estadísticos, es una variable aleatoria nada misteriosa, con un comportamiento noble y fácil de prever.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.3 ¿Por qué se dice que la media es una variable aleatoria?"
    ]
  },
  {
    "objectID": "0304_formula_Normal.html",
    "href": "0304_formula_Normal.html",
    "title": "3.4 ¿De dónde sale la fórmula de la distribución Normal?",
    "section": "",
    "text": "En los libros de estadística es fácil encontrarse con la famosa –y también curiosa, ya que incluye los números \\(\\pi\\) y \\(e\\)– función densidad de probabilidad de la distribución Normal. Lo que no es tan fácil es encontrar una explicación de cómo se obtiene. Se puede llegar a ella de una manera formal por diferentes vías, pero ninguna es fácil y nosotros tampoco vamos a emprender ese camino1. Jugando con la ventaja de saber dónde queremos llegar, nos vamos a conformar con justificar que es muy razonable que esa función sea como es.\nPara ello hemos construido un histograma con 10.000 valores generados aleatoriamente de una distribución Normal con media \\(\\mu\\) =10 y desviación típica \\(\\sigma\\)=2 (estos valores son arbitrarios, podrían ser otros) y vamos a intentar llegar a la función que da el perfil suavizado de este histograma.\nLa primera observación que puede hacerse es que la forma de caída del histograma a ambos lados recuerda la función exponencial. La parte de la izquierda, en que la función es creciente, podría ser de la forma \\(f(x)=e^x\\) , pero para poder representar la parte derecha de forma simétrica, utilizaremos la función \\(f(x)=e^{x-10}\\) para la parte creciente de la izquierda y \\(f(x)=e^{10-x}\\) para la parte de la derecha.\nAhora debemos colocar en una sola función la parte creciente y la decreciente. Esto se consigue mediante la expresión \\(f(x)=e^{-\\vert x-10 \\vert}\\).\nYa tenemos una función que tiene una forma parecida a la Normal en las colas pero que presenta un pico en su máximo. Este pico, punto en que la función no tiene derivada, provoca el mal comportamiento característico de la función valor absoluto. Por tanto, si el problema está en la expresión \\(\\vert x-10 \\vert\\) es razonable pensar en sustituirla por el cuadrado de la diferencia: \\((x-10)^2\\).\nLa figura 4 muestra la función \\(f(x) = e^{-(x-10)^2}\\) superpuesta con el histograma de los datos. Vamos por buen camino, efectivamente el pico ha desaparecido y ya tenemos forma de campana, aunque ahora se trata de ensancharla.\nEnsanchar la campana significa aumentar el valor de las ordenadas para \\(x\\neq 10\\) manteniendo la forma de la función. Esto se consigue dividiendo el exponente por una constante que depende de la variabilidad de los datos y, por tanto, de \\(\\sigma\\). Se pueden hacer pruebas para deducir ese valor y resulta ser \\(2 \\sigma^{2}\\).\nEn la figura 5 tenemos la superposición de la función \\(f(x) = e^{- \\frac{(x - \\mu)^2}{2 \\sigma^2}}\\) (en la que \\(\\mu\\) = 10 y \\(\\sigma\\) = 2) con el histograma de los datos.\nEl ajuste es excelente, pero esta no es la función densidad de probabilidad de la distribución Normal. En realidad no es ni una función densidad de probabilidad. Para serlo es necesario que el área bajo la curva sea igual a 1 y en nuestra función esto no es así.\nSi el área es igual a \\(K\\) entonces \\(\\frac{1}{K}f(x)\\) mantendrá la misma forma y con las mismas proporciones, ya que solo cambia un factor de escala en el eje de ordenadas, y ahora el área sí será igual a 1.\nPara saber cuánto vale \\(K\\) solo hay que integrar nuestra función. Se puede hacer en una página web con calculadora de integrales (nosotros hemos usado calculadora-de-integrales.com) y se obtiene:\n\\[ \\int_{-\\infty}^{\\infty} e^{- \\frac{(x - \\mu)^2}{2 \\sigma^2}} = \\sigma \\sqrt{2 \\pi} \\]\nAhora sí hemos llegado a la fórmula que buscábamos:\n\\[ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}} \\]\nNo podemos acabar diciendo aquello de “como queríamos demostrar” pero esperamos que ahora esta expresión se vea más justificada.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.4 ¿De dónde sale la fórmula de la distribución Normal?"
    ]
  },
  {
    "objectID": "0305_Solo_N01.html",
    "href": "0305_Solo_N01.html",
    "title": "3.5 ¿Por qué para la distribución Normal solo se necesita la tabla de la N(0; 1)?",
    "section": "",
    "text": "Aunque las tablas estadísticas ya son algo del pasado, es interesante ver por qué habiendo infinitas distribuciones Normales (tantas como parejas \\(\\mu\\), \\(\\sigma\\)) basta la tabla de solo una para poder calcular probabilidades en todas ellas.\nLo veremos con razonamientos básicamente geométricos. Sea \\(X \\sim N(\\mu; \\sigma)\\) y deseamos calcular \\(P(X&gt;x)\\). Si definimos \\(Y = X - \\mu\\), está claro que \\(Y \\sim N(0; \\sigma)\\), y con ayuda de la figura 1 es fácil observar que \\(P(X&gt;x)=P(Y&gt;x-\\mu)\\) ya que la forma de las dos distribuciones es idéntica y al punto \\(x\\) en la distribución de \\(X\\) le corresponde \\(x-\\mu\\) en la de \\(Y\\).\n\n\n\n\n\n\nFigura 1: Transformación de \\(X \\sim N(\\mu; \\sigma)\\) en \\(Y \\sim N(0; \\sigma)\\)\n\n\n\nSi \\(Y \\sim N(0; \\sigma)\\) y \\(k\\) es una constante, entonces \\(kY \\sim N(0; k\\sigma)\\) ya que \\(E(kY) = kE(Y) = 0\\) y \\(V(kY) = k^2 \\sigma^2\\). Veamos ahora cómo representar la distribución de \\(kY\\).\nSi representamos \\(f(Y)\\) y \\(f(kY)\\) utilizando los mismos ejes, las formas de las distribuciones serán distintas, por tener distinto valor de \\(\\sigma\\). Pero también podemos representarlas usando la misma forma para la distribución (la misma campana) y cambiar las escalas de los ejes, tal como se indica en la figura 2.\nRecordando que la función densidad de probabilidad de \\(Y \\sim N(0; \\sigma)\\) es: \\(f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{- \\frac{y^2}{2\\sigma^2}}\\), se deduce que:\n\\[ f(ky) = \\frac{1}{k\\sigma \\sqrt{2 \\pi}}e^{- \\frac{k^2y^2}{2 k^2 \\sigma^2}} = \\frac{1}{k}f(y) \\]\n\n\n\n\n\n\nFigura 2: Distribución con \\(\\sigma\\) =1 o con \\(\\sigma = k\\) según la escala\n\n\n\nPor tanto, las campanas se pueden representar de forma idéntica multiplicando por \\(k\\) el eje de abscisas y dividiendo por el mismo valor el de ordenadas (que no hemos representado).\nSi hacemos \\(k= \\frac{1}{\\sigma}\\) tendremos \\(Z = \\frac{Y}{\\sigma}\\), o lo que es lo mismo: \\(Z = (X-\\mu)/ \\sigma\\). Por lo comentado anteriormente, la distribución de \\(Z\\) se puede representar con la misma campana que la utilizada para la distribución de \\(Y\\) (3).\n\n\n\n\n\n\nFigura 3: Transformación de \\(Y \\sim N(0; \\sigma)\\) en \\(Z \\sim N(0; 1)\\)}\n\n\n\nSi la forma de las campanas es la misma, y solo hemos sustituido el punto \\(x - \\mu\\) por el \\(\\frac{x - \\mu}{\\sigma}\\), resulta claro que \\(P \\left( Z &gt; \\frac{x -\\mu}{\\sigma} \\right) = P\\left( Y &gt; X - \\mu \\right)\\) y, por tanto, \\(P\\left( X&gt;x\\right) = P\\left(Z&gt; \\frac{x-\\mu}{\\sigma}\\right)\\).",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.5 ¿Por qué para la distribución Normal solo se necesita la tabla de la N(0; 1)?"
    ]
  },
  {
    "objectID": "0306_Estatura_cero.html",
    "href": "0306_Estatura_cero.html",
    "title": "3.6 ¿Por qué la probabilidad de tener mi estatura es igual a cero?",
    "section": "",
    "text": "Si usted mide 1,68 m y suponiendo que las estaturas siguen una distribución Normal calcula la probabilidad de que se dé ese valor, descubrirá que esa probabilidad es cero ¡pero usted existe! Esta paradoja, que se da -por supuesto- para todas las estaturas, se debe a que en la práctica tratamos como discretas a las variables que en realidad son continuas.\nCuando decimos que \\(X\\) sigue una distribución \\(N(\\mu; \\sigma)\\), estamos diciendo también que \\(X\\) es una variable continua que puede tomar infinitos valores. Sabemos que la probabilidad de que tome valores comprendidos entre \\(a\\) y \\(b\\) es igual al área definida por su función densidad de probabilidad entre estos valores, es decir: \\[ P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) dx \\] Por tanto: \\[ P(X=1,68) = P(1,68 \\leq X \\leq 1,68) = \\int_{1,68}^{1,68} f(x) dx = 0 \\] Pero cuando decimos que alguien mide 1,68 metros no queremos decir que mide exactamente 1,680000000… con infinitos ceros, sino que entendemos que el valor se ha redondeado y lo que queremos decir es que su altura está comprendida entre 1,675 y 1,685 (si fuera menor de 1,675 lo habríamos aproximado a 1,67 y si fuera mayor de 1,685 a 1,69)\nSuponiendo que las alturas se distribuyen según una Normal con media \\(\\mu\\)=1,70 m y desviación típica \\(\\sigma\\)=0,07 m, la probabilidad de que una persona mida 1,68 m (entendido como valor redondeado, que es como hablamos), es de 0,0547 (figura 1).\n\n\n\n\n\n\nFigura 1: Probabilidad de tener valores entre 1,675 y 1,685\n\n\n\nTodas las variables continuas se discretizan para tratar con ellas en la práctica. Casi siempre se redondea, como en el caso de la estatura, aunque en algunos casos se trunca, como hacemos con las edades. Si hoy es día de elecciones y usted cumple los 18 años mañana, hoy tiene 17+364/365 = 17,997 años, pero no le dejarán votar.\n\nObservación final\nUn argumento falaz, pero muchas veces convincente haciendo mención a aquello de los casos favorables partido por los casos posibles, es considerar que si la variable puede tomar infinitos valores, la probabilidad de que tome uno en concreto es cero. Esto es falso porque la regla de casos favorables partido por casos posibles solo vale cuando todos los sucesos tienen la misma probabilidad de ocurrir y este no es nuestro caso. Por otra parte, es perfectamente posible que una variable pueda tomar infinitos valores y que ninguno de ellos tenga probabilidad cero. Piense, por ejemplo, en la distribución de Poisson.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.6 ¿Por qué la probabilidad de tener mi estatura es igual a cero?"
    ]
  },
  {
    "objectID": "0307_Contrario_Normal.html",
    "href": "0307_Contrario_Normal.html",
    "title": "3.7 ¿Existen variables con comportamiento contrario a la distribución Normal?",
    "section": "",
    "text": "Entendemos por “contrario a la Normal” aquel comportamiento en el que la mayor frecuencia se concentra en los extremos del rango de valores, en lugar de hacerlo en torno al valor medio.\nUn ejemplo claro es la edad al morir, que presenta una distribución con picos en los extremos. Si siguiera una distribución Normal, la mayoría de personas moriría en torno a los 40 años, y sabemos que esto no es así. Actualmente la distribución de la edad al morir tiene forma de J, es decir, el pico alto se da en los valores más altos aunque también hay un pico pequeño (cada vez más pequeño) que tiene que ver con la mortalidad infantil. Algo parecido ocurre con la duración de los productos tecnológicos, donde también existe una cierta “mortalidad infantil”; precisamente para cubrir estos fallos tempranos está la garantía.\nOtro ejemplo que suele citarse es el de la distribución del porcentaje de cielo cubierto. Parece que, en general, es más frecuente que el cielo esté totalmente cubierto o totalmente despejado a que esté cubierto en torno al 50 %. La cobertura de las nubes se mide en octas (u octavas) pero no es fácil encontrar datos sobre esta variable. Las páginas web de estaciones meteorológicas que hemos consultado o bien no la registran, o no la publican.\nEn el ámbito de los modelos teóricos este fenómeno se da en la distribución del coeficiente de correlación entre variables independientes con muestras de tamaño \\(n=3\\). Si \\(n=1\\) solo se tiene un punto y no es posible calcular ninguna correlación. Si \\(n=2\\) solo puede tomar los valores 1 y -1, es decir, solo los valores extremos. Cuando \\(n=3\\) ya puede tomar cualquier valor entre -1 y 1 pero es más probable que tome valores cerca de los extremos. Si \\(n=4\\) todos los valores tienen la misma densidad de probabilidad (y como \\(r\\) está definido entre -1 y 1, seguro que será 0,5 para que el área sea 1). A medida que \\(n\\) aumenta va apareciendo la típica forma de campana.\nUtilizando la expresión de la función densidad de probabilidad de \\(r\\) (coeficiente de correlación muestral) cuando en la población es igual a cero (\\(\\rho\\) =0) hemos construido la figura 1 donde se puede observar la forma de la \\(f(r)\\) para diversos valores de \\(n\\). Para \\(n=30\\) se ha superpuesto una distribución Normal con la misma media y desviación típica. Puede observarse que para ese valor de \\(n\\) las dos distribuciones ya son casi idénticas, aunque \\(f(r)\\) no llega a ser Normal porque está definida en el intervalo \\((-1, 1)\\) mientras que en una Normal el rango de variación no está acotado.\n\n\n\n\n\n\nFigura 1: Función densidad de probabilidad del coeficiente de correlación para variables independientes según el tamaño de muestra",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.7 ¿Existen variables con comportamiento contrario a la distribución Normal?"
    ]
  },
  {
    "objectID": "0308_Formula_Poisson.html",
    "href": "0308_Formula_Poisson.html",
    "title": "3.7 ¿De dónde sale la fórmula de la distribución de Poisson?",
    "section": "",
    "text": "Vamos a partir de la distribución binomial cuando el número de pruebas \\(n\\) tiende a infinito y la probabilidad de éxito \\(p\\) tiende a cero, manteniéndose constante el valor \\(np\\) al que llamamos \\(\\lambda\\).\nSabemos que si \\(X\\) sigue una distribución binomial con parámetros \\(n\\), \\(p\\):\n\\[\\begin{equation*}\n    \\begin{split}\n    P(X=x) &=\\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x} \\\\\n        &= \\frac{n!}{x!(n-x)!} \\left(\\frac{\\lambda}{n} \\right )^{x} \\left(1-\\frac{\\lambda}{n} \\right )^{n-x}\\\\\n        &=\\frac{n(n-1) \\ldots (n-x+1)}{x!} \\cdot \\frac{\\lambda^{x}}{n^x} \\cdot \\left(1-\\frac{\\lambda}{n} \\right )^{n} \\left(1-\\frac{\\lambda}{n} \\right)^{-x}\\\\\n        &= \\underbrace{\\vphantom{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}} \\frac{n(n-1)\\ldots(n-x+1)}{n^x} }_1 \\cdot\n            \\underbrace{\\vphantom{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}} {\\frac{\\lambda^x}{x!}}}_2 \\cdot      \n        \\underbrace{\\left(1-\\frac{\\lambda}{n} \\right )^{n}}_3  \\underbrace{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}}_4\n\\end{split}\n\\end{equation*}\\]\nEn el primer paso simplemente se ha sustituido \\(p\\) por \\(\\lambda/n\\). A continuación se simplifica la expresión del número combinatorio y se realizan cambios evidentes. Finalmente se intercambian los valores de \\(n^x\\) y \\(x!\\) en los denominadores de los dos primeros términos y dividimos la expresión en cuatro partes que analizamos a continuación:\n\nParte 1:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\frac{n(n-1)\\ldots(n-x+1)}{n^x} &=\\frac{n}{n} \\cdot \\frac{n-1}{n} \\cdot \\frac{n-2}{n}\\ldots\\frac{n-x+1}{n}= \\\\\n        &=1 \\cdot\\left(1-\\frac{1}{n} \\right) \\left(1-\\frac{2}{n} \\right) \\ldots \\left(1-\\frac{x-1}{n} \\right)\n    \\end{split}\n\\end{equation*}\\]\nEstá claro que si \\(n \\to \\infty\\) manteniéndose \\(x\\) constante, cada uno de los términos tiende a 1 y, por tanto: \\[\\displaystyle\\lim_{n \\to \\infty} \\frac{n(n-1) \\ldots (n-x+1)}{n^x} =1 \\]\n\n\nParte 2:\nLa expresión \\(\\frac{\\lambda^x}{x!}\\) la dejamos tal como está.\n\n\nParte 3:\nEl análisis de esta tercera parte va a ser un poco más largo. Partiremos de la definición del número \\(e\\) como \\(\\displaystyle\\lim_{n \\to \\infty} \\left( 1+\\frac{1}{n} \\right)^n\\) e intentaremos poner nuestra expresión de una forma parecida a esta.\nPara empezar puede comprobarse que se verifica: \\[\\left( 1-\\frac{\\lambda}{n} \\right)^n =  \\left [\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} \\right ]^{-\\lambda}\\] Operando solo con la expresión del interior del corchete: \\[\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}}=\\left( \\frac{n/\\lambda}{n/\\lambda}-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} =  \\left( \\frac{n/\\lambda-1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} = \\left( \\frac{n/\\lambda}{n/\\lambda-1} \\right )^{\\frac{n}{\\lambda}}\\] y también podemos hacer:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\left(\\frac{n/\\lambda}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}}&=\\left(1+\\frac{1}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}} =\\\\\n        &= \\left(1+\\frac{1}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}-1} \\cdot \\left(1+\\frac{1}{n/\\lambda-1} \\right)\n    \\end{split}\n\\end{equation*}\\]\nObsérvese que siendo \\(\\lambda\\) una constante, cuando \\(n \\to\\infty\\) también \\((n/\\lambda-1) \\to\\infty\\). Por tanto el primer factor de la última expresión es igual a \\(e\\) cuando \\(n \\to\\infty\\). El segundo factor evidentemente es igual a 1 cuando \\(n \\to\\infty\\), por tanto:\n\\[ \\displaystyle\\lim_{n \\to \\infty} \\left( 1-\\frac{\\lambda}{n} \\right)^n  = \\displaystyle\\lim_{n \\to \\infty} \\left [\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} \\right ]^{-\\lambda} = e^{-\\lambda} \\]\n\n\nParte 4:\nEn esta última parte resulta claro que \\(\\displaystyle\\lim_{n \\to \\infty} \\left( 1-\\frac{\\lambda}{n} \\right)^{-x}  =1.\\)\nRecopilando resultados, se obtiene que, bajo las condiciones \\(n \\to\\infty\\), \\(p \\to 0\\) y \\(np = \\lambda\\) constante, se verifica que:\n\\[P(X=x)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\]",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.7 ¿De dónde sale la fórmula de la distribución de Poisson?"
    ]
  },
  {
    "objectID": "0309_Varianza_Chi_cuadrado.html",
    "href": "0309_Varianza_Chi_cuadrado.html",
    "title": "3.9 ¿Cómo se relaciona la varianza muestral con la distribución Chi-cuadrado?",
    "section": "",
    "text": "Utilizaremos la definición de \\(\\chi^2\\) con \\(\\nu\\) grados de libertad como \\(\\sum_{i=1}^{\\nu} z_{i}^2\\), siendo las \\(z_i\\) variables aleatorias independientes con distribución \\(N(0;1)\\). Respecto a la notación utilizada consideraremos que \\(X \\sim N(\\mu;\\sigma)\\) y que \\(\\bar{X}\\) y \\(S^2\\) son la media y la varianza de muestras aleatorias de tamaño \\(n\\). Tenemos:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\sum_{i=1}^n (X_i-\\mu)^2 &= \\sum_{i=1}^n \\left[ (X_i-\\bar{X})+(\\bar{X}-\\mu) \\right]^2\\\\\n        &= \\sum_{i=1}^n (X_i-\\bar{X})^2+2(\\bar{X}-\\mu) \\sum_{i=1}^n (X_i-\\bar{X})+ \\sum_{i=1}^n (\\bar{X}-\\mu)^2 \\\\\n    \\end{split}\n\\end{equation*}\\]\nY como \\(\\sum_{i=1}^n (X_i-\\bar{X})=0\\) y \\((\\bar{X}-\\mu)^2\\) es una constante, se obtiene que: \\[\\sum_{i=1}^n (X_i-\\mu)^2 = \\sum_{i=1}^n (X_i-\\bar{X})^2 + n(\\bar{X}-\\mu)^2\\]\nComo \\(S^2= \\frac{\\sum_{i=1}^n (X_i-\\bar{X})^2}{n-1}\\) podemos escribir:\n\\[\\sum_{i=1}^n (X_i-\\bar{X})^2 = S^2(n-1)\\]\nSustituyendo en la expresión anterior y dividiéndolo todo por \\(\\sigma^2\\):\n\\[\\frac{\\sum_{i=1}^n(X_i-\\mu)^2}{\\sigma^2} = \\frac{S^2(n-1)}{\\sigma^2}+ \\frac{(\\bar{X}-\\mu)^2}{\\sigma^2/n} \\]\nAceptando que los dos sumandos que aparecen a la derecha corresponden a variables aleatorias independientes, tenemos:\n\\[\\sum_{i=1}^{n} z_{i}^2 = \\frac{S^2(n-1)}{\\sigma^2}+z^2\\]\nY dado que la suma de variables aleatorias independientes distribuidas según \\(\\chi^2\\) sigue también esta misma distribución con un número de grados de libertad igual a la suma de los grados de libertad de las distribuciones sumadas, se espera que si por un lado \\(\\sum_{i=1}^{n} z_{i}^2 \\sim \\chi_{n}^2\\;\\) y por otro \\(z^2 \\sim \\chi_{1}^2\\), entonces:\n\\[\\frac{S^2(n-1)}{\\sigma^2} \\sim \\chi_{n-1}^2\\]",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.9 ¿Cómo se relaciona la varianza muestral con la distribución Chi-cuadrado?"
    ]
  },
  {
    "objectID": "0310_Sumark_Multiplicark.html",
    "href": "0310_Sumark_Multiplicark.html",
    "title": "3.10 ¿Por qué no es lo mismo sumar \\(k\\) veces una variable aleatoria que multiplicarla por \\(k\\)?",
    "section": "",
    "text": "El resultado es el mismo cuando las cantidades a las que nos referimos son magnitudes constantes. Para saber cuántos huevos hay en 8 docenas, como el número de huevos en una docena es una constante, podemos sumar 12 huevos 8 veces o multiplicar 12 por 8 (¡evidente!). Pero si lo que tenemos es una variable aleatoria, como el peso de un huevo, esto ya no es verdad.\nNo es lo mismo el peso de una docena de huevos que el peso de un huevo multiplicado por 12 porque aunque estas dos variables tienen el mismo valor medio no tienen la misma variabilidad y, por tanto, no podemos decir que son iguales.\nPara entender por qué esto es así, aclararemos en primer lugar el significado de la notación que vamos a utilizar. Llamaremos \\(X\\) a la variable aleatoria que consideramos (en nuestro ejemplo es el peso de un huevo), podríamos decir que \\(X\\) se distribuye según una Normal, pero no necesitamos hacer referencia a ninguna distribución en concreto, solo hay que tener claro que no es un valor fijo, sino una variable aleatoria. Si tomamos una docena, designaremos los pesos como \\(X_1, X_2, \\ldots, X_{12}\\). Cada una de las \\(X_i\\) es una variable aleatoria con la misma distribución que \\(X\\). En realidad son extracciones de la misma población, el subíndice solo indica el orden en que se extraen.\nEchando mano de las fórmulas correspondientes y suponiendo que los 12 pesos son independientes, tendremos que la esperanza matemática y la varianza del peso de una docena será:\n\\[E(X_1+X_2+\\ldots+X_{12})=E(X_1)+\\ldots+E(X_{12})=12 \\cdot E(X)\\] \\[V(X_1+X_2\\ldots+X_{12})=V(X_1)+ \\ldots+V(X_{12})=12 \\cdot V(X)\\]\nPensemos ahora en la variable “peso de un huevo multiplicado por 12”, es decir, la variable \\(12X\\). Ahora tendremos:\n\\[E(12X)=12 \\cdot E(X)\\]\n\\[V(12X)=12^2 \\cdot V(X)=144 \\cdot V(X)\\]\nVamos a ver que estas fórmulas reflejan lo que ocurre en la realidad a través de una mirada intuitiva al problema. Cuando formamos una docena de huevos, aunque tomemos uno singularmente pequeño no hay que temer que esta docena salga con un peso muy por debajo del valor medio, ya que seguramente también habrá otros con un peso por encima de lo normal de forma que los más grandes compensarán el peso de los más pequeños y viceversa.\n\n\n\n\n\n\nFigura 1: Una docena de huevos (exagerando las diferencias)\n\n\n\nSin embargo, en la variable “peso de un huevo multiplicado por 12”, si el huevo elegido resulta ser pequeño, es como tener una docena de huevos pequeños, y si es grande sería como una docena de huevos grandes, con lo que tendremos pesos totales con más dispersión que en el caso anterior (en este caso no se compensan los grandes con los pequeños).\n\n\n\n\n\n\nFigura 2: Un huevo multiplicado por 12. Si es pequeño es como tener una docena de huevos pequeños. Igual si es grande.\n\n\n\nPor tanto, tiene más dispersión la variable aleatoria “peso de un huevo multiplicado por 12” que la variable “peso de una docena”. Y si la variabilidad es distinta, evidentemente las variables son distintas.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.10 ¿Por qué no es lo mismo sumar $k$ veces una variable aleatoria que multiplicarla por $k$?"
    ]
  },
  {
    "objectID": "0304_formula_Normal.html#footnotes",
    "href": "0304_formula_Normal.html#footnotes",
    "title": "3.4 ¿De dónde sale la fórmula de la distribución Normal?",
    "section": "",
    "text": "Si está interesado en un enfoque más formal, aunque también en tono de divulgación, le gustará el artículo: “The Evolution of the Normal Distribution” de Sal Stahl, en Mathematics Magazine Vol. 79, núm. 2, abril de 2006.}.↩︎",
    "crumbs": [
      "Distribuciones de probabilidad",
      "3.4 ¿De dónde sale la fórmula de la distribución Normal?"
    ]
  },
  {
    "objectID": "0401_Creemos_muestra.html",
    "href": "0401_Creemos_muestra.html",
    "title": "4.1 ¿Por qué nos creemos los resultados de una muestra sabiendo que si tomáramos otra serían distintos?",
    "section": "",
    "text": "1) El valor medio de la media muestral coincide con la media de la población\nEn pocas palabras: porque serán distintos pero . Además, sabemos cómo se comportan nuestras estimaciones y usando las propiedades de las distribuciones de probabilidad –las que convengan en cada caso– podemos obtener los niveles de confianza y los márgenes de error deseados. Claro que hace falta que las muestras sean aleatorias y de tamaño suficiente.\nVamos a ver por qué esto es así centrándonos en la media. La clave está en que la media de la muestra, como estimador de la media de la población, tiene dos importantes propiedades:\nLa media varía de una muestra a otra, pero esa variabilidad se produce en torno al valor de la media poblacional. Es decir, si repetimos varias veces el proceso de muestreo, aunque los valores de las medias serán distintos, todos ellos se encontrarán agrupados –con mayor o menor dispersión– en torno a la media de la población. Cuando un estimador tiene esta propiedad se dice que es insesgado.\nTambién es cierto que al tomar una sola muestra conocemos un solo valor de la media muestral, y no tenemos manera de saber si se encuentra cerca o lejos de la media poblacional. Para tratar con este inconveniente utilizamos la siguiente propiedad.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.1 ¿Por qué nos creemos los resultados de una muestra sabiendo que si tomáramos otra serían distintos?"
    ]
  },
  {
    "objectID": "0402_Intervalo_confianza.html",
    "href": "0402_Intervalo_confianza.html",
    "title": "4.2 ¿De dónde sale la expresión del intervalo de confianza?",
    "section": "",
    "text": "Vamos a empezar con el intervalo de confianza para la media de una población Normal, con desviación típica conocida y calculado a partir de una sola observación.\nEn la figura 1 tenemos representada la distribución cuya media \\(\\mu\\) se desea estimar. Se han sombreado las colas de forma que la probabilidad de que una observación caiga en esa zona sea igual a \\(\\alpha\\) (\\(\\alpha\\)/2 en cada lado). Por tanto, la probabilidad de que caiga en la zona interior es \\(1-\\alpha\\).\n\n\n\n\n\n\nFigura 1: Intervalos construidos sumando y restando \\(z_{\\alpha/2}\\sigma\\) a un valor obtenido al azar\n\n\n\nVeamos ahora cuánto vale la distancia desde la media \\(\\mu\\) hasta el punto \\(x_{\\alpha/2}\\) en que empieza la zona sombreada. Como el valor de \\(\\alpha/2\\) es conocido (lo hemos elegido nosotros) podemos determinar el valor de \\(Z \\sim N(0; 1)\\) que deja esa área de cola.\nPor otra parte, sabemos que si \\(X \\sim N(\\mu; \\sigma)\\), entonces \\(Z = \\frac{X-\\mu}{\\sigma}\\) sigue una distribución \\(N(0; 1)\\), por tanto: \\[ z_{\\alpha/2} = \\frac{x_{\\alpha/2} - \\mu} {\\sigma} \\]\nDe aquí se deduce inmediatamente que la distancia entre \\(x_{\\alpha/2}\\) y \\(\\mu\\) es igual a \\(z_{\\alpha/2}\\sigma\\). Si ahora sumamos y restamos esa distancia a un valor (\\(x\\)) obtenido al azar, tenemos el intervalo: \\[x \\pm z_{\\alpha/2}\\sigma \\]\nObserve que si el valor de \\(x\\) está en la zona de probabilidad \\(1 - \\alpha\\), tal como ocurre con \\(x_1\\) y \\(x_2\\) en la figura 1, el intervalo obtenido incluye el valor de \\(\\mu\\). Sin embargo, si \\(x\\) cae en la zona de las colas, como ocurre con \\(x_3\\), el intervalo no llega a alcanzar el valor de \\(\\mu\\). Por tanto, los intervalos calculados con este procedimiento aciertan si el valor obtenido al azar cae en la zona \\(1- \\alpha\\) y esto ocurre una proporción de veces \\(1 - \\alpha\\). Por esta razón se denominan intervalos de confianza \\(1 - \\alpha\\). El valor \\(1 - \\alpha\\) se da normalmente en porcentaje y si \\(\\alpha = 0,05\\) hablaremos de intervalo de confianza del 95%.\n\n¿Y si lo que tenemos no es una única observación sino una muestra?\nConstruimos el intervalo en torno a la media de la muestra. La media muestral también sigue una distribución Normal con la misma media \\(\\mu\\) que la población pero ahora la desviación típica será \\(\\sigma /\\sqrt{n}\\). La media de nuestra muestra, \\(\\bar{x}\\), pertenecerá a la distribución de las medias, así que la expresión del intervalo de confianza ahora será: \\[ \\bar{x} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\]\n\n\n¿Y si la población no es Normal?\nSi la muestra no es muy pequeña, pongamos que tiene más de 10 observaciones, sabemos que la media también seguirá una distribución aproximadamente Normal. A efectos prácticos puede calcularse el intervalo como si la población fuera Normal.\n\n\n¿Y si no conocemos el valor de \\(\\sigma\\)?\nEn este caso hay que sustituir \\(\\sigma\\) por su estimador \\(s\\) pero este cambio tiene consecuencias porque la distribución de \\(\\frac{x- \\mu}{s}\\) ya no es una distribución \\(N(0;1)\\) sino una \\(t\\) de Student con los mismos grados de libertad, \\(\\nu\\), que tiene \\(s\\). Así pues, la expresión del intervalo de confianza queda: \\[ \\bar{x} \\pm t_{\\nu;\\alpha/2} \\frac{s}{\\sqrt{n}} \\]\nSiendo esta es la expresión de uso más habitual del intervalo de confianza para la media de la población.\n\n\n¿Y si lo que queremos estimar es una proporción?\nProporción y media son más similares de lo que parece. En realidad son lo mismo. Supongamos que hablamos de una proporción de piezas defectuosas, si tenemos 10 piezas y asignamos un 1 a las defectuosas y un 0 a las correctas, podemos tener algo así como: \\(0;\\;\\; 0;\\;\\; 1;\\;\\; 0;\\;\\; 1;\\;\\; 0;\\;\\; 0;\\;\\; 0;\\;\\; 1;\\;\\; 0\\)\nHay 3 defectos en 10 piezas, una proporción de 0,3, y esa proporción es precisamente la media de los 10 valores.\nCuando los elementos de una población se pueden clasificar en dos grupos: el grupo de interés, con una probabilidad de ocurrencia \\(p\\) y el resto con una probabilidad \\(1-p\\), en una muestra de tamaño \\(n\\) la proporción de elementos que pertenecen al grupo de interés es una variable aleatoria \\(\\hat{p}\\) con media \\(p\\) y varianza \\(p(1-p)/n\\).\nSi \\(n\\) no es muy pequeña ni \\(p\\) muy cercana a 0 o a 1, la variable \\(\\hat{p}\\) se puede aproximar a la distribución Normal. \\[ \\hat{p} \\sim N \\left( p; \\sqrt{\\frac{p(1-p)}{n}} \\right)\\]\nSiguiendo el mismo razonamiento que conduce a la expresión del intervalo de confianza para \\(\\mu\\), usando el valor de \\(\\hat{p}\\) (el de \\(p\\) no lo conocemos) llegamos a la siguiente expresión para el intervalo de confianza \\(1-\\alpha\\) para \\(p\\): \\[ \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\]\nEn todos los casos hemos supuesto que la población es infinita. Esto es lo habitual, ya que la población es un modelo teórico o es tan grande que a efectos prácticos puede considerarse infinita. Si la población es finita las fórmulas cambian un poco, pero eso lo comentamos en la siguiente pregunta.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.2 ¿De dónde sale la expresión del intervalo de confianza?"
    ]
  },
  {
    "objectID": "0403_Factor_correccion.html",
    "href": "0403_Factor_correccion.html",
    "title": "4.3 ¿Qué es el factor de corrección por población finita?",
    "section": "",
    "text": "Aunque sobre esto no se habla mucho, la fórmula de la varianza muestral $_{{x}}^2 =^2/n $ donde \\(\\sigma^2\\) es la varianza poblacional y \\(n\\) el tamaño de muestra, solo es válida si la población es infinita.\nPodemos verlo a través de un caso muy sencillo en que la población solo tiene $ N=3 $ elementos con valores: 7, 8 y 9. Su varianza es \\(\\sigma^2 = 2/3\\) y si consideramos las muestras de tamaño \\(n=2\\), solo hay 3 medias muestrales, las correspondientes a las únicas 3 muestras que se pueden obtener:\nSe comprueba fácilmente que la varianza de las medias muestrales es: \\(\\sigma_{\\bar{x}}^2 = 1/6\\), que es distinta de \\(\\sigma^2 /n = 1/3\\)\nLas peculiaridades de las poblaciones finitas tienen que ver con que el muestreo se realiza sin reposición. Una vez elegido un elemento ese ya no forma parte de los elegibles y, en consecuencia, la probabilidad de incorporar a la muestra elementos de un cierto tipo depende de cuantos han salido ya de ese tipo. Esto complica los cálculos, pero solo cuando la población es finita. Con el supuesto de población infinita no importa si el muestreo es con o sin reposición: En una baraja infinita, si la probabilidad de sacar una carta de espadas es ¼, esa probabilidad se mantiene constante con independencia del palo a que pertenezcan las cartas que van saliendo. Sin embargo, en una baraja normal de 48 cartas, si la primera es de espadas, la segunda tiene una probabilidad menor de ser de espadas porque del resto de palos quedan 12 y de espadas solo 11.\nCuando la población es finita la varianza de la media muestral se obtiene aplicando la fórmula general (\\(\\sigma^2/n\\)) con un factor \\(f\\) que llamamos “factor de corrección por población finita”. \\[f=\\frac{N-n}{N-1}\\]\nEn nuestro caso, en que \\(N=3\\) y \\(n=2\\) tenemos: \\[\\sigma_{\\bar{x}}^2 = \\frac{\\sigma^2}{n} \\cdot \\frac{N-n}{N-1} = \\frac{\\frac{2}{3}}{2} \\cdot \\frac{3-2}{3-1} = \\frac{1}{6} \\]\nQue sí coincide con el valor correcto. Seguramente la pregunta que ahora surge es: ¿de dónde sale esta expresión? pero no vamos a entrar en este tema porque a pesar de su apariencia inocente, la deducción del factor de corrección no es trivial1\nPara deducir la expresión que aparece en los intervalos de confianza hay que tener en cuenta otra peculiaridad que se da en las poblaciones finitas, la varianza muestral calculada de la forma habitual: \\[ s^2 = \\frac{\\sum_{i=1}^n \\left( x_i - \\bar{x} \\right)^2}{n-1} \\]\nno es un estimador insesgado de \\(\\sigma^2\\) sino de:\n\\[ \\sigma_{N-1}^2 = \\frac{\\sum_{i=1}^N \\left( x_i - \\mu \\right)^2}{N-1} \\]\nPor tanto, el estimador insesgado de la varianza de \\(\\bar{x}\\) con el factor de corrección por población finita es:\n\\[ s_{\\bar{x}}^2 = \\frac{s^2}{n} \\cdot \\frac{N-1}{N} \\cdot \\frac{N-n}{N-1} = \\frac{s^2}{n} \\cdot \\frac{N-n}{N}  \\]\nEs interesante observar que casi siempre nos referimos a poblaciones infinitas y que estas no son en realidad “poblaciones” en el sentido de “conjunto de elementos o individuos objeto de estudio” sino modelos teóricos, hipótesis sobre el comportamiento de los datos. Son poblaciones de resultados, o de mediciones, nunca de individuos. Evidentemente, no existen conjuntos infinitos de objetos reales.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.3 ¿Qué es el factor de corrección por población finita?"
    ]
  },
  {
    "objectID": "0404_Elementos_muestra.html",
    "href": "0404_Elementos_muestra.html",
    "title": "4.4 ¿Cuántos elementos debe tener una muestra para que las conclusiones sean fiables?",
    "section": "",
    "text": "En el ámbito del muestreo probabilístico, el tamaño de la muestra se calcula aplicando una fórmula que puede ser más o menos complicada, dependiendo del tipo de muestreo. En el caso del muestreo aleatorio simple y para la estimación de una proporción, \\(p\\), tenemos: \\[ n = \\frac{Np(1-p)}{(N-1)(E^2/z^2)+p(1-p)} \\]\nEsta fórmula se deduce a partir de la expresión del intervalo de confianza para \\(p\\) con la corrección para población finita. Para obtener el valor de \\(n\\) basta con asignar valores a las variables que intervienen. Estas variables son:\n\nE: Margen de error\nSi le piden que a través de una muestra estime la proporción de jóvenes de su ciudad que son usuarios habituales de una red social, nadie le va a exigir que dé el valor exacto, por ejemplo el 23,7 %. En su informe usted hará constar que el porcentaje estimado es de 23,7 $$3,3 %. El 23,7 % es la proporción obtenida en la muestra y ese 3,3 % de incertidumbre en torno al valor de la muestra es lo que llamamos margen de error. En igualdad de valores del resto de variables que intervienen, si quiere dar el resultado con menos margen de error deberá usar un mayor tamaño de muestra.\n\n\nz: Relacionado con el nivel de confianza\nSi llega a la conclusión de que esa proporción está en el intervalo 23,7$$3,3 % ¿Puede usted afirmar con total seguridad que el verdadero valor está dentro de este intervalo? No, no puede hacerlo, su afirmación siempre tendrá un cierto nivel de confianza. Si ese nivel de confianza es del 95 % significa que el intervalo se ha construido siguiendo un procedimiento que acierta (incluye el verdadero valor) el 95 % de las veces, es como una información que da alguien que dice la verdad el 95 % de las veces. El nivel de confianza está relacionado con el valor de \\(z\\). Para un nivel de confianza \\(1-\\alpha\\) el valor de \\(z\\) es aquel que deja un área de cola de \\(\\alpha/2\\) en la distribución \\(N(0; 1)\\). Si el nivel de confianza es el 95 % tenemos que \\(z_{0,025} = 1,96\\) (cuando los medios de cálculo eran rudimentarios ese 1,96 se redondeaba a 2 obteniéndose un nivel de confianza del 95,5 %). ¿Podemos construir el intervalo de manera que acierte el 99 % de las veces? Sí podemos, incluso podemos lograr que acierte el 99,99 %, pero no lo hacemos porque al aumentar el nivel de confianza aumenta también el margen de error y podemos llegar a la conclusión de que el porcentaje que andamos buscando está en el intervalo 23,7 \\(\\pm\\) 20 %. De eso estaremos muy seguros pero no hacía falta ningún estudio para llegar a esa conclusión.\nEn general, la determinación del margen de error y del nivel de confianza ``adecuados’’, no es un tema de la Estadística, ni de los estadísticos, es una decisión del equipo de investigación, que tiene conocimiento de los riesgos reales de equivocarse y del presupuesto disponible.\n\n\np: La variabilidad en la población\nSi en una población no hay variabilidad basta con mirar un solo elemento para saber cómo son todos. Cuando la variabilidad aumenta también lo hace el tamaño de muestra necesario para estimar sus características. Si se trata de estimar una proporción esa variabilidad está relacionada con el valor de la propia proporción \\(p\\), o más concretamente con \\(p(1-p)\\). Aquí aparece un problema porque si queremos estimar una proporción no podemos usar el valor de esa proporción –que no conocemos– para calcular el tamaño de muestra necesario. La solución es calcular el tamaño de la muestra poniéndonos en el caso más desfavorable que es cuando \\(p = 50\\%\\). A \\(1-p\\) también se le denomina \\(q\\), por esta razón muchas veces se habla del supuesto de \\(p=q=50 %\\) en las fichas técnicas de las encuestas.\n\n\nN: El tamaño de la población\nParece que esta es la variable cuya influencia está más justificada, pero no es así. Si la población es grande –y esto es lo más habitual– su tamaño prácticamente no influye. Usando la fórmula que hemos visto y con la ayuda de una hoja de cálculo se puede construir la siguiente tabla donde se aprecia la poca influencia del tamaño de la población.\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n \nTamaños de muestra para la estimación de una proporción con un nivel de confianza del 95 %\n\n\n  \n    \n      Tamaño de la población\n      Margen de error\n    \n    \n      ±1 % ±2 % ±3 % ±4 % ±5 % ±10 %\n    \n  \n\n  \n    50047641434127321881\n    1.00090670751737627888\n    1.5001.29892462442930691\n    2.0001.6561.09269746232392\n    2.5001.9841.22574948533493\n    3.0002.2871.33478850134194\n    3.5002.5661.42581851334794\n    4.0002.8251.50184352335194\n    4.5003.0651.56686353035595\n    5.0003.2891.62388053635795\n    6.0003.6941.71590754636295\n    7.0004.0501.78892755336595\n    8.0004.3651.84794255936795\n    9.0004.6471.89695556336996\n    10.0004.9001.93796556737096\n    15.0005.8562.07099757837596\n    20.0006.4892.1441.01458337796\n    25.0006.9392.1911.02458737996\n    50.0008.0572.2911.04559438296\n    100.0008.7632.3451.05659738396\n    500.0009.4232.3901.06560038497\n    1.000.0009.5132.3961.06660038497\n    1.500.0009.5432.3981.06760038597\n    2.000.0009.5582.3991.06760138597\n    \n      50.000.0009.6022.4011.06860138597\n    \n  \n\n\nAunque no aparece en la fórmula, el presupuesto disponible (tiempo, dinero, recursos) es seguramente la variable más influyente, de manera que muy a menudo la muestra es tan grande como los recursos permiten. En este caso, dado el tamaño de muestra, y establecido un nivel de confianza, se puede calcular el margen de error obtenido.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.4 ¿Cuántos elementos debe tener una muestra para que las conclusiones sean fiables?"
    ]
  },
  {
    "objectID": "0405_Muestra_poblacion.html",
    "href": "0405_Muestra_poblacion.html",
    "title": "4.5 ¿Qué relación hay entre tamaño de muestra y tamaño de población?",
    "section": "",
    "text": "Guiándonos solo por la intuición parece razonable considerar que el tamaño de la muestra debe estar muy relacionado con el de la población. Nos parece que para un país de 50 millones de habitantes hará falta una muestra mucho mayor que para una ciudad de 50 mil. A veces se ponen en duda los resultados de un estudio con el argumento de que la muestra no llega ni al 10 % de la población. Pues resulta que esas intuiciones son falsas.\n\n¿Le falta sal a la sopa?\nPara responder a esta pregunta el cocinero debe tomar una muestra representativa de la sopa y probarla ¿Le parece sensato recomendar al cocinero que pruebe el 10 % de la sopa para poder tomar una buena decisión? Esta recomendación contradice todas nuestras experiencias, ya que la cucharilla que usamos en nuestras casas para probar la sopa que preparamos habitualmente es la misma que cuando usamos una olla más grande porque tenemos invitados, y eso nunca nos ha sorprendido.\n\n\n\n\n\n\nFigura 1: La misma cuchara para las dos ollas\n\n\n\nLo que todos hacemos antes de sacar la muestra es dar un buen meneo con el cucharón para homogeneizar la sopa. Sabemos que es mucho más importante mezclar bien antes de tomar la muestra que aumentar el tamaño de la cuchara y, por supuesto, los problemas derivados de no remover bien no se resuelven con el uso de una cuchara más grande.\n\n\nDoctor, ¿para saber mi grupo sanguíneo me va usted a sacar una muestra con el 10 % de mi sangre?\nEs bien sabido que basta con una muestra de una gota de sangre para conocer en forma inequívoca el tipo de sangre de una persona. Todas las gotas de sangre de una persona son del mismo tipo, así que vista una, quedan vistas todas. La misma cantidad de sangre se requiere para un niño recién nacido que para su padre.\n\n\\[ \\bullet \\;\\;\\;\\;\\; \\bullet \\;\\;\\;\\;\\; \\bullet \\]\n\nLa figura 2 se ha construido usando la fórmula del tamaño de muestra para estimar una proporción. Puede apreciarse que a partir de un cierto tamaño de la población, que podemos situar en torno a 50.000, el tamaño de la muestra apenas cambia.\n\n\n\n\n\n\nFigura 2: Tamaño de muestra en función del tamaño de la población para los márgenes de error (E) que se indican, bajo el supuesto de \\(p=q=0,5\\) y un nivel de confianza del 95 %",
    "crumbs": [
      "Muestreo y Estimación",
      "4.5 ¿Qué relación hay entre tamaño de muestra y tamaño de población?"
    ]
  },
  {
    "objectID": "0406_Tipo_muestreo.html",
    "href": "0406_Tipo_muestreo.html",
    "title": "4.6 ¿Qué tipo de muestreo conviene elegir?",
    "section": "",
    "text": "Los tipos de muestreo se pueden dividir en dos grandes grupos: muestreo probabilístico y muestreo no probabilístico.\n\nMuestreo probabilístico\nEl más típico (al menos en los libros) es el muestreo probabilístico. La idea es tomar una muestra al azar (siempre más fácil de decir que de hacer) y, en función de la estrategia seguida y de los resultados obtenidos, se construyen los intervalos de confianza y se dan márgenes de error usando razonamientos puramente matemáticos. Según la estrategia seguida para seleccionar la muestra, el muestreo probabilístico puede ser (la lista no es exhaustiva):\n\nAleatorio simple: Se elige la muestra al azar de entre todo el conjunto de la población. Seguramente el más fácil de tratar en la teoría y el más difícil de llevar a cabo en la práctica.\nEstratificado: Se divide la población en estratos homogéneos y se extrae una muestra de cada estrato. Dado un mismo tamaño de muestra global permite realizar estimaciones más precisas para cada estrato.\nSistemático: Se selecciona la muestra siguiendo un criterio que facilita la selección y evita discrecionalidad, que en general no es lo mismo que aleatoriedad. Por ejemplo, en las entrevistas a pie de urna se va preguntando a uno de cada 10 por orden de salida.\nMultietápico: Primero se seleccionan zonas (barrios, estanterías del almacén,…) y dentro de cada zona se seleccionan unidades (individuos, piezas,…). En general es menos costoso porque las unidades están agrupadas y cuesta menos llegar a ellas.\n\n\n\nMuestreo no probabilístico\nEl problema del muestreo probabilístico es que en muchos casos la selección al azar no es viable, especialmente en el ámbito de las ciencias sociales. En estos casos no hay más remedio que usar métodos de muestreo no probabilístico, entre estos se encuentran los siguientes:\n\nMuestreo por cuotas: Se trata de definir grupos que tengan la máxima homogeneidad. La selección dentro de cada grupo no se realiza al azar sino que cualquier persona que cumpla los requisitos del grupo puede ser incluida en la muestra (al haber poca variabilidad dentro de cada grupo cualquier individuo puede ser un buen representante). Este procedimiento se adapta muy bien a las entrevistas telefónicas marcando números al azar. La entrevista se puede realizar a la persona que responde si no está completo el grupo al que pertenece, o se puede preguntar si en el hogar hay alguien con el perfil de un grupo que todavía esté sin completar. Cuando todos los grupos se han completado se entiende que la muestra es un buen reflejo de la población.\nMuestreo razonado: En ocasiones lo más conveniente puede ser tomar una muestra que responda a unas características específicas. Por ejemplo, si se viene comprobando que los resultados en un colegio electoral son un buen reflejo de lo que ocurre en todo el país, tomar a los votantes de ese colegio como muestra de todo el país puede ser lo más adecuado.\nEncuestas informales: Programa de televisión: “Salimos a la calle y preguntamos la opinión de los ciudadanos sobre…”. Más allá del tamaño de la muestra, los que pasan por ese sitio a esa hora y se prestan a responder delante de la cámara, no son una muestra representativa de la población. Casi siempre es evidente que se trata de un. Lo peor es cuando en un trabajo académico se realiza una encuesta más o menos de este tipo y se pretende dar a los resultados un valor que no tienen (a veces incluyendo niveles de confianza y márgenes de error).\nEncuestas de cortesía: En algunas ocasiones se nos pide que rellenemos un cuestionario dando nuestra opinión sobre un producto o servicio. En general solo responden los que están muy descontentos o muy satisfechos. La encuesta puede servir para detectar esos casos, pero es evidente que sus resultados no se pueden extrapolar a todos los clientes.\n\n\n\n¿Qué tipo elegir?\nEn contextos relacionados con la ingeniería, donde la población es un conjunto de unidades físicas (lote de producción, existencias en el almacén…) el muestreo probabilístico es, en general, una buena opción porque es relativamente fácil (o al menos es viable) elegir la muestra aleatoriamente.\nEn el ámbito de las ciencias sociales es mucho más difícil disponer de muestras verdaderamente aleatorias, por lo que en muchos casos no queda más remedio que optar por muestreos no probabilísticos. Dentro de este grupo también está el hacer lo que se pueda sacando el máximo provecho a los recursos disponibles.\nLo que no debe hacerse es utilizar muestras claramente no aleatorias y presentar los resultados ignorando ese detalle. Presentar niveles de confianza y márgenes de error puede dar un aire científico al estudio, pero si las muestras no son aleatorias esos valores son totalmente arbitrarios. Es como si le dicen “Supongamos que una castaña es una esfera…” y partir de ahí llegan a una serie de conclusiones sobre el comportamiento y las características geométricas de las castañas. No hay ninguna garantía de que esas conclusiones sean ciertas, no porque el método usado para obtenerlas sea incorrecto –puede ser una deducción impecable–, sino porque la hipótesis en que se basa es falsa. Exactamente lo mismo ocurre cuando se dice “Bajo la hipótesis de muestreo aleatorio simple…” y a continuación se dan márgenes de error, niveles de confianza y demás jerga estadística. En la presentación de trabajos académicos esto puede servir para dar un aire de rigor científico y enfriar las ganas de preguntar que pueden tener los miembros del jurado poco duchos en estas cosas, pero solo para eso.\nPara conocer la opinión de una población de interés, existen otros métodos además de las encuestas. En estudios de mercado suelen utilizarse los llamados focus groups. Se trata de elegir un grupo reducido de personas –en torno a 8 o 10– que incluya representantes de distintos sectores de la población de interés. Las conversaciones/entrevistas con estas personas, llevadas a cabo por personal experto, permiten obtener información para valorar el nivel de satisfacción con un producto o servicio y también obtener ideas para mejorarlo.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.6 ¿Qué tipo de muestreo conviene elegir?"
    ]
  },
  {
    "objectID": "0407_Aleatoria_representativa.html",
    "href": "0407_Aleatoria_representativa.html",
    "title": "4.7 ¿Es lo mismo muestra aleatoria que muestra representativa?",
    "section": "",
    "text": "No, no es lo mismo. Ni por ser aleatoria ya es representativa, ni que sea representativa implica que sea aleatoria.\nPara que una muestra aleatoria sea representativa es necesario que tenga un cierto tamaño. Si en la población existen 7 estratos sociales y se toma una muestra de 5 individuos, por muy aleatoria que sea esa muestra no será representativa de la población.\nSí se pueden tener muestras representativas sin ningún tipo de selección aleatoria. Esto es lo que se pretende con el muestreo por cuotas. Naturalmente, hay que tener muy clara la estructura de la población, saber dividirla en grupos homogéneos y asignar a cada grupo el peso o el tamaño que le corresponde. Si todo se hace correctamente, esa muestra puede considerarse representativa, aunque el entrevistador se entreviste a sí mismo, y entreviste también a sus padres y a su novia, siempre que pertenezcan a grupos especificados en el plan de muestreo.\nYa que estamos en este tema, tres reflexiones sobre la representatividad:\n\nEl término “representante”, o “representativo”, muchas veces se utiliza con un sentido distinto al que damos en estadística. Así, por ejemplo, cuando se pregunta por un escritor representativo de Colombia en muchas ocasiones se responde que Gabriel García Márquez, aunque seguramente este es el más atípico de los escritores colombianos. O cuando se habla de los atletas representantes de un país en unas olimpiadas, seguro que no son representativos -al menos en forma física- de los ciudadanos de ese país.\nTenemos una tendencia innata a considerar representativa y, por tanto, a generalizar, en base a muestras muy pequeñas. A veces incluso a muestras de una sola observación: “Este remedio va muy bien, a mi vecino le funcionó”.\nLas muestras autoseleccionadas nunca son representativas. Es una práctica habitual hacer encuestas enviando cuestionarios y sacando conclusiones a partir de los que responden, como si esos fueran una muestra representativa. Los que responden son los que están interesados en el tema de la encuesta, si se pregunta sobre cuanto se recicla responderán más los que están más sensibilizados con los problemas del medio ambiente y, por tanto, los que más reciclan.\n\nSi usted quiere estimar las características de una población de 1000 empresas y envía un cuestionario a todas ellas, con mucha suerte le responderán 200. Quizá este número le parezca suficiente y piense que a partir de ahí se pueden sacar unas buenas conclusiones, pero será mucho más representativa una muestra de 50 empresas elegidas al azar y perseguidas hasta tener su opinión que la de 200 autoseleccionadas. Claro que el margen de error le saldrá mayor con 50 empresas que con 200, pero el primero será cierto y útil y el otro ni una cosa ni otra.\n\n¿Como saber si mi muestra es representativa?\nNo existen test de representatividad, y es una lástima porque en muchos estudios estadísticos, donde hay profusión de test de todo tipo, se pasa por alto la justificación de la representatividad de la muestra como si esa fuera una característica innata de todas las muestras y no fuera necesario justificarla.\nUna forma de verificar la representatividad es comprobar que se resiste un duro interrogatorio que lo ponga en duda. Imagínese que le cuestionan esa representatividad por todas las razones que pueda imaginar (por ejemplo, usted solo ha entrevistado a los que vio con actitud de querer colaborar, y esos tendían a tener una determinada opinión…). Solo si es capaz de rebatir de manera convincente todas y cada uno de esas objeciones podrá considerar que su muestra es representativa.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.7 ¿Es lo mismo muestra aleatoria que muestra representativa?"
    ]
  },
  {
    "objectID": "0408_Acertar_sondeos.html",
    "href": "0408_Acertar_sondeos.html",
    "title": "4.8 ¿Por qué cuesta acertar en los sondeos electorales?",
    "section": "",
    "text": "Cuando se estiman las características de una población a partir de una muestra siempre hay que asumir un cierto margen de error, pero cuando ese error va más allá de lo esperado es que falla algo. No es que no se cumpla la teoría estadística, lo que no se cumple son los principios en que se basa, ya sea por falta de recursos o porque en la práctica es muy difícil cumplirlos. Veamos algunas de estas dificultades.\n\nConseguir que la muestra sea representativa\nEste no es un problema específico de los sondeos electorales pero es más difícil conseguir la muestra adecuada si una parte de la población se muestra renuente a responder preguntas sobre sus ideas políticas. Si las razones de no respuesta fueran independientes de las preferencias de voto, el problema tendría solución desde la estadística. Sin embargo, la práctica ha demostrado que esto no es así, hay más voto oculto en unas opciones políticas que en otras, y el problema se complica.\n\n\nLa intención de voto va cambiando\nLos sondeos electorales se basan en encuestas realizadas varios días, o incluso varias semanas, antes de las elecciones. En algunos países está prohibido publicar resultados de sondeos electorales durante un cierto periodo de tiempo antes de las elecciones. Por tanto, nos encontramos con dos tipos de extrapolaciones: 1) La que se hace desde la muestra hacia la población, siendo esta la que trata la teoría estadística del muestreo, y 2) La que generaliza los resultados de las fechas en que se ha hecho el sondeo, al día de las elecciones. Pero los partidos se emplean a fondo en sus campañas electorales, se producen debates entre candidatos, pueden ocurrir sucesos sobre los que se posicionan los candidatos, y todo esto puede afectar a la decisión final de a quién se vota.\n\n\n¿A quién votarán los indecisos?\nLos indecisos suelen representar un porcentaje importante de la población y depende de lo que estos acaben votando los resultados serán unos u otros. Realizar las estimaciones ignorando a los indecisos no es una buena idea porque estos acabarán votando (al menos una gran parte). Suponer que entre los indecisos se reproducirán las mismas proporciones que entre los que ya han decidido su voto también es mucho suponer.\nLas empresas especializadas en realizar sondeos electorales tienen sus procedimientos para asignar el voto a los indecisos. Las entrevistas empiezan con preguntas “fáciles” (edad, profesión,…) que permiten asignar un cierto perfil socioeconómico a los entrevistados. A continuación se pueden hacer preguntas más relacionadas con la ideología, como su opinión sobre un tema polémico en el que derecha e izquierda tienen opiniones contrapuestas, su valoración de algunos líderes políticos o a quién votó en las últimas elecciones. La respuesta a estas preguntas marca un perfil al que se asigna un voto. La correcta asignación de este voto responde más a conocimientos relacionados con la sociología y con la política que con la estadística, y en esa correcta asignación está el éxito o el fracaso de los resultados del sondeo.\n\n\nLa falta de sinceridad en las respuestas\nLa redacción de las preguntas y el orden en que se realizan son aspectos críticos para conseguir la participación y la sinceridad de los encuestados. Por otra parte, conseguir que el entrevistado se sienta cómodo y responda con sinceridad requiere entrevistadores bien entrenados y motivados (léase bien pagados).\nA veces la situación política hace que algunos ciudadanos prefieran disimular sus preferencias declarando que votarán a las opciones que consideran “mejor vistas”. También puede ocurrir que se muestren indecisos cuando en realidad se trata de “decisos cautos”.\n\n\nDel porcentaje de votos al número de escaños\nEn muchas ocasiones lo verdaderamente relevante no es el porcentaje de votos sino el número de escaños que va a obtener cada partido. Pequeñas variaciones en el porcentaje de votos –imposibles de precisar– provocan cambios en el número de escaños.\nOtro problema es que algunas legislaciones electorales exigen un mínimo porcentaje de votos para entrar en el reparto. Si ese porcentaje es del 5 % y la estimación de voto para un partido es del 4$$2 % no se puede saber si llegará o no al mínimo necesario, y el hecho de que llegue o no llegue afectará también al número de escaños del resto de partidos.\n\\[ \\bullet \\;\\;\\;\\;\\; \\bullet \\;\\;\\;\\;\\; \\bullet \\]\nA pesar de las dificultades comentadas, las empresas especializadas saben cómo hacer las estimaciones en base a su experiencia aplicando técnicas y conocimientos que van más allá de los procedimientos clásicos de estimación estadística. Sus resultados siempre son esperados con interés y muchas veces el grado de acercamiento a lo que al final acaba ocurriendo es espectacular. Claro que, como en otros ámbitos, siempre se destacan más los fallos que los aciertos.",
    "crumbs": [
      "Muestreo y Estimación",
      "4.8 ¿Por qué cuesta acertar en los sondeos electorales?"
    ]
  },
  {
    "objectID": "0409_Maximoverosimil.html",
    "href": "0409_Maximoverosimil.html",
    "title": "¿Qué es un estimador de máxima verosimilitud?",
    "section": "",
    "text": "Cuando queremos estimar un parámetro de una población cuya distribución es conocida (Normal, binomial, Poisson, …), tomamos una muestra aleatoria para a partir de ella estimar dicho parámetro. Por ejemplo, si se sabe que una situación puede modelarse con una distribución de Poisson, para estimar el valor de su media \\(\\lambda\\), podemos tomar una muestra aleatoria \\((x_1, x_2, ..., x_n)\\) de \\(n\\) observaciones e intentar responder a la siguiente pregunta ¿cuál de todos los posibles valores de \\(\\lambda\\) produce con mayor verosimilitud (credibilidad) una muestra como la observada? La respuesta a esta pregunta corresponde al estimador de máxima verosimilitud.\nPara hacer operativo el criterio descrito vamos a deducir la expresión del estimador de máxima verosimilitud de \\(\\lambda\\) en nuestro ejemplo de la distribución de Poisson. La matemática es quizá un poco aparatosa, pero fácil de seguir.\nConsideremos la muestra aleatoria \\((x_1, x_2, ..., x_n)\\). Como las variables aleatorias que componen la muestra son independientes, la probabilidad conjunta es igual al producto de las probabilidades de cada una de ellas, de manera que:\n\\[\\begin{equation*}\n    \\begin{split}\n        L &=P(X_1=x_1;\\;X_2=x_2;\\;...; \\;X_n=x_n\\mid \\lambda) \\\\[1mm]\n        &= \\underbrace{P(X_1=x_1\\mid \\lambda)}_{\\LARGE{ \\frac{e^{-\\lambda}\\lambda^{x_1}}{x_1!}}} \\cdot \\underbrace{P(X_2=x_2\\mid \\lambda)}_{\\LARGE{ \\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!}}} \\cdot ... \\cdot \\underbrace{P(X_n=x_n\\mid \\lambda)}_{\\LARGE{ \\frac{e^{-\\lambda}\\lambda^{x_n}}{x_n!}}}\n    \\end{split}\n\\end{equation*}\\]\nLa expresión que hemos nombrado con la letra \\(L\\) es una función de \\(\\lambda\\), pues se supone que \\((x_1, x_2, ... , x_n)\\) es una realización de la muestra, es decir, son números concretos. Así que en \\(L\\) el parámetro \\(\\lambda\\) es nuestra única incógnita. Esto podemos escribirlo así: \\[L(\\lambda \\mid x_1,\\;x_2,\\;..., x_n)=\\frac{e^{-\\lambda}\\lambda^{x_1}}{x_1!} \\cdot \\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!} \\cdot ... \\cdot \\frac{e^{-\\lambda}\\lambda^{x_n}}{x_n!}\\]\nLa pregunta ahora puede formularse de la siguiente manera: si se obtuvo la muestra \\((x_1, x_2, ..., x_n)\\), ¿cuál es el valor de \\(\\lambda\\) (en términos de las \\(x_i\\)) que hace máxima la función \\(L(\\lambda \\mid x_1,\\;x_2,\\;..., x_n)\\)?\nDe esta manera el problema queda convertido en un problema de optimización, del tipo de los que resolvimos en nuestros cursos de cálculo, aquellos en los que debía derivarse e igualar a cero la derivada para encontrar puntos críticos, que luego serían probados con la segunda derivada para identificar si correspondían a un punto máximo o con un mínimo.\nPara que la deducción sea más cómoda, un truco que suele dar buenos resultados es trabajar con el logaritmo de \\(L\\) en vez de con \\(L\\) directamente, ya que el valor de \\(\\lambda\\) que maximice una expresión, maximizará también la otra. En nuestro caso lo haremos de esta forma, obteniéndose:\n\\[\n\\begin{flalign*}\n\\log \\left[ L(\\lambda) \\right] &= \\log \\left(\\frac{e^{-\\lambda}\\lambda^{x_1}}{x_1!} \\cdot \\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!} \\cdot ... \\cdot \\frac{e^{-\\lambda}\\lambda^{x_n}}{x_n!} \\right) = &&\\\\[4mm]\n&= \\log \\left(\\frac{e^{-\\lambda}\\lambda^{x_1}}{x_1!} \\right) + \\log \\left( \\frac{e^{-\\lambda}\\lambda^{x_2}}{x_2!} \\right) +...+ \\log \\left(\\frac{e^{-\\lambda}\\lambda^{x_n}}{x_n!} \\right) =\\\\[4mm]\n&= \\left[-\\lambda+x_1 \\log(\\lambda)-\\log(x_1!) \\right] +...+ \\left[-\\lambda+x_n \\log(\\lambda)-\\log(x_n!) \\right] =\\\\[4mm]\n&=-n \\lambda + \\log(\\lambda) \\sum_{i=1}^n x_i - \\sum_{i=1}^n \\log(x_i!)\n\\end{flalign*}\n\\]\nDerivando respecto a \\(\\lambda\\) e igualando a cero: \\[\\frac{\\partial\\; [ \\log\\;L(\\lambda)]}{\\partial \\lambda} = -n + \\frac{1}{\\lambda} \\sum_{i=1}^n x_i =0\\]\nPara asegurar que estamos ante un máximo podemos hacer la segunda derivada y comprobar que da un valor negativo. De la primera derivada se deduce fácilmente que el valor de \\(\\lambda\\) que maximiza \\(\\log[L(\\lambda)]\\), y por tanto también \\(L(\\lambda)\\), es: \\[ \\lambda = \\frac{\\sum_{i=1}^n x_i}{n} = \\bar{x} \\]\nPor tanto, diremos que la media de la muestra es el estimador de máxima verosimilitud para el parámetro \\(\\lambda\\) de una distribución de Poisson.",
    "crumbs": [
      "Muestreo y Estimación",
      "¿Qué es un estimador de máxima verosimilitud?"
    ]
  },
  {
    "objectID": "0401_Creemos_muestra.html#footnotes",
    "href": "0401_Creemos_muestra.html#footnotes",
    "title": "4.1 ¿Por qué nos creemos los resultados de una muestra sabiendo que si tomáramos otra serían distintos?",
    "section": "",
    "text": "La fórmula que permite calcular el tamaño de la muestra, cuando el tamaño de la población se supone infinito, o muy grande respecto al tamaño de la muestra, es: \\(n=z_{\\alpha/2}^2 \\sigma^2 /E^2\\), donde el valor \\(z_{\\alpha/2}\\) depende del nivel de confianza (para el 99,7 % vale 2,97), \\(\\sigma\\) es la desviación típica de la población y \\(E\\) es el margen de error. Si suponemos \\(\\sigma=4\\), el nivel de confianza indicado y \\(E=2\\), se obtiene \\(n=35,3\\). Este valor siempre se redondea por exceso.↩︎",
    "crumbs": [
      "Muestreo y Estimación",
      "4.1 ¿Por qué nos creemos los resultados de una muestra sabiendo que si tomáramos otra serían distintos?"
    ]
  },
  {
    "objectID": "0403_Factor_correccion.html#footnotes",
    "href": "0403_Factor_correccion.html#footnotes",
    "title": "4.3 ¿Qué es el factor de corrección por población finita?",
    "section": "",
    "text": "El lector interesado puede consultar, por ejemplo: Steven K. Thompson: ``Sampling’’, Wiley, 2012, pp. 20-22.↩︎",
    "crumbs": [
      "Muestreo y Estimación",
      "4.3 ¿Qué es el factor de corrección por población finita?"
    ]
  },
  {
    "objectID": "0501_Que_es.html",
    "href": "0501_Que_es.html",
    "title": "5.1 ¿Qué es un contraste de hipótesis?",
    "section": "",
    "text": "Es el tipo de razonamiento que se sigue en los test estadísticos.\nSupongamos que el tratamiento médico A, bien conocido y usado durante muchos años, cura al 50 % de los pacientes. Aparece otro tratamiento, B, que se cree que puede ser más eficaz y para comprobarlo se aplica a 10 pacientes de los cuales se curan 7. ¿Puede decirse que el nuevo tratamiento es más eficaz?\nSi usted está pensando que sí, que si A cura al 50 % y B al 70 % está claro que B cura más que A, está ignorando la variabilidad que presentan los resultados de las pruebas (¿está seguro de que si se vuelve a realizar la prueba con otros 10 pacientes, también la proporción de curados será mayor del 50 %?). Cuando se realiza un contraste de hipótesis se tiene en cuenta esa variabilidad y se analiza si la diferencia observada (en nuestro caso, del 70 % respecto al 50 %) se puede atribuir al azar o, por el contrario, es muy poco probable que así sea, en cuyo caso se dice que es estadísticamente significativa.\nLa carga de la prueba la tiene el que afirma que algo es mejor, o –en general– que ha cambiado, de manera que el nuevo tratamiento se considera igual que el anterior a menos que los datos obtenidos no sean coherentes con esa hipótesis. Este es el proceso de razonamiento:\nUn p-valor pequeño indica que los datos obtenidos son poco probables si la hipótesis nula es cierta, con lo cual lo más razonable será rechazarla. En el caso extremo de que el p-valor sea igual a cero significa que es imposible obtener esos datos si la hipótesis nula es cierta, y como los datos son los que son, seguro que la hipótesis nula es falsa. Por el contrario, si el p-valor es grande, significa que los valores obtenidos son razonables suponiendo cierta la hipótesis nula, por lo que no habría ninguna razón para dudar de ella.\nEn nuestro caso, se ha obtenido un p-valor del 17,2 %, es decir, que suponiendo que la probabilidad de curarse sea del 50 % (hipótesis nula) la probabilidad de que se curen 7 o más en un grupo de 10 es del orden del 17 %. Lo observado es bastante probable suponiendo que la probabilidad de curarse sea del 50 %, luego no hay razón para rechazar la hipótesis nula. Sin embargo, si se hubiera probado con una muestra de 100 pacientes y se hubieran curado 70, el p-valor sería prácticamente igual a cero (exactamente el 0,00393 %) y, por tanto, sería muy raro que el porcentaje de curados fuera del 50 % (figura 1 dcha.). Lo más razonable en este caso sería rechazar la hipótesis nula.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.1 ¿Qué es un contraste de hipótesis?"
    ]
  },
  {
    "objectID": "0502_Controvertido.html",
    "href": "0502_Controvertido.html",
    "title": "5.2 ¿Por qué es controvertido el uso del contraste de hipótesis?",
    "section": "",
    "text": "Aunque es una pieza clave en el análisis estadístico –al menos en la estadística clásica– el uso del contraste de hipótesis es discutido y se proponen alternativas en el ámbito de la llamada Estadística Bayesiana. Veamos algunas pegas que se le pueden poner.\n\nSi todos buscamos la diferencia, alguien la encontrará\nLa probabilidad de error por rechazar equivocadamente la hipótesis nula se fija en un valor que se considera razonable, habitualmente del 5 %. Por tanto, si se realiza un estudio para analizar si un medicamento es eficaz, si en realidad no lo es la probabilidad de darlo por bueno será ese 5 % que se había fijado. El problema se presenta cuando muchos investigadores sospechan de la posible eficacia de ese medicamento y realizan estudios similares con la misma probabilidad de error. No será nada raro que en alguno de ellos la diferencia sea estadísticamente significativa. Basta con que se realicen 10 estudios para que la probabilidad de que en alguno se obtenga una diferencia significativa sea del 40 % (\\(1-0,95^{10}\\)), una cifra nada despreciable.\nSi los que han obtenido resultados negativos no informan de su trabajo (al fin y al cabo, no han encontrado nada nuevo) y los que sí han visto que el medicamento es eficaz (por casualidad, pero ellos no lo saben) publican su investigación en una revista científica, se dará validez a unos resultados que en realidad se han obtenido por azar.\n\n\nSi ponemos muchos recursos para encontrar una diferencia, la encontraremos\nCuando se comparan dos tratamientos seguro que sus resultados no son idénticos, seguro que se observará alguna diferencia si las mediciones se realizan con suficiente precisión. Otro tema es que esa diferencia sea relevante o que tenga importancia a efectos prácticos.\nSi se realizan estudios estadísticos con muestras suficientemente grandes llegaremos a notar diferencias que pueden ser estadísticamente significativas, es decir, que no explica el azar, pero que son irrelevantes a efectos prácticos.\nEs como si vemos dos animales a lo lejos y no sabemos si son un gato y un perro (diferentes) o son dos gatos (no diferentes). Con unos prismáticos podremos ver de qué se trata, pero si los miramos a través de un telescopio los veremos tan ampliados que seguro que nos parecen distintos. Si miramos –por ejemplo– las orejas de uno y otro, seguro que no son iguales, pero tanto detalle no es útil a efectos de lo que interesa.\n\n\nTodos los que ganan la lotería han hecho trampa\nA su vecino le ha tocado el primer premio de un sorteo realizado con fines benéficos y, como alguien sospecha que quizá ha hecho trampa, usted decide analizar la situación mediante un contraste de hipótesis. Planteará como hipótesis nula que el premio ha sido justo y como alternativa que ha habido trampa. Como en el sorteo había 10.000 boletos, la probabilidad de que le toque el primer premio –suponiendo que no haya hecho trampa– es de 1/10.000. Este sería el \\(p\\)-valor de la prueba, tan pequeño que invita a pensar lo peor.\nPero si su vecino es una persona honrada y usted no cree que tuviera ninguna intención de hacer trampa, esa conclusión no parece nada acertada. El enfoque bayesiano tiene en cuenta la información de que su vecino es una persona honrada. Considerando que la probabilidad a priori –antes de conocerse el ganador– de que haya hecho trampa es de 1 entre 1 millón podemos construir el esquema de la figura 3 donde el valor que aparece junto a cada línea indica la probabilidad de ocurrencia.\n\n\n\n\n\n\nFigura 1: Probabilidades de hacer trampa y de ganar comprando un boleto\n\n\n\nAhora, aplicando el teorema de Bayes, podemos volver a calcular la probabilidad de que haya hecho trampa sabiendo que ha ganado. La fórmula es la siguiente (G: Gana, T: hace trampa; Nt: No hace trampa):\n\\[\\begin{equation*}\n    \\begin{split}\n    P(\\text{T} |\\text{G}) &= \\frac{P(\\text{G}| \\text{T}) \\cdot P(\\text{T})}{P(\\text{G}| \\text{T}) \\cdot P(\\text{T})+P(\\text{G}| \\text{Nt}) \\cdot P(\\text{Nt})} \\\\\\\\\n    &=\\frac{1 \\cdot \\frac{1}{\\text{1.000.000}}} {1 \\cdot \\frac{1}{\\text{1.000.000}} + \\frac{\\text{1}}{\\text{10.000}} \\cdot \\frac{\\text{999.999}} {\\text{1.000.000}}} = \\text{0,009901}\n    \\end{split}\n\\end{equation*}\\]\nCon las suposiciones que hemos realizado llegamos a la conclusión de que la probabilidad de que nuestro vecino sea un tramposo es del orden del 1 %. Si hubiéramos supuesto que la probabilidad a priori era de 1 entre 10 millones, el resultado a posteriori sería de 1 entre mil.\nA algunos investigadores les parece “poco científico” dar un valor puramente especulativo a una variable que influirá en el resultado obtenido. Pero es evidente que no es lo mismo que el comprador del boleto sea una persona de conducta ejemplar o que haya sido condenado varias veces por estafa y, además, haya organizado él mismo el sorteo. Enfrentarse a un problema ignorando una información tan evidente y a la vez tan relevante, no parece que sea la mejor forma de aprovechar los recursos disponibles. Los que se adentren en este terreno tendrán ocasión de elegir en cada caso la alternativa que les parezca más razonable.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.2 ¿Por qué es controvertido el uso del contraste de hipótesis?"
    ]
  },
  {
    "objectID": "0503_Que_alternativa.html",
    "href": "0503_Que_alternativa.html",
    "title": "5.3 ¿Cómo elegir la hipótesis alternativa que conviene plantear?",
    "section": "",
    "text": "La selección de la hipótesis alternativa está relacionada con el planteamiento del problema y con la zona en que queremos situar el riesgo de equivocarnos al rechazar la hipótesis nula. Lo veremos a través de la reflexión sobre tres situaciones distintas.\n\nSituación 1: Fertilizante enriquecido para una plantación de tomates\nUna explotación agraria es informada de que añadiendo un cierto complejo mineral al fertilizante que usa en sus plantaciones de tomates, se obtiene una mayor cosecha. Para comprobar si esta afirmación es cierta se toman 20 plantas, en 10 de ellas se utiliza sólo el fertilizante habitual (grupo de control, A) y en las otras 10 se añade el complemento mineral (grupo tratado, B). Se quiere contrastar la hipótesis nula de que el peso medio de tomates por planta es igual en ambos casos. ¿Cuál debe ser la alternativa?\nComo nuestro interés está en saber si el complemento mineral es eficaz, sólo rechazaremos la hipótesis nula si la media del grupo tratado es mayor (en la magnitud requerida) que la media del grupo de control. Naturalmente no podremos decir que el complejo mineral es eficaz si la media del grupo tratado es menor. Por tanto, el riesgo de equivocarnos al rechazar la hipótesis nula lo situamos sólo hacia los valores mayores. En este caso la hipótesis alternativa debe ser: \\(H_1:\\;\\mu_A&lt;\\mu_B\\).\n\n\n\n\n\n\nFigura 1: Solo rechazamos \\(H_0\\) si la media del grupo tratado es “mucho” mayor\n\n\n\n\n\nSituación 2: ¿Tienen los sacos de fertilizante un peso menor al establecido?\nLa explotación agrícola compra sacos de fertilizante y el proveedor asegura que el peso medio de los sacos es de 50 kg, con una desviación típica de 0,5 kg. Como el comprador sospecha que los sacos contienen, en promedio, menos de 50 kg, decide tomar una muestra y contrastar la hipótesis nula de que el peso medio es el que dice el proveedor, \\(H_0:\\;\\mu=50\\), ¿frente a qué alternativa?\nPara realizar la prueba podemos tomar 4 sacos, y comparar su peso medio con la distribución a la que pertenecería si \\(\\mu=50\\). Lo que nos preocupa es que el peso sea menor y por tanto, solo rechazaremos la hipótesis nula si la media de los 4 sacos es suficientemente menor que el valor nominal. Es decir, en este caso la hipótesis alternativa será: \\(H_1:\\;\\mu&lt;50\\), y con un nivel de significación \\(\\alpha=0,05\\), “suficientemente menor” significa menor que \\(50-z_{0,05}\\sigma/\\sqrt{n} = 49,59\\)\n\n\n\n\n\n\nFigura 2: Zona de rechazo de \\(H_0\\) si lo que nos preocupa es que los sacos pesen menos de 50 kg\n\n\n\nObsérvese que este planteamiento beneficia al vendedor, ya que la carga de la prueba se le pone al comprador. El proceso se supone centrado “a no ser que se demuestre lo contrario”, y el riesgo de equivocarnos en contra del vendedor (que el promedio sea de 50 kg y digamos que es menor) está fijado de antemano en un valor bajo (probabilidad \\(\\alpha\\), en nuestro caso 0,05), pero nada se dice sobre el riesgo de que el promedio sea, por ejemplo, 49,5 kg y que demos el proceso por bueno. Este último riesgo –riesgo del comprador, probabilidad \\(\\beta\\)– con los números de nuestro ejemplo es igual al 36 % (nada despreciable).\n\n\nSituación 3: ¿Está el peso de los sacos fuera de tolerancias?\nEl productor llena los sacos en una línea automática y, cada cierto tiempo, pesa una muestra para verificar que el peso medio está en 50 kg. Al fabricante no le interesa dar más producto (pierde dinero) ni menos (da mala calidad). Su hipótesis nula es que el proceso se mantiene centrado. ¿Cuál debe ser la alternativa?\nTal como está planteado, al fabricante le preocupa lo mismo que el proceso se descentre hacia arriba o hacia abajo, así que deberá estar atento a los dos lados. Si su plan de control consiste en tomar muestras de 4 sacos y acepta tener un 5 % de falsas alarmas, deberá repartir este riesgo entre valores por defecto (2,5 %) y valores por exceso (2,5 %). En este caso los valores críticos son: \\(50 \\pm z_{0,025}\\sigma/\\sqrt{n}\\), lo que resulta igual a 49,51 y 50,49.\n\n\n\n\n\n\nFigura 3: Zona de rechazo de \\(H_0\\) si lo que nos preocupa es que el peso de los sacos se desvíe tanto por exceso como por defecto\n\n\n\nEvidentemente en este caso la hipótesis alternativa debe ser \\(H_1: \\mu \\ne 50 \\text{ kg}\\)",
    "crumbs": [
      "Contraste de hipótesis",
      "5.3 ¿Cómo elegir la hipótesis alternativa que conviene plantear?"
    ]
  },
  {
    "objectID": "0504_No_rechazo.html",
    "href": "0504_No_rechazo.html",
    "title": "5.4 ¿Por qué se habla de “no rechazo” y no de “aceptación”?",
    "section": "",
    "text": "Esta es una característica general de la búsqueda del conocimiento científico. Veamos un ejemplo.\nEn un juego se trata de descubrir un animal oculto y los participantes (los científicos) deben hacer preguntas sobre características de dicho animal con el propósito de descubrirlo. Uno de ellos tiene como hipótesis que el animal es una paloma y, para contrastar su hipótesis, pregunta: ¿tiene alas? Se le responde que sí, que efectivamente el animal tiene alas.\n¿Qué conclusión puede sacarse hasta el momento? ¿Puede decirse que su hipótesis es cierta y que el animal es una paloma? Sabemos que la respuesta es no. La evidencia (tener alas) es compatible con su hipótesis, pero ello no significa que sea verdadera, pues existen muchas otras hipótesis que son igualmente compatibles con dicha evidencia, por ejemplo, que el animal sea un murciélago.\nEl científico hace una nueva pregunta (observación): ¿el animal es vertebrado? y se le responde que no. ¿Qué pasa con su hipótesis ahora? ¿El animal podría ser una paloma? No. Ahora rechazamos la hipótesis de forma contundente para replantearla de tal manera que sea compatible con los nuevos hechos: tiene alas y no es vertebrado. La nueva hipótesis puede ser: el animal es un mosquito.\nTodas las verdades en la ciencia son de carácter transitorio, de forma que una afirmación sobre la naturaleza es verdadera porque no ha podido demostrarse que sea falsa. Pueden existir muchas hipótesis compatibles con los hechos, no solo la nuestra, por lo que el no rechazo de una hipótesis no implica su veracidad. No ocurre lo mismo cuando los hechos contradicen la hipótesis: si el animal no es vertebrado estamos muy seguros de que no es una paloma.\nVolviendo a nuestro tema, al contrastar la hipótesis nula de que la media poblacional es \\(\\mu=10\\) frente a la alternativa \\(\\mu \\ne 10\\), suponiendo que la desviación típica es \\(\\sigma=6\\), si se obtiene que la media de una muestra de 9 observaciones es \\(\\bar{x}=25\\), claramente podemos rechazar la hipótesis nula, pero si sale \\(\\bar{x}=11\\) no la podemos rechazar, aunque tampoco afirmar que es cierta porque nuestros datos también serían coherentes con hipótesis del tipo \\(\\mu=10.5\\) o \\(\\mu=11\\).",
    "crumbs": [
      "Contraste de hipótesis",
      "5.4 ¿Por qué se habla de “no rechazo” y no de “aceptación”?"
    ]
  },
  {
    "objectID": "0505_Lado_cola.html",
    "href": "0505_Lado_cola.html",
    "title": "5.5 ¿Cómo se sabe hacia qué lado hay que mirar el área de cola?",
    "section": "",
    "text": "1) \\(\\;\\bar{y}_A &gt; \\bar{y}_B\\):\nCuando se plantean dudas de este tipo siempre es mejor encontrar la respuesta razonando, ya que echar mano de recetas puede llevar a cometer errores de mucho bulto. Supongamos que el planteamiento del contraste es:\nUna vez tengamos los resultados de las medias muestrales estaremos en uno de los siguientes casos:\nEstamos de suerte en cuanto a facilidad de cálculo. No hace falta que calculemos nada. Seguro que no se puede rechazar la hipótesis nula. Por ejemplo, si se analiza la eficacia de un complemento mineral en el fertilizante de una plantación y resulta que las plantas en las que se ha utilizado este complemento dan una producción menor, es evidente que no podremos rechazar la hipótesis nula y concluir que el complemento mineral aumenta la cosecha.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.5 ¿Cómo se sabe hacia qué lado hay que mirar el área de cola?"
    ]
  },
  {
    "objectID": "0506_p_valor.html",
    "href": "0506_p_valor.html",
    "title": "5.6 ¿A partir de qué p-valor se debe rechazar la hipótesis nula?",
    "section": "",
    "text": "A todos nos gustan las reglas claras y sencillas, pero no es sensato tomar un p-valor como frontera universal y aplicarlo siempre con independencia del contexto en que esté situado. Fijar un valor frontera es lo mismo que decidir la probabilidad de equivocarnos si se rechaza la hipótesis nula, y la probabilidad de error que es razonable asumir depende de la situación en la que estemos y de las consecuencias de cometer ese error.\nSupongamos que un día por la mañana, al salir de casa, miramos como está el tiempo y consideramos que hay una probabilidad del 10 % de que llueva ¿debemos volvernos a coger el paraguas? A nadie le parecerá temerario que sigamos y corramos un riesgo del 10 % de que la lluvia nos pille desprotegidos. Si nos equivocamos no perdemos mucho (quizá nos mojemos un poco) y también hay que considerar que ir todo el día con el paraguas sin llover es bastante incómodo.\nOtra situación. Vamos conduciendo por una carretera secundaria muy poco transitada. En un cambio de rasante, sin ninguna visibilidad de los coches que vienen de frente, vemos que hay un pequeño bache en el lugar por donde debemos pasar, aunque lo podríamos evitar colocándonos a la izquierda. Pero no lo haremos. La probabilidad de que por esa carretera tan poco transitada nos crucemos con un coche es pequeña, y que nos crucemos justo en el cambio de rasante es mucho menor. Pero no lo haremos porque aunque la probabilidad es muy pequeña, si se produce nos perjudica mucho (muchísimo). Es evidente que la probabilidad de error que estamos dispuestos a correr al tomar una decisión depende de las circunstancias y de lo que nos costaría ese error.\nPor tanto, la respuesta a la pregunta planteada no es de carácter estadístico, sino que está relacionada con el contexto del problema que se está tratando. Cuando se realiza una prueba para analizar si un nuevo fármaco es mejor que el actual, tomar como valor frontera 0,05 significa que corremos un riesgo del 5 % de decir que es mejor cuando en realidad no lo es. ¿Qué implicaciones tiene esto? ¿Puede tener el nuevo tratamiento efectos secundarios perjudiciales? ¿Es mucho más caro que el tratamiento convencional? Las respuestas a los interrogantes planteados son importantes para fijar el valor frontera más conveniente.\nPero también es verdad que en muchos casos se toma como referencia el valor de 0,05 sin entrar en más consideraciones. El porqué se utiliza 0,05 tiene que ver con los valores que figuran en las tablas. Cuando se empezaron a elaborar, con unos medios muy rudimentarios, sólo se tabularon los valores correspondientes a algunas probabilidades –números fáciles como 0,001, 0,005; 0,01; 0,05, 0,10,…– y de entre los disponibles, se acostumbró a tomar el correspondiente a 0,05 como el más adecuado para separar lo habitual de lo raro. La ventaja del 0,05 es ser un valor redondo en nuestro sistema decimal. Si tuviéramos 6 dedos, seguramente consideraríamos más natural tomar decisiones utilizando el 0,06 como valor frontera.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.6 ¿A partir de qué *p*-valor se debe rechazar la hipótesis nula?"
    ]
  },
  {
    "objectID": "0507_Tipos_error.html",
    "href": "0507_Tipos_error.html",
    "title": "5.7 ¿Qué tipos de error se pueden cometer en un contraste de hipótesis?",
    "section": "",
    "text": "Recordemos que se empieza suponiendo que las cosas son de una determinada forma, y que este planteamiento, normalmente conservador y relacionado con no cambiar, es lo que se denomina hipótesis nula. Esto será lo que creeremos a no ser que los datos lo contradigan, en cuyo caso consideraremos cierta la hipótesis alternativa (no pueden existir situaciones intermedias).\nPor ejemplo, una línea de envasado de detergente llena los paquetes con un peso que sigue una distribución N(4 kg; 0,03 kg). Para comprobar que todo marcha correctamente cada cierto tiempo se toma una muestra, supongamos que de \\(n=9\\) paquetes, y si su peso medio \\((\\bar{x})\\) está fuera de un intervalo previamente fijado –los llamados límites de control– se considera que el proceso está descentrado. En este caso la hipótesis nula es que el proceso está centrado (\\(H_0: \\mu = 4\\) kg) y la alternativa es que está descentrado (\\(H_1: \\mu \\ne 4\\) kg). El valor de la media de 9 paquetes con el proceso centrado se distribuye según N(4 kg; 0,03/\\(\\sqrt{9}\\) kg). Si los límites de control se fijan a ± 2 desviaciones típicas del valor nominal, la zona de rechazo será la que está fuera del intervalo 4,00 ± 0,02, tal como se indica en la figura 1.\n\n\n\n\n\n\nFigura 1: Zonas de rechazo y de no rechazo\n\n\n\nCon esta forma de decidir se pueden cometer dos tipos de error:\n\nRechazar la hipótesis nula cuando en realidad es cierta. En nuestro caso esto significa que aunque el proceso esté centrado, es posible que la media de la muestra esté fuera del intervalo (3,98; 4,02). La probabilidad de que esto ocurra, con nuestros números, es del orden del 5 % (exactamente 0,0455).\nNo rechazar la hipótesis nula cuando en realidad es falsa. Puede ser que la media muestral nos dé 4,01 en cuyo caso no rechazamos la hipótesis nula, pero el proceso podría estar centrado en \\(\\mu=4,02\\), o en \\(\\mu=4,03\\).\n\nAl primer tipo de error se le llama error tipo I, y al segundo, error tipo II. La verdad es que, aparte de utilizar números romanos, hay poca originalidad en la denominación.\nPodemos decidir la probabilidad de cometer el error tipo I fijando los límites a partir de los cuales se rechaza la hipótesis nula. Por ejemplo, si los límites los fijamos a \\(\\pm 3 \\sigma\\), la probabilidad de rechazarla equivocadamente será del orden del 3 por mil (exactamente 0,0027). Si queremos que esta probabilidad sea del 1 por mil, los límites deberán estar en 3,967 y 4,033. A la máxima probabilidad de rechazar equivocadamente la hipótesis nula se le denomina \\(\\alpha\\), y en función de ese valor se coloca la frontera entre la zona de aceptación y la de rechazo.\nVeamos ahora qué pasa con el error tipo II. La probabilidad de cometer este tipo de error no se puede calcular sin fijar un valor concreto para la hipótesis alternativa. Por ejemplo, si el proceso se descentra y pasa a llenar los paquetes con un peso medio de 4,03 kg, la probabilidad de que la media de una muestra de 9 paquetes esté dentro de los límites de control es de 0,1587. Luego existe una probabilidad del orden del 16 % de que consideremos que el proceso está centrado en su valor nominal, cuando en realidad lo está en \\(\\mu=4,03\\). A esta probabilidad de cometer el error tipo II se le denomina \\(\\beta\\).\n\n\n\n\n\n\nFigura 2: Zonas de rechazo y de no rechazo\n\n\n\nLa probabilidad \\(\\alpha\\) depende sólo de la regla de decisión (situación de los límites de control), mientras que la \\(\\beta\\) depende además del valor que tome la media \\(\\mu\\). Al valor \\(1-\\beta\\) se le denomina potencia de la prueba. Si representamos los valores de \\(1-\\beta\\) para los distintos valores posibles de \\(\\mu\\), obtenemos una curva que se conoce como “curva de potencia de la prueba”.\n¿Cómo disminuir la probabilidad \\(\\beta\\)? Una opción es aumentar \\(\\alpha\\). Si en nuestro caso los límites de control los ponemos a \\(\\pm 1\\sigma\\), la probabilidad \\(\\alpha\\) pasará a ser del orden del 32 %, pero para \\(\\mu =\\) 4,03 la probabilidad \\(\\beta\\) en vez de ser del 16 %, pasará a ser del 2,5 %.\n¿Y si queremos disminuir \\(\\alpha\\)? Si ponemos los límites a \\(\\pm 3\\sigma\\), \\(\\alpha\\) pasa a ser del 3 por mil, pero \\(\\beta\\), para $=$4,03, pasa a ser del 50 %.\n¿Es posible disminuir \\(\\alpha\\) y \\(\\beta\\) a la vez? Sí, aumentando el tamaño de la muestra. Si el tamaño de la muestra en vez de ser 9 fuera 25, la desviación típica de la media pasaría a ser \\(0,03/\\sqrt{25} =0,006\\). Una probabilidad \\(\\alpha\\) de 0,05 significa poner los límites a \\(\\pm 2 \\sigma\\), es decir a \\(4,00 \\pm 0,012\\). En este caso, si el proceso se descentra pasando a tener una media de 4,03 la probabilidad \\(\\beta\\) será prácticamente cero.\nDel trío \\(\\alpha\\), \\(\\beta\\) y \\(n\\), dados dos se puede deducir el tercero. Por ejemplo, si en nuestro caso queremos una probabilidad \\(\\alpha\\) del 5 % y una \\(\\beta\\) también de 5 % cuando la media se coloque en 4,03, el tamaño de la muestra debe ser n=13.\nEn definitiva, para un esfuerzo dado (esfuerzo = tamaño de muestra) si queremos reducir \\(\\alpha\\) debe ser a costa de \\(\\beta\\) y viceversa. Si se quieren reducir las dos a la vez no queda más remedio que hacer más esfuerzo (mayor tamaño de muestra). En este contexto también vale aquello de que “el que algo quiere algo le cuesta”.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.7 ¿Qué tipos de error se pueden cometer en un contraste de hipótesis?"
    ]
  },
  {
    "objectID": "0508_Significativa.html",
    "href": "0508_Significativa.html",
    "title": "5.8 ¿Es lo mismo diferencia significativa que diferencia importante?",
    "section": "",
    "text": "Aunque a veces se utiliza la palabra “significativo” para enfatizar la importancia o la relevancia de algo, en el contexto de los estudios estadísticos no es lo mismo significativo que importante. Una diferencia altamente significativa puede ser irrelevante a efectos prácticos, y también puede ocurrir que una diferencia importante no sea significativa.\nEn los procesos de soldadura por puntos se hace pasar una gran cantidad de corriente eléctrica (miles de amperios) durante un corto espacio de tiempo (milisegundos), pero suficiente para que las dos superficies metálicas se fundan en los puntos de contacto por el calor producido. Al fundirse se mezclan los materiales de las dos chapas y, al solidificarse esa mezcla, se forma lo que llamamos punto de soldadura.\nUn problema que se puede presentar en estos procesos está relacionado con el tratamiento superficial que se da a las chapas para que no se oxiden durante el periodo en que están almacenadas. Este tratamiento suele consistir en un recubrimiento con cierto producto (le llamaremos pintura) que no es tan buen conductor como el metal y dificulta el paso de la corriente, lo que puede repercutir en las propiedades del punto de soldadura.\nSe decide comparar la pintura habitual, A, con otra alternativa, B, que aseguran es más conductora y permite mejores soldaduras. Para realizar la comparación se llevan a cabo un cierto número de soldaduras en chapas pintadas con A, y otras en chapas pintadas con B. Lo que se mide es la resistencia a la cizalladura. Vamos a analizar cuáles serían nuestras conclusiones en dos situaciones con distintos resultados.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSituación 1\nSituación 2\n\n\n    Pint. A\nPint. B    \n    Pint. A\nPint. B    \n\n\n\n\nTamaño muestras:\nMedia:\nDesviación típica:\n    100\n    1750 kg\n    3,70 kg\n100  \n1752 kg  \n3,69 kg\n    10\n    1750 kg\n    169 kg\n10  \n1850 kg  \n193 kg\n\n\n\n\n\nSi los resultados son como los reflejados en la situación 1, la diferencia es claramente significativa, pero 2 kg sobre 1750 seguramente es una diferencia poco importante, y si cambiar de pintura entraña alguna dificultad o algún riesgo, por pequeño que sea, lo más probable es que no se cambie.\nEn la situación 2 la diferencia son 100 kg, lo cual ya puede ser una diferencia importante, al menos por comparación con el caso anterior. Pero ahora la diferencia no es significativa, es decir, puede ser debida al azar y no estaría justificado cambiar de pintura en base a estos resultados.\nObsérvese que hay dos características que tienen distinto orden de magnitud en ambas situaciones: el tamaño de las muestras y las desviaciones típicas. En la situación 1 (diferencia significativa) el tamaño de las muestras es grande, \\(n=100,\\) y la desviación típica es pequeña, \\(s_A=3.70\\) y \\(s_B=3.69\\), frente a la situación 2 (diferencia no significativa), en que el tamaño de las muestras es \\(n=10\\) y las desviaciones típicas son 169 y 193 kg. Tamaños de muestra grandes y con poca variabilidad permiten detectar diferencias muy pequeñas y quizá irrelevantes a efectos prácticos. Sin embargo, si los tamaños de muestra son pequeños y la variabilidad grande, no se ponen de manifiesto las diferencias aunque estas existan y sean importantes.\nPor tanto, hay que andarse con cuidado con la interpretación de lo que significa “diferencia significativa”, porque el hecho de que lo sea no significa que también sea relevante. Y que la diferencia salga no significativa no implica que no haya diferencia, es posible que el pequeño tamaño de muestra y/o la variabilidad que existe en los datos no nos deje ver esa diferencia que sí existe, y que además puede ser importante.",
    "crumbs": [
      "Contraste de hipótesis",
      "5.8 ¿Es lo mismo diferencia significativa que diferencia importante?"
    ]
  },
  {
    "objectID": "0509_Por2_cola_F.html",
    "href": "0509_Por2_cola_F.html",
    "title": "5.9 ¿Es correcto multiplicar por dos el área de la cola en los test de igualdad de varianzas?",
    "section": "",
    "text": "En este tipo de test el estadístico de prueba es el cociente de las varianzas muestrales y la distribución de referencia es la \\(F\\) de Snedecor, con los grados de libertad de las varianzas que hemos colocado en el numerador y el denominador, en este orden.\nComo la distribución \\(F\\) de Snedecor no es simétrica, parece que cuando la hipótesis alternativa es del tipo “distinto de” no se puede multiplicar por 2 el área de una de las colas, tal como hacemos en las distribuciones que son simétricas, como la Normal o la \\(t\\) de Student.\nPues bien, sí se puede multiplicar por 2 el área de cola también en este caso. Sean \\(s_A^2\\) y \\(s_B^2\\) las dos varianzas que queremos comparar, y supongamos que \\(s_A^2 &gt; s_B^2\\). El estadístico de prueba es el cociente de las dos varianzas, y podemos elegir tanto \\(s_A^2/s_B^2\\), como al revés, es decir su inversa \\(s_B^2/s_A^2\\).\nSi elegimos \\(s_A^2/s_B^2\\), como el numerador es mayor que el denominador, tendremos un cociente mayor que 1, y será tanto mayor cuanto mayor sea la diferencia entre varianzas. En este caso, tendremos que mirar el área de cola hacia la derecha en una distribución F de Snedecor con \\(\\nu_A\\) y \\(\\nu_B\\) grados de libertad.\nSi, por el contrario, elegimos \\(s_B^2/s_A^2\\) al ser \\(s_A^2 &gt; s_B^2\\) el cociente será menor que 1, tanto menor cuanto mayor sea la diferencia entre varianzas. En este caso, lo que interesa es la cola hacia la izquierda, pero no en la misma distribución que en el caso anterior, porque ahora se ha cambiado el orden de los grados de libertad.\nIntuitivamente parece razonable que si el cociente de varianzas (insistimos: nada se dice sobre el orden en que se colocan) sigue una distribución \\(F\\), las probabilidades \\(P(\\frac{s_A^2}{s_B^2}&gt;k)\\) y \\(P(\\frac{s_B^2}{s_A^2}&lt;\\frac{1}{k})\\) deben ser iguales. Esta igualdad viene resumida en la siguiente propiedad:\n\\[F_{\\nu_1, \\nu_2 (\\alpha)}=\\frac{1}{F_{\\nu_2, \\nu_1 (1-\\alpha)}}\\]\nDe aquí se deduce que las dos áreas son idénticas y que basta con calcular solo una y multiplicarla por 2. Como no es necesario mirar las dos áreas de cola, las tablas que vienen en los libros sólo dan colas hacia la derecha y el estadístico que se usa es el cociente de la varianza mayor entre la menor (cociente mayor que 1, área de cola hacia la derecha).\n\n\n\n\n\n\nFigura 1: Las dos áreas de cola en un test de igualdad de varianzas",
    "crumbs": [
      "Contraste de hipótesis",
      "5.9 ¿Es correcto multiplicar por dos el área de la cola en los test de igualdad de varianzas?"
    ]
  },
  {
    "objectID": "0505_Lado_cola.html#footnotes",
    "href": "0505_Lado_cola.html#footnotes",
    "title": "5.5 ¿Cómo se sabe hacia qué lado hay que mirar el área de cola?",
    "section": "",
    "text": "Entendemos que se cumplen las condiciones para poder aplicar el test de la t de Student.↩︎",
    "crumbs": [
      "Contraste de hipótesis",
      "5.5 ¿Cómo se sabe hacia qué lado hay que mirar el área de cola?"
    ]
  },
  {
    "objectID": "0601_FisicaQuimica.html",
    "href": "0601_FisicaQuimica.html",
    "title": "¿Cómo que diseño de experimentos? ¿no es eso de física o de química?",
    "section": "",
    "text": "Es verdad que experimentar suena más a tubos de ensayo y a laboratorios que a estadística, pero en estadística también hacemos experimentos. Los hacemos cuando queremos conocer cómo se comporta una variable –puede ser el rendimiento de una reacción química o el porcentaje de enfermos que se curan– en unas condiciones determinadas.\nCuando se realizan estudios estadísticos existen dos grandes formas de recoger los datos: por muestreo (valores al azar) y realizando experimentos.\nEn los procesos de producción el análisis de datos recogidos por muestreo se equipara a escuchar lo que nos dice el proceso. Pero si queremos saber qué ocurre al aumentar la temperatura o cambiar el catalizador, no podemos esperar que nos lo diga el proceso si siempre se trabaja a la misma temperatura y con el mismo catalizador. Hay que hacer pruebas y eso es como interrogar al proceso: ¿qué pasa si aumentamos la temperatura?\nEntre los diseños para lo que genéricamente se denomina “comparación de tratamientos” se encuentran aquellos que analizan si un medicamento es más eficaz que un placebo. En este caso hay que estar seguros de que las muestras, tanto del grupo de control que toma placebo como del grupo tratado con el medicamento, se han seleccionado de la forma adecuada y, desde luego, hay que cuidar los detalles para que no aparezcan sesgos en los resultados. Entre otras medidas para evitar esos sesgos, estas pruebas son de “doble ciego”: ni el paciente ni el médico que informa sobre sus resultados saben si se ha tomado el medicamente o el placebo.\nEn el ámbito de los procesos de producción siempre es complicado hacer pruebas, de manera que hay que pensarse muy bien la estrategia y las condiciones en que se van a realizar para obtener la máxima información con los recursos disponibles. Los llamados “diseños factoriales” son muy útiles para lograr este objetivo.\nEn definitiva, el diseño de experimentos tiene que ver con la recogida de datos en condiciones controladas, y es una de las partes más importantes de muchos estudios estadísticos.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Cómo que diseño de experimentos? ¿no es eso de física o de química?"
    ]
  },
  {
    "objectID": "0602_tStudent.html",
    "href": "0602_tStudent.html",
    "title": "¿Por qué no se usa el test de la t-Student para comparar más de dos tratamientos?",
    "section": "",
    "text": "Utilizar a fondo las técnicas disponibles es, desde luego, una buena idea, pero que no sirve para el caso que nos ocupa. No es lo mismo comparar todas las parejas de tratamientos que aplicar la técnica de análisis de la varianza. Vamos a verlo.\nSupongamos que tenemos muestras de 5 tratamientos: \\(A\\), \\(B\\), \\(C\\), \\(D\\) y \\(E\\). Podemos calcular las medias: \\(\\bar{y}_A\\), \\(\\;\\bar{y}_B\\), … y plantear para cada una de las 10 parejas que se pueden formar la hipótesis nula de que sus medias poblaciones son iguales frente a la alternativa de que son distintas.\nPareja 1: \\(\\;\\mu_A = \\mu_B\\;\\) frente a \\(\\;\\mu_A \\neq \\mu_B\\)\nPareja 2: \\(\\;\\mu_A = \\mu_C\\;\\) frente a \\(\\;\\mu_A \\neq \\mu_C\\)\n\\(\\cdots\\)\nPareja 10: \\(\\;\\mu_D = \\mu_E\\;\\) frente a \\(\\;\\mu_D \\neq \\mu_E\\)\nEstos 10 contrastes se pueden abordar construyendo los 10 intervalos de confianza para las diferencias de las medias poblacionales. Si no existen diferencias entre los tratamientos la probabilidad de que un intervalo incluya el cero y por tanto nos conduzca a la conclusión correcta es igual a su nivel de confianza, supongamos –por ejemplo– del 95 %.\n¿Qué pasa con el análisis conjunto? Al ser iguales todos los tratamientos, sólo llegaremos a la conclusión correcta en el caso de no rechazar ninguna de las hipótesis nulas. Si fueran independientes, la probabilidad de que esto ocurra será de \\(0,95^{10}=0,60\\).\nEl riesgo de rechazar “injustamente” la hipótesis nula aumenta al aumentar el número de tratamientos que se comparan de forma que los riesgos no son los que parecen a primera vista. Si las pruebas fueran independientes, para comparar \\(k\\) parejas con un nivel de confianza \\(c\\) global para toda la prueba, bastaría con calcular los intervalos individuales con un nivel de confianza \\(\\sqrt[c]{k}\\). Pero no se puede contar con la independencia ya que si un par de tratamientos presentan una diferencia significativa porque uno de ellos tiene la media anormalmente alta, esto aumenta la probabilidad de que otras diferencias aparezcan también como significativas.\nEl análisis de la varianza resuelve este problema al plantear un contraste de hipótesis conjunto sobre la igualdad de todas las medias frente a la alternativa de que alguna es distinta. Su punto débil es que cuando se rechaza la hipótesis nula no informa sobre cual o cuales son los tratamientos que deben considerarse distintos.\nUna buena forma de actuar es aplicar la técnica de análisis de la varianza y, si se rechaza la hipótesis de igualdad de medias, mirar los intervalos de confianza para identificar cuáles son distintas. También puede recurrirse a los denominados “test de comparaciones múltiples”, entre los cuales se encuentra el test de Tukey.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Por qué no se usa el test de la t-Student para comparar más de dos tratamientos?"
    ]
  },
  {
    "objectID": "0603_ANOVA_Medias.html",
    "href": "0603_ANOVA_Medias.html",
    "title": "¿Por qué se llama Análisis de la Varianza si lo que se compara son medias?",
    "section": "",
    "text": "No es por ganas de confundir. Supongamos que se desea comparar las medias de las muestras representadas en la figura 1.\n\n\n\n\n\n\nFigura 1: La diferencia de medias está clara\n\n\n\n¿Qué impresión nos da este gráfico? Estará de acuerdo que parece claro que B da un nivel de respuesta mayor que A o C, no apreciándose diferencias entre estos dos últimos.\nVeamos ahora otra situación. Supongamos que los valores obtenidos son los de la figura 2.\n\n\n\n\n\n\nFigura 2: La diferencia de medias está clara\n\n\n\n¿Qué opina sobre las diferencias en este caso? Ahora no está tan claro que sean significativas. Las tres muestras pueden provenir perfectamente de la misma población.\nVeamos ahora cuales son las medias en ambos casos:\n\n\n\n\n\nCaso 1\n\nCaso 2\n\n\nMuestra\nMedia\n\nMuestra\nMedia\n\n\n\n\nA\n13,73\n\nD\n13,73\n\n\nB\n15,71\n\nE\n15,71\n\n\nC\n14,00\n\nF\n14,00\n\n\n\n\n\n¡Las medias son idénticas! Entonces, ¿por qué las conclusiones han sido distintas?\nPorque, de una forma intuitiva, hemos comparado la variabilidad de los valores en cada muestra con las diferencias (es decir, también variabilidad) que presentan sus medias. En el primer caso, si las tres muestras provienen de la misma población, las diferencias entre sus medias son mayores de lo que cabe esperar a partir de la variabilidad observada dentro de cada muestra. En el segundo caso, la variabilidad dentro de las muestras es mucho mayor y por eso nos parece que la diferencia de medias es compatible con el hecho de que las tres provengan de la misma población.\nEn ambos casos hemos llegado a nuestras conclusiones sobre la igualdad de medias analizando variabilidades. Cuando la comparación se realiza analíticamente (en vez de gráficamente como hemos hecho nosotros) las variabilidades se miden a través de las varianzas. Lo que se hace es comparar varianzas. Por eso la técnica se llama Análisis de la Varianza.\n\\[\\bullet \\;\\;\\;\\; \\bullet \\;\\;\\;\\; \\bullet\\]\nLos valores representados son:\nSituación 1:\n\n\n\nA:\n13,7\n13,5\n13,2\n14,6\n14,4\n13,2\n14,0\n13,5\n13,7\n13,5\n\n\nB:\n15,2\n16,8\n16,5\n14,9\n15,5\n16,0\n16,0\n14,7\n16,3\n15,2\n\n\nC:\n14,6\n15,2\n13,8\n13,2\n13,5\n13,8\n14,3\n14,3\n13,8\n13,5\n\n\n\n\nSituación 2:\n\n\n\nA:\n14,9\n16,4\n14,2\n7,7\n11,8\n7,7\n17,4\n10,4\n20,3\n17,2\n\n\nB:\n14,4\n15,1\n12,2\n20,5\n10,5\n19,9\n23,0\n14,3\n10,8\n16,4\n\n\nC:\n11,4\n19,5\n10,7\n14,2\n14,8\n8,0\n21,2\n8,7\n21,8\n9,7",
    "crumbs": [
      "Diseño de experimentos",
      "¿Por qué se llama *Análisis de la Varianza* si lo que se compara son medias?"
    ]
  },
  {
    "objectID": "0604_No_UnaaUna.html",
    "href": "0604_No_UnaaUna.html",
    "title": "¿Por qué no hay que mover las variables una a una?",
    "section": "",
    "text": "Cuando se trata de estudiar experimentalmente como un conjunto de variables afectan a una respuesta parece que la mejor estrategia es fijar todas las variables menos una e ir moviendo esa no fijada hasta identificar con que valor se optimiza la respuesta. Después se sigue con la siguiente y así con todas, obteniendo de esta forma el valor más adecuado para cada una de ellas.\nVeamos gráficamente como funciona este procedimiento en un caso con solo dos variables. Se desea maximizar la cantidad de producto obtenido en una reacción química en la que intervienen dos variables que pueden resultar influyentes: la temperatura del reactor (habitualmente fijada a 130\\(^\\circ\\)C) y el tiempo de reacción (habitualmente 90 minutos); la cantidad que se obtiene en estas condiciones es de 70 gr.\nMantenemos fija la temperatura en su valor habitual y probamos distintos valores del tiempo, obteniéndose una cantidad máxima de 77 gr. cuando el tiempo es de 102 minutos. A continuación se fija el tiempo a 102 min. y se experimenta con diversos valores de la temperatura. La nueva cantidad máxima es de 92 gr. correspondiente a una temperatura de 141\\(^\\circ\\)C. Los resultados están representados en la figura 1.\n\n\n\n\n\n\nFigura 1: Representación gráfica de las variables y la respuesta\n\n\n\nAsí pues, una vez concluido el experimento, se ha conseguido aumentar la cantidad producida en 22 g. Pero, ¿hemos determinado realmente las condiciones óptimas de producción? En la figura 2 la cantidad obtenida está representada por curvas de nivel en función del tiempo y de la temperatura y se han representado también los puntos que corresponden a los experimentos anteriores. Es evidente que no se ha alcanzado el óptimo.\n\n\n\n\n\n\nFigura 2: Representación gráfica de las variables y la respuesta\n\n\n\nEste tipo de estrategia tiene la ventaja de que es fácil de entender y parece razonablemente buena (cuesta convencer a algunas personas de que hay alternativas mejores) pero tiene algunos inconvenientes que desaconsejan su uso:\n\nProporciona falsos óptimos, que pueden estar lejos del óptimo real dependiendo de donde se empiece la experimentación.\nEs una estrategia lenta de acercamiento al óptimo. Podríamos volver a determinar el tiempo que maximiza la respuesta para la nueva temperatura encontrada, y después hacer lo mismo con el tiempo, y así sucesivamente, trazando líneas sobre la superficie de respuesta, pero es evidente que este no es el camino más rápido para acercarse al óptimo.\nNo permite detectar interaccionesentre los factores, y esta es una limitación muy importante para entender como las variables afectan a la respuesta.\n\nPara estudiar a través de la experimentación como un conjunto de variables afectan a una respuesta, tenemos una alternativa mucho mejor. Son los diseños experimentales que conocemos con el nombre de diseños factoriales. A primera vista parecen un lío difícil de entender, pero cuando más se conocen más se aprecian. Si el tema le parece interesante y tiene la oportunidad, vale la pena dedicar un tiempo a conocerlos.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Por qué no hay que mover las variables una a una?"
    ]
  },
  {
    "objectID": "0605_Efecto_separado.html",
    "href": "0605_Efecto_separado.html",
    "title": "¿Cómo es posible estudiar por separado el efecto de cada variable?",
    "section": "",
    "text": "De entrada resulta chocante que para estudiar experimentalmente como un conjunto de variables afectan a una respuesta lo mejor sea moverlas todas a la vez realizando lo que se conoce como diseño factorial. Inmediatamente surgen dos pegas:\n\nUn diseño factorial exige experimentar en todas las combinaciones de valores de las variables y eso implica realizar muchos experimentos, tantos que seguramente esta estrategia no es viable.\nSi se mueven todas las variables a la vez no va a ser posible identificar cuáles de ellas son las que están produciendo los cambios en la respuesta.\n\nRespecto al primer punto, uno de los “trucos” es que en cada tanda de experimentación cada variable –le llamaremos factor– toma solo dos valores –niveles– distintos, de manera que si tenemos \\(k\\) factores el número de experimentos a realizar es \\(2^k\\). Esto no quiere decir que solo se pueda experimentar con dos valores de cada factor, en general el diseño consta de varias tandas y si en la primera vemos que al aumentar el valor de un factor mejora la respuesta, en la siguiente tanda podemos seguir explorando con nuevos valores. Claro que \\(2^k\\) también son muchos experimentos, pero este tipo de diseños permiten obtener la información más relevante haciendo solo una parte (fracción) del diseño completo, realizando lo que se denomina diseño fraccional.\nEntramos ya en el problema de interpretar los resultados si movemos todos los factores a la vez. Supongamos que tenemos tres factores: A, B y C y que a cada uno le asignamos dos valores que codificamos como \\(-1\\) y \\(+1\\). Habrá que realizar \\(2^3=8\\) experimentos. Las condiciones de experimentación y la respuesta (\\(y\\)) obtenida en cada caso son las que se indican en la siguiente.\n\n\n\n\n\n\n\n\n\n\n\nnº\nA\nB\nC\n\\(y\\)\n\n\n1  2  3  4  5  6  7  8 \n-1  1  -1  1  -1  1  -1  1\n-1  -1  1  1  -1  -1  1  1\n-1  -1 - 1  -1  1  1  1  1\n\\(y_1\\)  \\(y_2\\)  \\(y_3\\)  \\(y_4\\)  \\(y_5\\)  \\(y_6\\)  \\(y_7\\)  \\(y_8\\) \n\n\n\n\nEstos resultados se pueden representar en los vértices de un cubo tal como se indica en la figura 1, donde cada eje corresponde a un factor. Observe que la única diferencia entre las condiciones que dan la respuesta \\(y_5\\) y las que dan \\(y_1\\) es la debida al nivel del factor \\(C\\), no cambia nada más. Lo mismo ocurre con las diferencias entre \\(y_7\\) e \\(y_3\\), entre \\(y_8\\) e \\(y_4\\) y entre \\(y_6\\) e \\(y_2\\). Al promedio de esas cuatro diferencias se le denomina efecto principal del factor C. Ese mismo valor también se puede calcular como el promedio de respuestas con \\(C\\) a nivel \\(+\\) menos el promedio con \\(C\\) a nivel \\(-\\).\n\n\n\n\n\n\nFigura 1: Representación gráfica de las variables y la respuesta\n\n\n\nLo mismo ocurre con los otros factores, su efecto principal se calcula como el promedio de respuestas con el factor a nivel \\(+\\) menos el promedio a nivel \\(-\\) (figura 2).\n\n\n\n\n\n\nFigura 2: Representación gráfica de las variables y la respuesta\n\n\n\nObserve que se saca mucho jugo a las 8 respuestas obtenidas. Siempre usamos las 8 y depende de como se hagan los cálculos se mide el efecto de un factor o de otro. Naturalmente, esto no solo ocurre cuando se tienen tres factores. Con tres factores se puede representar fácilmente como hemos hecho nosotros, pero el procedimiento es el mismo para cualquier número de factores.\nY no todo queda aquí. Esta disposición de las condiciones de experimentación también permite calcular fácilmente las interacciones entre los factores, aspecto muy importante para entender el comportamiento de la respuesta y que es imposible analizar moviendo los factores uno a uno.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Cómo es posible estudiar por separado el efecto de cada variable?"
    ]
  },
  {
    "objectID": "0606_Ecuacion.html",
    "href": "0606_Ecuacion.html",
    "title": "¿Cómo se puede escribir una ecuación para la respuesta con los resultados de un diseño factorial?",
    "section": "",
    "text": "Observación interesante\nSupongamos que tenemos un circuito como el de la figura 1 y deseamos conocer cuál es la intensidad (I) que circula en función del valor de la resistencia (R) y de la fuente de alimentación (V). En un caso como este la relación es perfectamente conocida, se trata de la ley de Ohm: \\(I=V/R\\).\nPero supongamos que no conocemos esa relación y queremos deducirla a través de la experimentación1. Consideremos que nuestra zona de interés se encuentra en valores de entre 6 y 9 voltios para el voltaje y de entre 2 y 4 ohmios para la resistencia, siendo razonable la aproximación lineal entre esos valores. En este caso bastará con realizar un diseño \\(2^2\\) en el que, ignorando la existencia del error experimental, se obtendrían los resultados que se indican a continuación:\nUsando un paquete de software estadístico para calcular los efectos o, en un caso tan sencillo, también a mano, se obtiene: \\[ \\text{Media}=2,8125\\;\\;\\;\\; V=1,125 \\;\\;\\;\\; R=-1,875 \\;\\;\\;\\;  VR = -0,375 \\]\nLos efectos indican cuanto cambia la respuesta al pasar el factor del nivel –1 al +1, por tanto, el cambio al aumentar en 2 unidades –codificadas– el valor del factor. Sin embargo, los coeficientes de una ecuación de regresión indican cuanto cambia la respuesta al aumentar en una unidad la variable regresora.\nLa ecuación para explicar el comportamiento de la respuesta se escribe colocando el valor medio como constante y corrigiendo esa media general con el valor de los factores (el subíndice C indica que están codificados con los valores –1 y +1) acompañados de unos coeficientes que son los valores de los efectos divididos por 2. En nuestro caso la ecuación tendrá la forma:\n\\[ I = \\text{Media} + \\frac{\\text{Efec. ppal. }V}{2}V_C +  \\frac{\\text{Efec. ppal. }R}{2}R_C + \\frac{\\text{Interac.}VR}{2}V_C R_C \\]\nY sustituyendo queda: \\[ I = 2,8125+0,5625V_C - 0,9375R_C - 0,1875V_CR_C \\]\nPero, tal como se ha comentado, en esta ecuación los valores de \\(V\\) y \\(R\\) deben introducirse codificados ya que al calcular los efectos se ha considerado que los valores tanto para \\(V\\) como \\(R\\) eran –1 y +1, sin tomar en consideración a qué valores (en voltios y en ohmios) corresponden esos niveles.\nAsí, si queremos saber cuál será el valor de la intensidad para \\(V=9V\\) y \\(R=2\\Omega\\), deberemos sustituir \\(V_C\\) por +1 (9\\(V\\) es el nivel + de esta variable) y \\(R_C\\) por –1 (2\\(\\Omega\\) es el nivel – para \\(R\\)), obteniendo: \\[\\begin{equation*}\n    \\begin{split}\n        I &= 2,8125 + 0,5625(+1) - 0,9375(-1) - 0,1875(+1)(-1)\\\\\n        I &= 4,5\n    \\end{split}\n\\end{equation*}\\]\nPara tener la ecuación en las unidades originales de \\(V\\) y \\(R\\) es necesario decodificarlas, para ello usamos la expresión: \\[ X_C = -1 + 2 \\left( \\frac{X-X_{(-)}}{X_{(+)}-X_{(-)}} \\right) \\] Siendo \\(X\\) el valor de la variable sin codificar y \\(X_{(+)}\\), \\(X_{(-)}\\) sus niveles alto y bajo respectivamente. Aplicando esta transformación a nuestro modelo, tenemos:\nY operando se llega a: \\[ I = \\frac{3}{4}V-\\frac{1}{8}VR \\]\nEl modelo es una aproximación a la realidad. La figura 2 compara la superficie que corresponde a la relación real (curvada) junto con la obtenida a través del diseño \\(2^2\\) que es una superficie plana apoyada en las 4 esquinas de la superficie real.\n¿Qué ocurriría si en vez de la resistencia se mide la conductancia (su inversa: \\(G = 1/R\\))? Ahora la fórmula es \\(I = V \\cdot G\\), y la tabla de resultados de la experimentación será:\nObteniéndose los efectos: \\[ \\text{Media}=2,8125\\;\\;\\;\\; V=1,125 \\;\\;\\;\\; G=1,875 \\;\\;\\;\\;  VG = 0,375 \\]\nY a partir de los efectos podemos escribir el modelo: \\[ I = 2,8125 + 0,5625V_C + 0,9375G_C + 0,1875 V_CG_C \\]\nSiendo ahora la expresión con las variables originales: \\[\\begin{equation*}\n    \\begin{split}\n        I = 2,8125 &+ 0,5625 \\left[-1+2 \\left( \\frac{V-6}{3} \\right) \\right] \\\\\n        &- 0,9375 \\left[-1+2 \\left( \\frac{G-0,25}{0,25} \\right) \\right] \\\\\n        &- 0,1875 \\left[-1+2 \\left( \\frac{V-6}{3} \\right) \\right] \\left[-1+2 \\left( \\frac{G-0,25}{0,25} \\right) \\right]\n    \\end{split}\n\\end{equation*}\\]\nY esta expresión, después de operar y simplificar se reduce a:\n\\[I = VG \\]\nEn este caso el modelo obtenido coincide perfectamente con la realidad. Es interesante observar como la selección de una métrica adecuada para los factores (medir la conductancia en vez de la resistencia) influye de forma importante en la bondad del modelo obtenido.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Cómo se puede escribir una ecuación para la respuesta con los resultados de un diseño factorial?"
    ]
  },
  {
    "objectID": "0606_Ecuacion.html#footnotes",
    "href": "0606_Ecuacion.html#footnotes",
    "title": "¿Cómo se puede escribir una ecuación para la respuesta con los resultados de un diseño factorial?",
    "section": "",
    "text": "En general, mediante la experimentación no se pretende deducir la relación funcional exacta, sino una aproximación que resulte útil para cumplir los objetivos que se hayan planteado.↩︎",
    "crumbs": [
      "Diseño de experimentos",
      "¿Cómo se puede escribir una ecuación para la respuesta con los resultados de un diseño factorial?"
    ]
  },
  {
    "objectID": "0607_Bloqueo.html",
    "href": "0607_Bloqueo.html",
    "title": "¿Qué es un diseño bloqueado?",
    "section": "",
    "text": "Cuando se estudia la eficacia de una nueva vacuna, la muestra con que se realiza la prueba se divide en dos grupos: el llamado grupo de control, al que se aplica un placebo y el grupo tratado al que se aplica la vacuna.\nNaturalmente, es muy importante que los dos grupos sean lo más parecidos posible. No estaría bien poner en el grupo de control a las personas mayores y en el grupo tratado a los jóvenes porque si hay menos incidencia de la enfermedad en el grupo tratado no se sabrá si esa diferencia es debida a la vacuna o a la juventud. Cuando se estudia la influencia de un factor sobre una respuesta interesa que la única variable que cambie de un grupo a otro sea aquella cuyo efecto se desea estudiar. De esta forma, si existe diferencia entre grupos esta solo pueda ser atribuida al factor en estudio.\nPere no siempre es posible mantener fijas todas las variables ajenas a la experimentación y que pueden afectar a la respuesta. Si queremos analizar si dos aparatos para medir la tensión arterial dan el mismo resultado y tenemos 10 personas para realizar la prueba, no sería razonable medir la tensión a 5 de ellas con el aparato A y a las otras 5 con el B, porque –evidentemente– al valor obtenido le puede afectar el aparato pero seguro que también le afecta la tensión arterial de la persona. Sería más razonable medir la tensión a cada una con los dos aparatos y analizar las diferencias. La unidad dentro de la cual solo influye la variable en estudio se denomina bloque, en este caso cada persona es un bloque. El cómo hacer las mediciones no es un tema menor, no sería una buena idea tomar la presión siempre primero con el aparato A y después con el B. En general conviene aleatorizar dentro cada bloque teniendo lo que se llama un diseño en bloques aleatorizados.\nTambién cuando se realiza un diseño factorial puede ser difícil mantener fijas todas las variables ajenas a la experimentación y que pueden influir sobre la respuesta. Supongamos que deseamos estudiar como 3 factores afectan a una respuesta realizando un diseño \\(2^3\\). Es necesario realizar 8 experimentos pero supongamos que solo pueden realizarse 4 al día y que entre el primer y el segundo día de experimentación pasa una semana. Quizá de una semana a otra cambia el estado de las máquinas, o de la materia prima o las condiciones ambientales y esas variables también podrían influir en la respuesta.\nEs posible seleccionar los 4 experimentos que se deben hacer en cada bloque de forma que se neutralice la influencia de los factores asociados al cambio de día. La mejor manera de hacerlo es tal como se indica en la figura 1. A la izquierda se tienen los resultados realizando todos los experimentos en condiciones homogéneas y a la derecha los resultados experimentando en dos bloques: las respuestas dentro de un círculo corresponden al día 1, y dentro de un cuadrado al día 2. Los cambios en las condiciones provocan que el día 2 la respuesta sea 10 unidades mayor, pero si calcula los efectos principales y las interacciones de dos factores (lo que realmente interesa) verá que son exactamente los mismos tanto en un caso como en otro.\n\n\n\n\n\n\nFigura 1: Diseño \\(2^3\\) bloquedo. Sin (izq.) y con (der.) efecto bloque\n\n\n\nEn resumen, cuando comparamos tratamientos o estudiamos como un conjunto de factores afectan a una respuesta, hay que estar seguros de que no están influyendo otros factores que no tenemos controlados. Se puede diseñar la recogida de los datos de forma que la influencia de esos factores quede neutralizada. Estos diseños se llaman bloqueados.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Qué es un diseño bloqueado?"
    ]
  },
  {
    "objectID": "0608_Interacciones.html",
    "href": "0608_Interacciones.html",
    "title": "¿Por qué se suponen no significativas las interacciones de tres o más factores?",
    "section": "",
    "text": "En primer lugar vamos a intentar ver geométricamente lo que significa una interacción de dos factores. La figura 1 (izq.) muestra la superficie \\(Z=1+X+Y\\). Si consideramos que \\(X\\) e \\(Y\\) son los factores y \\(Z\\) es la respuesta, esta será una situación en que los factores no interaccionan, es decir, el efecto de \\(X\\) sobre la respuesta no depende del valor de \\(Y\\) (ni el efecto de \\(Y\\) depende de \\(X\\)). En concreto, aumentar una unidad el valor de \\(X\\) aumenta también una unidad el valor de \\(Z\\), con idependencia del valor de \\(Y\\). La parte derecha de la figura (es el cubo de la izquierda visto por la cara X) muestra claramente como el efecto de \\(X\\) no depende de \\(Y\\), las pendientes de las rectas son todas iguales.\nVeamos ahora la ecuación de la superficie representada por \\(Z=1,5+2X+Y+1,5XY\\). En este caso \\(X\\) e \\(Y\\) sí que interaccionan, ya que el efecto de \\(X\\) sobre la respuesta depende del valor de \\(Y\\). Al pasar \\(X\\) de -1 a +1 crece más la respuesta cuando \\(Y\\) toma el valor +1 que cuando toma el –1.\nObsérvese que la existencia o no de interacción está relacionada con lo “retorcida” que es la superficie. Lo que ocurre cuando se tiene una interacción de tres factores interacción!de tres factores no es fácil representarlo gráficamente (tres factores más la respuesta exigirían cuatro dimensiones), pero la idea general es que cuanto mayor es el grado de las interacciones que hacen falta para describir una superficie, más irregular o “sofisticada” resulta ser.\nCuando en la práctica se explora una superficie de respuesta, no se espera que sea muy irregular por las siguientes razones:\nDe hecho, si no fuera por estas razones, la experimentación sería una técnica poco prometedora, ya que, como se dice en el texto de Box, Hunter y Hunter1: “… Esto es una suerte, ya que de lo contrario, hacer un mapa de una superficie llena de estalagmitas, o parecida al lomo de un erizo sería totalmente imposible con un número razonable de experimentos”.\nPor otra parte, mediante los diseños factoriales a dos niveles, lo que hacemos es buscar una aproximación a la relación funcional que liga los factores con la respuesta, del tipo de la que se obtendría al descomponer una función en serie de Taylor. No es que el modelo obtenido a través de la experimentación sea la descomposición en serie de Taylor de la función buscada, sino que es una aproximación del mismo tipo. Si estamos ante una función de las que esperamos encontrarnos en la práctica (suave, regular, sin grandes altibajos), la zona de experimentación se podrá aproximar razonablemente bien descomponiéndola en serie de Taylor hasta el término de las derivadas cruzadas de segundo orden, sin necesidad de utilizar los términos correspondientes a las derivadas cruzadas de tercer orden (equivalente a las interacciones de 3 factores) y menos aún términos de cuarto orden (interacciones de 4) o superiores.\nTampoco es que se dogmatice la no existencia de interacciones de 3 o más factores, pero como el número de experimentos a realizar siempre resulta escaso, vale la pena ser consciente de la importancia de cada uno de los efectos que es posible estimar y dedicar los esfuerzos sólo a aquellos que mejor ayudarán a explicar el comportamiento de la respuesta. Por suerte, las interacciones de 3 o más factores no suelen ser importantes.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Por qué se suponen no significativas las interacciones de tres o más factores?"
    ]
  },
  {
    "objectID": "0608_Interacciones.html#footnotes",
    "href": "0608_Interacciones.html#footnotes",
    "title": "¿Por qué se suponen no significativas las interacciones de tres o más factores?",
    "section": "",
    "text": "“Statistics for Experimenters’’, 1ª edición, pág. 300”↩︎",
    "crumbs": [
      "Diseño de experimentos",
      "¿Por qué se suponen no significativas las interacciones de tres o más factores?"
    ]
  },
  {
    "objectID": "0609_Aleatorizar.html",
    "href": "0609_Aleatorizar.html",
    "title": "¿Qué hacer si al aleatorizar aparece el orden estándar de la matriz de diseño?",
    "section": "",
    "text": "Siempre se insiste en que una cosa es el orden en que se presenta la matriz de diseño (relación de las condiciones en que se va a experimentar) y otra el orden en que se deben realizar los experimentos. La matriz de diseño se presenta en el llamado “orden estándar” tanto por sus ventajas a la hora de escribirlo (la regla de construcción es muy fácil) como por la comodidad de tener un orden establecido al que nos podemos referir sin tener que detallar cuales son las condiciones una a una.\n\n  \n\n\n\n\n\n\n\n\n\nOrden\nMatriz de diseño\nA         B         C\n\nRespuesta\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n-         -         -\n+         -         -\n-         +         -\n+         +         -\n-         -         +\n+         -         +\n-         +         +\n+         +         +\ny1\ny2\ny3\ny4\ny5\ny6\ny7\ny8\n\n\n\n\n\n\nPero realizar los experimentos en este orden tiene el inconveniente de que si la respuesta tiende a aumentar o a disminuir a medida que se van realizando, ya sea por razones vinculadas al sistema de medida, a la materia prima, a la maquinaria, o a lo que sea, como los efectos principales se calculan haciendo el promedio de respuestas con el factor a nivel + menos el promedio con el factor a nivel –, el efecto principal del factor situado en la última columna (el C en el caso de un \\(2^3\\)) será el promedio de la mitad de experimentos realizados al final menos la mitad de los realizados al principio, y al hacerlo de esta forma la influencia del orden puede llevarnos a conclusiones equivocadas. Para evitar este tipo de situaciones, aleatorizamos el orden de realización de los experimentos, y si el orden tuviera alguna influencia, esperamos que esta se difumine entre todos los efectos sin concentrarse en ninguno de forma especial.\nPlanteada la razón de la aleatorización surge la pregunta de qué ocurre si al aleatorizar el orden obtenido resulta ser el estándar. La respuesta es polémica. Vamos a comentarla bajo dos puntos de vista.\nAlgunas personas (les llamaremos “académicos”) consideran que el orden estándar es un orden como cualquier otro y no debería haber ninguna razón para rechazarlo. Si se tienen razones para sospechar que el orden afecta a la respuesta, lo que hay que hacer es bloquear el experimento y/o tomar las medidas adecuadas para que esa influencia no se presente. Además, esa influencia puede seguir cualquier patrón, y por tanto tampoco está justificado temerle más a unos (tendencias crecientes o decrecientes) que a otros.\nOtras personas (les llamaremos “prácticos”) opinan que si al aleatorizar sale el orden estándar lo mejor es volver a realizar la aleatorización. Porque aunque es verdad que la tendencia vinculada al orden puede ser de cualquier tipo, en el caso de que exista es más razonable considerar que sea monótona creciente o decreciente y en ese caso el orden estándar sale especialmente perjudicado. Además, es difícil explicar que el denostado orden estándar para realizar la experimentación es el que finalmente hay que llevar cabo. Consuela saber que las probabilidades de que esto ocurra son pocas. Exactamente 1 entre 40.320 en un diseño \\(2^3\\) y del orden de 1 entre 21 billones en un \\(2^4\\).\nQuizá en esta polémica conviene tener presente que la palabra “aleatorizar” se utiliza en estadística con dos significados distintos. Una cosa es aleatorizar la selección de una muestra que se va a considerar aleatoria, en cuyo caso esta es una condición crítica y hay que andarse con cuidado con los relajamientos, y otra cosa es aleatorizar el orden de realización de los experimentos. Aunque la palabra es la misma (quizá la más sacralizada de las que usamos en estadística) en el último caso se trata de una práctica del tipo “curarse en salud” de forma que su significado e implicaciones son distintas.",
    "crumbs": [
      "Diseño de experimentos",
      "¿Qué hacer si al aleatorizar aparece el orden estándar de la matriz de diseño?"
    ]
  },
  {
    "objectID": "0701_Formula_covarianza.html",
    "href": "0701_Formula_covarianza.html",
    "title": "¿Cómo se justifica la fórmula de la covarianza?",
    "section": "",
    "text": "La figura 1 muestra la relación entre dos variables \\(X\\) e \\(Y\\). En la derecha el diagrama se ha dividido en cuatro cuadrantes trazando una línea vertical que pasa por la media de los valores de \\(x\\) y una horizontal por la media de los valores de \\(y\\). A estos valores medios los designamos \\(\\bar{x}\\) e \\(\\bar{y}\\) respectivamente. Los cuadrantes van del I al IV en el sentido de las agujas del reloj.\n\n\n\n\n\n\nFigura 1: Diagrama de dispersión y distancia de cada coordenada a su valor medio para el cálculo de la covarianza\n\n\n\nEn todos los puntos del primer cuadrante la distancia \\(x - \\bar{x}\\) es positiva, ya que todos se encuentran a la derecha de \\(\\bar{x}\\). También será positiva la distancia \\(y - \\bar{y}\\) ya que todos están por encima de \\(\\bar{y}\\). Por tanto, el producto de ambas distancias \\((x - \\bar{x})(y - \\bar{y})\\) será positivo para todos los puntos que se hayan en el primer cuadrante.\nPara los del segundo cuadrante este producto es negativo ya que la distancia \\(x - \\bar{x}\\) sigue siendo positiva (todos los puntos se encuentran a la derecha de \\(\\bar{x}\\)), pero \\(y - \\bar{y}\\) será negativo (todos están por debajo de \\(\\bar{y}\\)).\nEn el tercer cuadrante el producto de las distancias es positivo porque ambas distancias son negativas y en el cuarto vuelve a ser negativo ya que \\(y - \\bar{y}\\) es positivo pero \\(x - \\bar{x}\\) es negativo.\nCon \\(n\\) puntos, la suma de todos estos productos será \\(\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})\\). Si la mayoría se encuentra en los cuadrantes I y III, tal como ocurre en la figura 1, el resultado del sumatorio será un valor positivo, mientras que si están en los cuadrantes II y IV el resultado será negativo. Si no existe ninguna relación entre \\(X\\) e \\(Y\\) los puntos se repartiran de forma más menos equilibrada, tendiendo a compensarse los productos positivos con los negativos y dando un resultado alrededor de cero.\nLa covarianza es el valor de ese sumatorio dividido por el número de puntos que intervienen en su cálculo, algo así como el promedio de los productos \\((x_i -\\bar {x})(y_i -\\bar {y})\\). Si nuestro interés no es conocer la covarianza de los datos disponibles, sino estimar su valor en la población, dividimos por \\(n-1\\) en vez de por \\(n\\), por la misma razón que lo hacemos cuando estimamos el valor de la varianza. Como lo habitual es esto último, escribimos la fórmula de la forma: \\[ \\widehat{\\text{Cov}}(X,Y) = \\frac{\\sum_{i=1}^{n} (x_i -\\bar {x})(y_i -\\bar {y})}{n-1} \\]\nLa covarianza tiene un gran protagonismo en el terreno de los modelos teóricos, pero apenas se usa para valorar la relación lineal en un conjunto de datos. Para este menester tiene el inconveniente de que su valor depende de las unidades utilizadas. Si se mide la covarianza entre el peso y la estatura se tendrá un valor distinto si la estatura se da en metros o en centímetros (100 veces mayor en este último caso) y también será distinta si los datos se presentan en unidades anglosajonas de pulgadas y libras, aunque el diagrama de dispersión tendrá el mismo aspecto en todos los casos. Además, para su valoración no tenemos ningún marco de referencia sobre lo que representa un valor grande o pequeño. Todos estos problemas quedan resueltos con el uso del coeficiente de correlación.\n\nCuriosidad:\nDados unos valores de \\(X\\), la máxima covarianza no se obtiene cuando los valores de \\(Y\\) se alinean según una recta. Por ejemplo, sean los valores de \\(X\\) = 1, 2, 3, 4 y 5, si los de \\(Y\\) son: 2, 4, 6, 8, y 10 (relación lineal perfecta) la covarianza entre \\(X\\) e \\(Y\\) es igual a 5 pero si sustuimos el último 10 por 15, la covarianza aumenta y pasa a valer 7,5. Esto no deja en muy buen lugar a la covarianza como medida de relación lineal.",
    "crumbs": [
      "Correlación y regresión",
      "¿Cómo se justifica la fórmula de la covarianza?"
    ]
  },
  {
    "objectID": "0702_Coef_correlacion.html",
    "href": "0702_Coef_correlacion.html",
    "title": "¿De dónde sale la fórmula del coeficiente de correlación?",
    "section": "",
    "text": "Simplemente se divide la expresión de la covarianza por el producto de las desviaciones típicas de las dos variables \\(X\\) e \\(Y\\). Es fácil comprobar que desaparecen los denominadores tanto de la covarianza como de las desviaciones típicas, quedando: \\[ r  = \\frac{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( y_i - \\bar{y} \\right ) }\n        {\\sqrt {\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2}  \\sqrt{\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 }} \\]\nCon esta sencilla transformación se resuelven los problemas de la covarianza: su valor ya no depende de las unidades usadas y además queda acotado entre -1 y 1 (correlación perfecta negativa y positiva repectivamente).\nQue desaparecen las unidades es evidente, puesto que en el numerador tenemos las mismas que en el denominador, pero ver que está acotado entre -1 y 1 exige una mirada más detenida.\nSi la correlación es perfecta todos los puntos estarán alineados según una recta, es decir: \\(y_i =a+bx_i\\). Además, seguro que1: \\(\\bar {y} =a+b \\bar{x}\\). Así pues, podemos escribir el numerador de la expresión de \\(r\\) de la forma:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( y_i - \\bar{y} \\right ) &= \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right ) \\left ( a+bx_i - (a+b\\bar{x}) \\right ) \\\\\n        &= \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )   b \\left ( x_i - \\bar{x} \\right ) = b \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2\n    \\end{split}\n\\end{equation*}\\]\nCon un razonamineto similar, en el denominador podemos escribir el término en que aparecen los valores \\(y_i\\) de la forma:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\sqrt{\\sum_{i=1}^n \\left ( y_i - \\bar{y} \\right )^2 } &= \\sqrt{\\sum_{i=1}^n \\left ( a+bx_i - ( a+b \\bar{x} ) \\right )^2 } =  b \\sqrt{ \\sum_{i=1}^n \\left ( x_i -  \\bar{x}  \\right )^2 } \\\\\n    \\end{split}\n\\end{equation*}\\]\nRecuperando el término correspondiente a los valores de \\(x\\), el denominador nos queda: \\[  \\sqrt {\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2} \\cdot b \\sqrt{\\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2 } = b \\sum_{i=1}^n \\left ( x_i - \\bar{x} \\right )^2 \\]\nIgual que el numerador, aunque con la diferencia de que su valor seguro que es positivo (proviene de un producto de desviaciones típicas) mientras que el valor de \\(b\\) en el numerador será positivo o negativo según sea el signo de la pendiente de la recta.\nAsí pues, si los puntos se alinean según una recta, el valor del coeficiente de correlación será -1 o 1 según la pendiente sea negativa o positiva.\nOtra forma de verlo, que además sirve para probar que \\(r\\) no puede estar fuera de ese intervalo, es usando la expresión del coeficiente de determinación \\(R^2\\): \\[R^2 = \\frac{\\sum_{i=1}^{n}( \\hat{y_i} - \\bar{y} ) ^2}{\\sum_{i=1}^{n}( y_i - \\bar{y})^2} \\]\nEste coeficiente solo puede variar entre 0 y 1. Es igual a 0 cuando los valores estimados \\(\\hat{y_i}\\) siguen una recta horizontal, es decir, cuando la predicción de \\(y\\) no depende del valor de \\(x\\), y es igual a 1 cuando la explicación es perfecta: todos los valores previstos \\(\\hat{y_i}\\) coinciden con sus correspondientes valores reales \\(y_i\\). En el numerador tenemos:\n\\[\\begin{equation*}\n    \\begin{split}\n         \\sum_{i=1}^{n}( \\hat{y_i} - \\bar{y} ) ^2 &=   \\sum_{i=1}^{n}( b_0 + b_1 x_i - \\bar{y} ) ^2 =  \\sum_{i=1}^{n}( \\bar{y} - b_1 \\bar{x}+ b_1 x_i - \\bar{y} ) ^2 \\\\\n        &=  b_1^2  \\sum_{i=1}^n \\left ( x_i -  \\bar{x} \\right )^2  \\\\\n    \\end{split}\n\\end{equation*}\\]\nSustituyendo el numerador de \\(R^2\\) por esta nueva expresión:\n\\[\\begin{equation*}\n    \\begin{split}\n        R^2 &= b_1^2  \\cdot \\frac{\\sum( x_i - \\bar{x} ) ^2}{\\sum( y_i - \\bar{y})^2} =\n        \\frac{\\left[ \\sum(x_i-\\bar{x})(y_i-\\bar{y}) \\right]^2}{\\left [\\sum (x_i- \\bar{x})^2 \\right]^2} \\cdot  \\frac{\\sum ( x_i - \\bar{x} ) ^2}{\\sum ( y_i - \\bar{y})^2} =\\\\[10pt]\n        &= \\left[ \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})} {\\sqrt{\\sum (x_i - \\bar{x})^2} \\sqrt{\\sum (y_i - \\bar{y})^2}} \\right] ^2 = r^2\\\\\n    \\end{split}\n\\end{equation*}\\]\nSi \\(R^2\\) puede variar entre 0 y 1, está claro que \\(r\\) solo puede hacerlo entre -1 y 1.",
    "crumbs": [
      "Correlación y regresión",
      "¿De dónde sale la fórmula del coeficiente de correlación?"
    ]
  },
  {
    "objectID": "0702_Coef_correlacion.html#footnotes",
    "href": "0702_Coef_correlacion.html#footnotes",
    "title": "¿De dónde sale la fórmula del coeficiente de correlación?",
    "section": "",
    "text": "Si todos los puntos están sobre la recta: \\(\\sum y_i = \\sum (a+bx_i) \\rightarrow n\\bar{y} = na + bn \\bar{x}\\)↩︎",
    "crumbs": [
      "Correlación y regresión",
      "¿De dónde sale la fórmula del coeficiente de correlación?"
    ]
  },
  {
    "objectID": "0703_Valores_criticos.html",
    "href": "0703_Valores_criticos.html",
    "title": "¿Cómo se calculan los valores críticos del coeficiente de correlación?",
    "section": "",
    "text": "El coeficiente de correlación \\(r\\) tiene su propia función densidad de probabilidad y con ella se pueden calcular los valores críticos que se desee. Sin embargo, seguramente por economía de cálculo, las primeras tablas se construyeron usando la distribución \\(t\\)-Student.\nDado un conjunto de \\(n\\) pares de valores de \\(X\\) e \\(Y\\), contrastar que el coeficiente de correlación (\\(\\rho\\)) entre esas variables es igual a cero es lo mismo que contrastar que es igual a cero la pendiente de la recta ajustada (\\(\\beta_1\\)). No tendría sentido -sería una contradicción- que los dos análisis dieran resultados distintos.\nSabemos que si \\(\\beta_1=0\\), el estadístico \\(T_0 = b_1/s_{b_1}\\) sigue una distribución \\(t\\)-Student con \\(n-2\\) grados de libertad. Pues bien, se puede demostrar que: \\[ \\frac{b_1}{s_{b_1}} = \\frac{r  \\sqrt{n-2}}{\\sqrt{1 - r^2}} \\]\nPor tanto, bajo la hipótesis de \\(\\beta_1=0\\), que es lo mismo que \\(\\rho = 0\\), tenemos que: \\[ \\frac{r  \\sqrt{n-2}}{\\sqrt{1 - r^2}} \\sim t\\text{-Student con $n-2$ grados de libertad} \\]\nYa podemos calcular valores críticos para \\(r\\). Es inmediato comprobar que para un tamaño de muestra \\(n\\) y un nivel de significación \\(\\alpha\\) (prueba bilateral) tenemos: \\[ r_ {\\alpha, n} = \\frac{t_{\\alpha/2, n-2}}{\\sqrt{n-2 + t_{\\alpha/2, n-2}^2}} \\]\nLa función densidad de probabilidad de \\(r\\) se puede obtener a partir de la de \\(t\\). Realizando el correspondiente cambio de variable se llega a la siguiente expresión: \\[ f(r \\mid \\rho =0) = \\frac{ \\Gamma \\left [\\frac{1}{2} (n-1) \\right ]} { \\Gamma \\left [\\frac{1}{2} (n-2) \\right ] \\sqrt{\\pi}\n} (1-r^2)^{\\frac{1}{2}(n-4)} \\]\nDonde el símbolo \\(\\Gamma\\) representa la función gamma de Euler. En general, las tablas presentan los valores críticos en función de los grados de libertad de la distribución \\(t\\)-Student usada para determinarlos, no en función de \\(n\\) que sería lo más cómodo y natural. Es una forma algo confusa, ya que el coeficiente de correlación no tiene asociado ningún tipo de grados de libertad. Que las tablas se presenten de esta forma es, sin duda, un vestigio del pasado. Bueno, ahora también lo son las tablas enteras.\n\n¿Cómo se llega a \\(\\frac{r  \\sqrt{n-2}}{\\sqrt{1 - r^2}}\\) a partir de \\(\\frac{b_1}{s_{b_1}}\\) ?\nPara aligerar la notación escribiremos los sumatorios sin límites, que siempre son desde \\(i=1\\) hasta \\(n\\). Tenemos: \\[b_1 = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2} \\hspace{20pt} \\text{y} \\hspace{20pt} r = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2} \\sqrt{\\sum(y_i-\\bar{y})^2}} \\]\nCombinando estas dos expresiones podemos escribir: \\[ b_1 = r \\frac{\\sqrt{\\sum(y_i-\\bar{y})^2}}{\\sqrt{\\sum(x_i-\\bar{x})^2}} \\]\nPor otro lado: \\[ s_{b_1} = \\sqrt{\\frac{s_R^2}{\\sum(x_i-\\bar{x})^2}} \\hspace{20pt} \\text{con} \\hspace{20pt} s_R^2 = \\frac{\\sum(y_i-\\hat{y_i})^2}{n-2}\\]\nEn el numerador de \\(s_R^2\\) sustituimos $ _i$ por $b_0 + b_1x_i $ y dentro de esta expresión \\(b_0\\) por $ {y} - b_1 {x} $: \\[\\begin{equation*}\n    \\begin{split}\n        \\sum(y_i-\\hat{y}_i)^2 &= \\sum \\left ( y_i - \\bar{y}  + b_1 \\bar{x} -b_1 x_i \\right )^2 = \\\\\n        &= \\sum \\left [ \\left ( y_i - \\bar{y} \\right ) - b_1 \\left (  x_i - \\bar{x} \\right ) \\right ]^2 = \\\\\n        &= \\sum \\left [ \\left ( y_i - \\bar{y} \\right )^2 - 2 b_1 \\left (  x_i - \\bar{x} \\right )  \\left( y_i - \\bar{y} \\right )   + b_1^2 \\left (  x_i - \\bar{x} \\right )^2 \\right ] \\\\\n    \\end{split}\n\\end{equation*}\\]\nEl tercer término de la expresión anterior lo podemos escribir de la forma: \\[\\begin{equation*}\n    \\begin{split}\n        \\sum  b_1^2 \\left (  x_i - \\bar{x} \\right )^2  &= b_1 \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2} \\sum(x_i-\\bar{x})^2 = \\\\\n        &= b_1 \\sum(x_i-\\bar{x})(y_i-\\bar{y}) \\\\\n    \\end{split}\n\\end{equation*}\\]\nPor tanto, nos queda: \\[\\begin{equation*}\n    \\begin{split}\n        \\sum (y_i-\\hat{y})^2 &= \\sum(y_i-\\bar{y})^2 - b_1 \\sum(x_i-\\bar{x})(y_i-\\bar{y}) \\\\\n        &=  \\sum(y_i-\\bar{y})^2 -  r \\frac{\\sqrt{\\sum(y_i-\\bar{y})^2}}{\\sqrt{\\sum(x_i-\\bar{x})^2}} \\sum(x_i-\\bar{x})(y_i-\\bar{y})  \\\\\n    \\end{split}\n\\end{equation*}\\]\nYa podemos volver a la expresión de \\(T_0\\). Para que no salgan expresiones muy grandes, usaremos la notación: \\[S_{XX} = \\sum(x_i-\\bar{x})^2;  \\hspace{10pt}  S_{YY} = \\sum(y_i-\\bar{y})^2; \\hspace{10pt}  S_{XY} = \\sum(x_i-\\bar{x})(y_i-\\bar{y}) \\]\ny como tanto el denominador de \\(b_1\\) como en el de \\(s_{b_1}\\) es igual a \\(\\sqrt{\\sum(x_i-\\bar{x})^2}\\), lo podemos eliminar y ya no lo escribimos:\n\\[\\begin{equation*}\n    \\begin{split}\n        T_0 = \\frac {r  \\sqrt {S_{YY}}}     \n        {\\sqrt {\\frac{S_{YY} - r \\frac{\\sqrt{S_{YY}}}{\\sqrt{S_{XX}}} S_{XY}}{n-2}}} &=  \n        r  \\sqrt {n-2} \\sqrt {\\frac { S_{YY}}     \n            {S_{YY} - r \\frac{\\sqrt{S_{YY}}}{\\sqrt{S_{XX}}} S_{XY}}} = \\\\\n        &= r  \\sqrt {n-2} \\sqrt {\\frac {\\sqrt{S_{YY}} }     \n            {\\sqrt{S_{YY}} - r \\frac{S_{XY}}{\\sqrt{S_{XX}}} }} =\\\\[5pt]\n        &= r  \\sqrt {n-2} \\sqrt {\\frac {1}     \n            {1 - r \\frac{S_{XY}}{\\sqrt{S_{XX}} \\sqrt{S_{YY}}} }} = \\\\[5pt]\n        &= r  \\sqrt {n-2} \\sqrt {\\frac {1} {1 - r^2}} = \\\\[5pt]\n        &= \\frac{r  \\sqrt{n-2}}{\\sqrt{1 - r^2}}  \\\\\n    \\end{split}\n\\end{equation*}\\]",
    "crumbs": [
      "Correlación y regresión",
      "¿Cómo se calculan los valores críticos del coeficiente de correlación?"
    ]
  },
  {
    "objectID": "0704_Tablas_CoefCorre.html",
    "href": "0704_Tablas_CoefCorre.html",
    "title": "¿Sirven las tablas del coeficiente de correlación si \\(X\\) e \\(Y\\) no son Normales?",
    "section": "",
    "text": "Las tablas se han construido identificando el contraste sobre el coeficiente de correlación con el que se realiza para la pendiente de la recta ajustada. Sabemos que para realizar este último contraste es necesario que los datos cumplan ciertas condiciones. Las hipótesis del modelo lineal exigen que \\(Y\\) siga una distribución Normal para cada valor de \\(X\\) (normalidad de los residuos) aunque en nuestro caso, como los valores críticos se determinan con \\(\\rho =0\\) (o \\(\\beta_1 =0\\), recta horizontal), basta con que \\(Y\\) sea Normal, sin necesidad de más concreción. Nada dicen esas hipótesis sobre la distribuición de \\(X\\) y de aquí ya se deduce una primera respuesta a la pregunta planteada: No es necesario que la variable \\(X\\) sea Normal.\nPero el coeficiente de correlación entre \\(X\\) e \\(Y\\) es el mismo que entre \\(Y\\) y \\(X\\), y si es significativo en un caso también lo será en el otro. No importa a qué variable se llame \\(X\\) y a cual se llame \\(Y\\). Por tanto, lo único necesario es que una de las dos sea Normal.\n¿Y que pasa si ninguna lo es? una forma rápida de verlo es simulando. En la figura 1 cada punto representa el percentil del 97,5% de 100.000 valores del coeficiente de correlación, cada uno de ellos obtenido de dos muestras aleatorias de las distribuciones y el tamaño que se indica. Cada una de estas simulaciones se ha repetido 25 veces y en el gráfico aparece una pequeña línea vertical en la media de los 25 valores obtenidos. Puede observarse que el valor medio se aleja del real si ninguna de las dos distribuciones es Normal. Esta diferencia disminuye al aumentar el tamaño de muestra, aunque si las distribuciones son muy asimétricas, la diferencia sigue siendo grande.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 1: Valores críticos obtenidos por simulación para \\(\\alpha=0,05\\) (prueba bilateral) para el tamaño (n) y las distribuciones que se indican (N: Normal, U: uniforme, Int: uniforme discreta, exp: exponencial). La línea vertical a trazos corresponde al valor exacto.\n\n\n\n\nCuriosidad:\nSean, por ejemplo, los puntos: (4; 3), (6; 8), (8; 12), (10; 10), (12; 12). La recta ajustada es: \\(y = 1+x\\). Si en vez de ajustar \\(y = f(x)\\) se ajusta \\(x=f(y)\\) ¿se obtendrá la ecuación resultante de despejar \\(x\\) en \\(y=f(x)\\), es decir: \\(x = -1 + y\\)? Si ajustamos \\(x=f(y)\\) obtendremos el mismo valor de \\(R^2\\) y también el mismo \\(p\\)-valor en el contraste de la pendiente, pero la ecuación será: \\(x=1,57+0,714x\\). No es lo mismo minimizar la suma de los cuadrados de los residuos medidos en dirección vertical que en dirección horizontal (esto último no son los residuos).",
    "crumbs": [
      "Correlación y regresión",
      "¿Sirven las tablas del coeficiente de correlación si $X$ e $Y$ no son Normales?"
    ]
  },
  {
    "objectID": "0705_Minimos_cuadrados.html",
    "href": "0705_Minimos_cuadrados.html",
    "title": "¿Por qué se utiliza el método de los mínimos cuadrados?",
    "section": "",
    "text": "Se trata de ajustar una nube de puntos a una ecuación del tipo \\(Y=b_0+b_1X\\). Llamamos residuo a la diferencia entre el valor real de \\(Y\\) y el valor estimado mediante la recta. Para el punto \\(i\\) el residuo será \\(r_i = Y_i - b_0 - b_1X_i\\).\nDecidir qué recta es la que mejor ajusta es decidir qué valores deben tener \\(b_0\\) y \\(b_1\\). Una opción es hacer que \\(b_0\\) y \\(b_1\\) tomen los valores que hagan que la suma de los residuos sea igual a cero, es decir, que se compensen los valores positivos (los puntos caen por encima de la recta) con los negativos (caen por debajo). Si tenemos \\(n\\) puntos (\\(i=1, 2,\\ldots, n\\)) esto sería: \\(\\sum Y_i - nb_0 - b_1 \\sum X_i = 0\\). No hay solución única y es fácil comprobar que esta idea no funciona.\nEn la figura 1 (izq.) hemos colocado 3 puntos y el ajuste que haríamos a ojo (método que también tiene sus ventajas). A la derecha tenemos esos mismos puntos con uno de los ajustes que se obtienen haciendo que la suma de los residuos sea igual a cero. Es evidente que este último es un mal ajuste.\n\n\n\n\n\n\nFigura 1: Ajuste a ojo y haciendo igual a cero la suma de los residuos\n\n\n\nOtra opción que parece razonable es minimizar la suma de los residuos en valor absoluto, pero este tipo de ajuste tampoco da los resultados esperados 2, izq.). El método que da mejores resultados –el que proporciona la recta que mejor se ajusta a la nube de puntos– es el que minimiza la suma de los cuadrados de los residuos (figura 2, der.). De ahí que el método de ajuste por excelencia sea el de los .\n\n\n\n\n\n\nFigura 2: Ajustes minimizando la suma de los residuos en valor absoluto (izq.) y la suma de sus cuadrados (der.)\n\n\n\nMuchos métodos estadísticos están relacionados con el análisis de los cuadrados de los residuos (el análisis de la varianza, por ejemplo). Sin embargo, tampoco es prudente despreciar otros criterios como el de minimizar la suma de su valor absoluto. Supongamos que tenemos los siguientes datos en los que se ha cometido un error al introducir uno de los valores de \\(Y\\).\n\n\n\n\nX\nY\n\n\n3  6  9  12  15\n6  5  4  13*  2\n\n\n\n\n*Es un error, debería ser 3\n\n\nEl modelo que se obtiene ajustando por el método de los mínimos cuadrados es \\(Y = 6\\) (es decir \\(Y=6+0X\\)) porque el valor anómalo tiene una gran influencia sobre la ecuación obtenida. Sin embargo, ajustándolo con el criterio de minimizar la suma de los residuos en valor absoluto se obtiene \\(Y = 7 - (1/3)X\\), que es el modelo que se obtendría si el valor erróneo se hubiera entrado correctamente.\n\n\n\n\n\n\nFigura 3: Ajustes minimizando la suma de los cuadrados de los residuos (izq.) y la suma de su valor absoluto (der.))\n\n\n\nCuando se tiene una sola variable regresora es fácil identificar estos puntos anómalos, pero cuando se tienen muchas puede no ser tan fácil hacerlo y criterios de ajuste como éste, robustos ante la presencia de valores anómalos, pueden ser contemplados aunque sólo sea como punto de vista complementario.\nEn general, las ventajas y desventajas de los dos criterios de ajuste son análogas a las que se han comentado al comparar la media y la mediana.",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué se utiliza el método de los mínimos cuadrados?"
    ]
  },
  {
    "objectID": "0706_Coef_VariablesAleatorias.html",
    "href": "0706_Coef_VariablesAleatorias.html",
    "title": "¿Por qué los coeficientes de una ecuación de regresión son variables aleatorias?",
    "section": "",
    "text": "Si usted coloca un conjunto de puntos en un plano, por ejemplo (2; 3), (4; 3), (6; 7) y (8; 7), de forma que aquí no hay variables aleatorias ni ningún tipo de variabilidad, obtendrá que la recta que mejor se ajusta a estos puntos es: \\(Y = 1 + 0,8X\\). Si los datos de partida son considerados números fijos, los coeficientes de la ecuación también lo son, y no hay más que decir. Pero esta no es la situación que nos planteamos cuando tratamos este tipo de problemas desde un punto de vista estadístico.\nLo veremos con un ejemplo. Entre la estatura y el peso hay una cierta relación, las personas más altas pesan más, en términos generales, que las más bajas, así que podríamos plantearnos hallar la ecuación que define esa tendencia al aumento de peso con la estatura. Naturalmente no podremos medir y pesar a todas las personas del mundo, sino que tomaremos una muestra, por ejemplo de 20 individuos, a los que mediremos su peso y estatura, y a partir de estos valores calcularemos la ecuación que andamos buscando.\nEstaremos de acuerdo en que si en vez de las personas elegidas hubiésemos tomado otras 20, la ecuación obtenida sería distinta. Esto es así porque dada una estatura, el peso no es fijo, sino una variable aleatoria que suponemos con distribución Normal. La figura 1 muestra 6 situaciones de este tipo, en las que las estaturas son valores que se han generado aleatoriamente de una N(170; 8) y los pesos se han calculado de la forma \\(Peso = Estatura - 100 + \\varepsilon\\), siendo \\(\\varepsilon\\) un número aleatorio tomado de una N(0; 5). Se ve claramente que aunque la relación es la misma, la variabilidad en el peso para una estatura dada, provoca que las rectas sean distintas.\n\n\n\n\n\n\nFigura 1: Seis situaciones de ajuste del peso en función de la estatura generadas aleatoriamente.\n\n\n\nSi \\(\\varepsilon\\) tiene unas ciertas propiedades, los coeficientes de la ecuación siguen una distribución Normal, con una media que coincide con el valor que se obtendría si se utilizaran los datos de toda la población (bonita propiedad) y una desviación típica que se puede calcular con base en la variabilidad de los residuos.\nEsto nos permite plantear pruebas de significación para los coeficientes (por ejemplo: ¿es la pendiente lo suficientemente distinta de cero para poder afirmar que existe relación entre \\(X\\) e \\(Y\\)?). También se pueden calcular intervalos de confianza para la media de \\(Y\\) dado un valor de \\(X\\) (en nuestro caso la media del peso dado un valor de la estatura). El valor medio del peso para una determinada estatura es el que cae en la recta, pero como esta recta no es única lo más adecuado es dar un intervalo, que estará relacionado con la superposición de todas las posibles rectas que se podrían calcular. Los libros explican que este intervalo es más estrecho en el centro, en nuestro caso en torno al punto (170; 70) y que se va ensanchando hacia los extremos. Esto se puede comprobar superponiendo los 6 gráficos de la figura 1, obteniéndose el resultado que se observa en la figura 2 (izq). Para verlo todavía más claro también lo hemos hecho superponiendo 50 situaciones similares a las descritas, obteniéndose la figura de la derecha.\n\n\n\n\n\n\nFigura 2: Superposición de los gráficos de la figura 1 (izq) y otros 50 similares (der.)\n\n\n\nEn definitiva, si a partir de una muestra ajustamos una recta para explicar la relación entre dos variables, \\(X\\) e \\(Y\\), la recta obtenida no se puede considerar fija y única para explicar la relación entre \\(X\\) e \\(Y\\), ya que si la muestra hubiera sido otra, la recta también sería otra. La buena noticia es que haciendo determinados supuestos sobre el comportamiento de esas variables se puede deducir cuales son las distribuciones teóricas a que pertenecen los coeficientes de la recta, y esto nos permite realizar pruebas de significación o calcular intervalos de confianza para los valores que tomarían si se hubiera utilizado toda la población.",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué los coeficientes de una ecuación de regresión son variables aleatorias?"
    ]
  },
  {
    "objectID": "0707_R2.html",
    "href": "0707_R2.html",
    "title": "¿Cómo se interpreta el valor de \\(R^2\\)",
    "section": "",
    "text": "A la vista de una ecuación de regresión es imposible saber si el ajuste es bueno, regular o malo, hace falta añadir alguna medida que informe de lo que se ha dado en llamar “bondad del ajuste”. También es verdad que si solo se tiene una variable regresora basta dar un vistazo a la nube de puntos para tener una idea de como es el ajuste, pero interesa una medida objetiva y que se pueda generalizar al caso de la regresión múltiple, donde los gráficos ya no son tan claros.\nComo la calidad del ajuste tiene que ver con la magnitud de los residuos (la distancia entre los puntos y la recta), una primera idea podría ser medirla a través de su suma, pero sumarlos ``tal cual’’ seguro que no funciona porque se compensan los positivos con los negativos. Este problema se puede resolver sumando los valores absolutos o elevando los residuos al cuadrado. Usaremos la suma del cuadrado de los residuos que –entre otras ventajas– está más alineada con nuestro criterio de considerar como mejor ajuste aquel que minimiza esta suma.\nEn la figura 1 se han representado en la izquierda los valores de la estatura y el peso de 5 personas y en la derecha se ha añadido la recta que mejor se ajusta a estos puntos indicando el valor del residuo que corresponde a cada uno.\n\n\n\n\n\n\nFigura 1: Valores de los residuos\n\n\n\nEn este caso la suma de los cuadrados de los residuos es \\(Q=16\\) ¿este es un valor grande o pequeño? Pues depende.\nDepende del número de puntos o, lo que es lo mismo, de la cantidad de residuos que se tengan. Este inconveniente se puede resolver calculando el valor \\(Q/n\\), siendo \\(n\\) el número de puntos. En nuestro ejemplo sería 15/5 = 3,2.\nPero hay otro problema: los residuos tienen unidades, las mismas que la variable respuesta, y si cambiamos las unidades cambia el valor de \\(Q\\). Anteriormente deberíamos haber puesto \\(Q=16 \\text{ kg}^2\\) y si en vez tener el peso en kilos lo tenemos en libras (1 libra = 0,4536 kg) el aspecto del gáfico será el mismo y el ajuste será igual de bueno, pero en este caso tendremos que \\(Q=77,77 \\text{ lb}^2\\) y \\(Q/n =15,55 \\text{ lb}^2\\).\nLo ideal es tener una medida que no dependa de las unidades y que esté acotada entre dos extremos, por ejemplo entre 0 y 1, de manera que valores próximos a 0 indiquen ajustes muy malos y próximos a 1 muy buenos. Lo que haremos será calcular el valor de \\(Q\\) ignorando la información que proporciona la variable \\(X\\) y también el que se obtiene utilizando esa información. Comparar esos dos valores nos dará una buena idea de la capacidad de \\(X\\) para explicar el comportamiento de \\(Y\\).\nSi en nuestro ejemplo solo tenemos los valores de los pesos y nos piden que estimemos el de un individuo tomado al azar, nuestra mejor opción será dar la media de los valores disponibles. Esta situación equivale al ajuste de una recta horizontal que pasa por el valor medio del peso (figura 2). La previsión del valor de \\(Y\\) siempre es su valor medio con independencia del valor de \\(X\\). En esta situación vamos a llamar \\(Q_Y\\) a la suma de los cuadrados de los residuos. En nuestro caso \\(Q_Y = 56\\).\nCuando ajustamos la recta de regresión evidentemente disminuye el valor de \\(Q_Y\\). En realidad, ajustamos la recta de manera que ese valor sea el mínimo posible. Gracias a disponer de los valores de \\(X\\) hemos logrado bajar el valor de \\(Q\\) de \\(Q_Y=56\\) a \\(Q_R=16\\). Usar \\(X\\) nos ha permitido reducir un \\(100 \\cdot (56-16)/56\\) = 71,43% la suma de los cuadrados de los residuos. Este es el valor de \\(R^2\\), que puede escribirse de la forma: \\[ R^2 = \\frac{Q_Y-Q_R}{Q_Y}\\]\n\n\n\n\n\n\nFigura 2: Residuos en un “ajuste” sin considerar los valores de la estatura.\n\n\n\nUna explicación gráfica se encuentra en la figura 3.\n\n\n\n\n\n\nFigura 3: Interpretación del valor de \\(R^2\\)",
    "crumbs": [
      "Correlación y regresión",
      "¿Cómo se interpreta el valor de $R^2$"
    ]
  },
  {
    "objectID": "0708_Recta_Origen_R2.html",
    "href": "0708_Recta_Origen_R2.html",
    "title": "¿Por qué cuando se ajusta la recta por el origen no se debe usar \\(R^2\\)",
    "section": "",
    "text": "Si se sabe que cuando \\(X=0\\) seguro que \\(Y=0\\) y además nuestros valores están en torno a esa zona, puede ser razonable forzar que la recta \\(y=b_0+b_1x\\) pase por el origen1. En este caso solo hay que calcular el valor de la pendiente \\(b_1\\). Deducir su expresión es muy fácil, solo hay que minimizar: \\(S = \\sum (y_i -b_1x_i)^2\\) y siguiendo el procedimiento habitual tenemos: \\[ \\frac{\\mathrm{d}S}{\\mathrm{d}b_1}  = \\frac{\\mathrm{d}(\\sum y_i^2-\\sum 2y_ib_1x_i+ \\sum b_1^2x_i^2)} {\\mathrm{d} b_1} = -2 \\sum x_iy_i +2 \\sum x_i^2b_1\\]\nEstá claro que la segunda derivada es positiva (es una suma de cuadrados) por lo que tendremos un mínimo. Igualando a cero y despejando el valor de \\(b_1\\) se obtiene: \\[ b_1 = \\frac{\\sum x_iy_i}{\\sum x_i^2} \\] Un aspecto singular de este caso es que el valor de \\(R^2\\) no es una buena medida de calidad del ajuste. El primer problema surge cuando nos ponemos a calcularlo. Sabemos que \\(R^2\\) mide la proporción en que se reduce la suma de los cuadrados de los residuos en la recta ajustada respecto a una recta que no usa la información de \\(X\\) y que es, por tanto, una recta horizontal (la estimación del valor de \\(Y\\) no depende del valor de \\(X\\)). En el caso de una recta ajustada sin restricciones está claro que la recta horizontal debe ser \\(y=\\bar{y}\\), de forma que la mejor estimación de \\(Y\\) sea su valor medio. En la figura 1 tenemos un ejemplo sencillo de cálculo de \\(R^2\\) en este caso.\nSi forzamos que la recta pase por el origen, para el cálculo de la suma de cuadrados en la recta horizontal (\\(Q_Y\\)) tenemos dos opciones:\n1. Usar \\(y=\\bar{y}\\), igual que en la recta sin restricciones. De entrada, a esta opción se le puede poner la pega de que nosotros queremos que la recta pase por el origen y parece razonable que la recta horizontal de referencia también pase por el origen. Ignorando este aspecto tenemos que \\(Q_Y\\) no cambia y sigue siendo igual a 56 mientras que \\(Q_R\\) es algo mayor (no puede ser de otra forma porque en la recta sin restricciones ese valor es el mínimo posible) y resulta ser igual a 16,56 (figura 1, derecha). Haciendo las operaciones nos queda \\(R^2 = 70,43\\) que aunque es algo menor que en la recta sin restricciones entendemos que corresponde a un mejor ajuste.\n2. Usar \\(y=0\\). Esta es una recta horizontal que pasa por el origen. Cumple la misma restricción que la recta que vamos a ajustar pero los residuos en este caso pueden ser muy grandes, por lo que la disminución que se consigue con la recta ajustada también va a ser grande y, por tanto, también lo será el valor de \\(R^2\\). En nuestro ejemplo tenemos que, calculado de esta forma \\(Q_Y = 461\\). El valor de \\(Q_R\\) no cambia, por lo que tenemos que \\(R^2=96,41\\) 2. Esto no tiene mucho sentido, aunque así lo presentan algunos paquetes de software estadístico y también Excel (versión 2019).\nCon independencia de la forma como se calcule, el valor de \\(R^2\\) cuando se fuerza que la recta pase por el origen no tiene las mismas propiedades que en el caso general ni sus valores son comparables. En particular, en el caso de la recta por el origen el valor de \\(R^2\\) no es el cuadrado del coeficiente de correlación entre \\(X\\) e \\(Y\\), como sí ocurre en el caso general. Lo mejor es no usar \\(R^2\\) en este caso y valorar la calidad del ajuste con otra medida, como la desviación típica de los residuos.",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué cuando se ajusta la recta por el origen no se debe usar $R^2$"
    ]
  },
  {
    "objectID": "0709_R2_ajustado.html",
    "href": "0709_R2_ajustado.html",
    "title": "¿Por qué hace falta el valor de R2 -ajustado si ya tenemos el de \\(R^2\\)?",
    "section": "",
    "text": "El coeficiente de determinación \\(R^2\\) es una excelente medida de bondad del ajuste en el ámbito de la regresión simple y también en el de la regresión múltiple cuando se comparan ajustes con el mismo número de variable regresoras. El problema que presenta \\(R^2\\) es que su valor aumenta siempre al añadir nuevas variables aunque estas no expliquen nada.\nSi usted ajusta un modelo para explicar el peso de las personas a partir de los datos de un conjunto de 50 individuos, puede empezar ajustando el peso en función de la estatura y obtendrá un determinado valor de \\(R^2\\), si añade una variable que no tiene nada que ver, como el dinero que cada uno lleva en el bolsillo ¿cómo cambiará \\(R^2\\)? Pues sí, aumentará. Y si añadimos el número de la casa donde vive cada uno volverá a aumentar, de manera que si lo que buscamos es un ajuste con el máximo valor de \\(R^2\\) vamos a acabar con un modelo grande y enredado lleno de variables que no explican absolutamente nada, y eso no nos interesa.\nHemos hablado de añadir nuevas variables, pero lo dicho también sirve si se añaden transformaciones de variables ya usadas. En la figura 1 tenemos 4 situaciones en las que 5 puntos son ajustados por un modelo lineal, cuadrático, cúbico y de cuarto grado.\n\n\n\n\n\n\nFigura 1: Diferentes ajustes a un conjunto de 5 puntos\n\n\n\nEn el último modelo ocurre una gran paradoja. Sin necesidad de conocer los datos se puede afirmar que el ajuste será perfecto, pues así como por dos puntos pasa una única recta, tres puntos se pueden ajustar perfectamente a un polinomio de segundo grado, cuatro puntos a uno de tercer grado, y cinco puntos a uno de grado cuatro. Siempre por \\(n+1\\) puntos pasará un polinomio de grado \\(n\\), y el ajuste será “perfecto” sin importar cuales sean los datos. Esto es un verdadero adefesio ya que este tipo de ecuaciones no tienen ningún poder de predicción, que es lo realmente importante.\nPara evitar este problema se ha corregido la definición de \\(R^2\\), dando origen al coeficiente de determinación ajustado. Simplemente se dividen las sumas de cuadrados por sus grados de libertad. Los grados de libertad de la \\(Q_R\\) son \\(n-p\\), y ese valor de \\(p\\) penaliza la incorporación de nuevas variables. \\[ R^2 = 1 - \\frac{Q_R}{Q_Y}\\;\\; \\rightarrow \\;\\; R_{\\text{Aj}}^2= 1 - \\frac{\\frac{Q_R}{n-p}}{\\frac{Q_Y}{n-1}} \\;\\; \\rightarrow \\;\\; R_{\\text{Aj}}^2= 1 - \\frac{s_R^2}{s_Y^2}\\] Cuando la relación \\(n/p\\) se hace grande, es decir que el número de datos supera mucho al número de parámetros, los dos coeficientes se acercan en sus valores. Si con \\(n=10\\) puntos se ajusta un polinomio de grado 8 (\\(p=9\\)) y resulta un coeficiente de determinación \\(R^2= 90\\%\\), podrá dar la falsa impresión de que estamos ante un buen modelo. Sin embargo, utilizando las fórmulas anteriores es fácil deducir que $R^2 =$0,1, es decir, nos indica que en esas condiciones el valor creíble del coeficiente de determinación es el 10 %. El ajuste es bastante pobre.\nSin embargo, supongamos ahora la misma situación anterior donde lo único que cambia es que se tienen \\(n=90\\) observaciones. En este caso tenemos \\(R^2\\text{-Aj} =0,89\\). Pasamos del 90 al 89 %, es decir que ha tenido muy poco cambio. Note que en esta ocasión se cumple la recomendación empírica de que haya 10 observaciones por cada parámetro, es decir, que la razón \\(n/p\\) valga por lo menos 10.\n\nBonus track\nUsted puede construir un modelo que explique perfectamente la cotización en bolsa de las 5 grandes empresas que desee. Tome esas las 5 cotizaciones de hoy (que serán las \\(Y\\)) seleccione ahora las temperaturas máximas de ayer en 5 capitales europeas (\\(X_1\\)), el tipo de cambio de las 5 monedas que usted elija frente al dólar (\\(X_2\\)), los precios de 5 materias primas en el mercado de Londres (\\(X_3\\)) y la temperatura media en Cali en los últimos 5 días (\\(X_4\\)). Obtenga el modelo que explica Y en función de \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_4\\). ¡Ajuste perfecto! Lástima que para hoy llega tarde, y para mañana es totalmente inútil.",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué hace falta el valor de R2 -ajustado si ya tenemos el de $R^2$?"
    ]
  },
  {
    "objectID": "0710_Variables_cualitativas.html",
    "href": "0710_Variables_cualitativas.html",
    "title": "¿Se pueden usar variables cualitativas en ecuaciones de regresión?",
    "section": "",
    "text": "Sí se puede, pero no como si fueran cuantitativas. Si queremos usar el día de la semana como variable explicativa y tenemos los días codificados como lunes = 1, martes = 2, …, es evidente que esta variable no se puede considerar así, ya que el modelo entendería que el domingo es 7 veces el lunes, cosa evidentemente falsa. Sin embargo sí hay forma de utilizar variables cualitativas.\nEn la siguiente tabla tenemos los datos correspondientes al peso, la estatura y el sexo de 20 individuos1. Se trata de encontrar una ecuación para explicar el peso en función de la estatura y el sexo.\nLo primero será echar un vistazo a los datos a través de un gráfico. En este caso basta con un diagrama bivariante usando distinto símbolo según el sexo (figura 1). Está claro que tanto la estatura como el sexo influyen en el peso.\nCuando tenemos una variable cualitativa que solo toma dos valores se puede introducir en el modelo codificándola con valores numéricos. Para facilitar la interpretación de los resultados lo mejor es codificar un valor como 0 y el otro como 1. En este caso convenimos: Mujer = 0 y Hombre = 1. Ajustando la ecuación de regresión se obtiene:\nDel resultado anterior se deduce que sí hay diferencias debido al sexo, ya que el coeficiente de esta variable es significativo. Sustituyéndola por sus valores 0 y 1, se obtienen los modelos específicos para mujeres y hombres:\nAsí de sencillo, pero ajustando el modelo de esta forma la pendiente de la recta siempre es la misma, tanto para mujeres como para hombres (figura 2). Esto es debido a que al cambiar el valor de la variable codificada solo cambia el intercepto \\(b_0\\).\nSi queremos que la pendiente de las rectas pueda ser distinta deberemos incluir en el modelo el producto de la variable cualitativa por las otras variables regresoras (en este caso sólo la altura). De esta forma se obtiene la siguiente ecuación:\nLa significación del término Altura*Sexo pone de manifiesto la diferencia en las pendientes de las rectas. Los modelos que se obtienen en este caso son:\nEn la figura 3} tenemos su representación gráfica. Seguro que ahora nos quedamos más tranquilos con los ajustes obtenidos.\n¿Y si la variable cualitativa tiene más de dos valores distintos? La regla general es que una variable cualitativa con $ k $ valores debe sustituirse por $ k-1 $ variables binarias que toman valores 0 y 1. En el caso de la variable “día de la semana”, como \\(k=7\\) habrá que sustituirla por 6 variables binarias tal como se indica en la siguiente tabla.\nSi el número de observaciones de que se dispone no da para estimar con solvencia tantos coeficientes, una opción podría ser usar los días clasificados solo como laborables y festivos. De esta forma el análisis es más sencillo y la presentación de los resultados se puede realizar de forma más clara y compacta, lo cual también es importante.",
    "crumbs": [
      "Correlación y regresión",
      "¿Se pueden usar variables cualitativas en ecuaciones de regresión?"
    ]
  },
  {
    "objectID": "0711_Varibles_Modelo.html",
    "href": "0711_Varibles_Modelo.html",
    "title": "¿Por qué las variables que se incluyen en el modelo no necesariamente son las más correlacionadas con la respuesta?",
    "section": "",
    "text": "Es muy fácil de entender con un ejemplo. Suponga que tiene que presentarse al examen de una asignatura cuyo programa consta de 100 temas y resulta que usted no sabe ninguno. Pero no todo está perdido, las reglas de este examen dicen que usted puede llevar compañeros de clase como asesores y, además, puestos a suponer, supondremos que usted sabe qué temas conoce cada uno de sus compañeros.\nSi pudiera llevar un solo asesor ¿a cuál elegiría? La respuesta es fácil: al que más temas sepa. Supongamos que ese es Pablo, que sabe 85 temas.\nA la hora de elegir el segundo, una opción que parece razonable es elegir al segundo que más sabe, por ejemplo, Alberto, que sabe 75 temas. El problema de esta estrategia es que puede ocurrir que los 75 temas de Alberto ya estén incluidos entre los 85 que sabe Pablo y, por tanto, que Alberto no aporte nada cuando ya se cuenta con Pablo.\nUna estrategia mejor para seleccionar al segundo es buscar el que más sabe pero no de todo el temario, sino de lo que le falta por saber al primero. Seguro que el lector estará de acuerdo con nosotros. Incluso puede ocurrir que en la mejor pareja de asesores no esté el que más sabe, ya que pueden haber dos que se complementen perfectamente, de modo que uno sepa 55 temas y el otro los 45 restantes, mientras que el que más sabe no se complemente bien con ningún otro.\nEl símil con la obtención del modelo de regresión está claro. La primera variable en ser elegida es la más correlacionada con la respuesta \\(Y\\), es decir, la que mejor explica su comportamiento. Pero la segunda no necesariamente será la segunda más correlacionada con \\(Y\\), ya que lo que explica esta quizá ya lo explicaba la primera. Una vez seleccionada una variable el criterio es: seleccionar la que mejor explica lo que falta por explicar.\nTambién hará falta que cumpla con otros requisitos, como que una vez en el modelo su coeficiente supere un cierto nivel de significación. La selección y el descarte de variables siguiendo estos criterios lo resuelven muy bien los paquetes de software estadístico utilizando la estrategia de selección de modelos denominada “paso a paso” (“Stepwise”).\nLos paquestes de software estadístico también permiten identificar el modelo que interesa a base de fuerza bruta. Se trata de la estrategia que denominan “Best subsets”. Simplemente se trata de calcular todos los modelos posibles junto a sus medidas de calidad del ajuste y presentar la lista de los mejores para que el usuario elija. El problema es que si entre las variables candidatas las hay que están muy correlacionadas entre ellas esta estrategia no funciona porque el algoritmo se atasca cuando quiere colocar a dos de esas en un modelo, mientras que el Stepwise esquiva bien esas situaciones. Otro problema para la fuerza bruta es tener muchas variables candidatas. Si \\(k\\) es el número de esas variables, el número de modelos posibles es \\(2^k\\) de forma que crece de forma exponencial con el número de variables consideradas. A partir de \\(k=30\\) el tiempo de computación es muy alto y los programas que conocemos no dejan que se sobrepase ese valor.",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué las variables que se incluyen en el modelo no necesariamente son las más correlacionadas con la respuesta?"
    ]
  },
  {
    "objectID": "0801_Logaritmo.html",
    "href": "0801_Logaritmo.html",
    "title": "Cuando se habla de transformación logarítmica ¿se refiere al logaritmo decimal o al neperiano?",
    "section": "",
    "text": "Si el objetivo que se pretende es la normalidad de los datos o la homogeneidad de su varianza, es indiferente cual sea la base de la transformación logarítmica.\nRecordemos que \\(z\\) es el logaritmo en base \\(a\\) de \\(y\\) si \\(a^z=y\\). En el caso del logaritmo neperiano la base es el famoso número \\(e\\) y tenemos: \\[\\ln(y) = x \\qquad  \\Leftrightarrow \\qquad e^x = y\\]\nComparemos ahora el \\(\\ln(y)\\), con el logaritmo en cualquier otra base, por ejemplo en base 10. Tenemos:\n\\[x=\\ln(y) \\qquad \\;\\, \\Leftrightarrow \\qquad e^x = y\\] \\[z=\\log_{10}(y) \\qquad  \\Leftrightarrow \\qquad 10^z = y\\]\nPor tanto, podemos escribir: \\[\\begin{equation*}\n    \\begin{split}\n        e^x &=10^z\\\\\n        \\ln(e^x)&= \\ln(10^z)\\\\\n        x &= \\ln(10^z) = z\\ln(10)\n    \\end{split}\n\\end{equation*}\\]\nComo \\(x\\) es el nombre que hemos dado a \\(\\ln(y)\\), el \\(\\ln(10)\\) es una constante igual a 2,3026 y \\(z\\) es el nombre asignado a \\(\\log_{10}(y)\\), tenemos: \\[\\ln(y)=z\\ln(10)=2,3026z=2,3026\\log_{10}(y)\\]\nEs decir que el logaritmo neperiano se convierte en logaritmo en base 10 al multiplicarlo por una constante, lo cual significa que si al aplicar una transformación con logaritmo neperiano se logra la distribución Normal o la homogeneidad de varianza, idéntico efecto surte la aplicación del logaritmo en cualquier otra base, en particular en base 10.",
    "crumbs": [
      "Miscelánea",
      "Cuando se habla de transformación logarítmica ¿se refiere al logaritmo decimal o al neperiano?"
    ]
  },
  {
    "objectID": "0802_TCL.html",
    "href": "0802_TCL.html",
    "title": "¿Debe decirse “Teorema central del límite” o “Teorema del límite central”?",
    "section": "",
    "text": "Lo central, en el sentido de clave o fundamental, es el teorema, no el límite que es como todos los límites. Debe decirse, por tanto, “Teorema central del límite” y no de la otra forma.\n¿Y por qué este teorema es central en la teoría estadística?\nCuando se tiene la suerte de enfrentar un fenómeno cuya característica de interés se puede modelar con una distribución Normal, heredamos de inmediato un arsenal de resultados útiles para la estimación de los parámetros y para hacer contraste de hipótesis. Si la aplicación de toda esa valiosa teoría dependiera de la suerte de toparse con variables de distribución Normal, su aplicación quedaría bastante restringida en la solución de problemas reales, pues existe también un amplio abanico de fenómenos en la naturaleza que no se ajustan a la distribución Normal.\nLo que le da un potente valor agregado a la batería de resultados de la inferencia estadística basada en la ley Normal es saber que gran parte de dicho conocimiento es útil, aun cuando la característica de estudio no se pueda modelar con esta distribución. Esto se justifica precisamente con el teorema a que estamos haciendo referencia, pues demuestra que es plausible modelar la variable aleatoria media muestral por medio de la distribución Normal, aun cuando la población madre de donde se extrae la muestra tenga otra distribución distinta de la Normal, exigiendo para su aplicación un conjunto no muy fuerte de condiciones que pueden hacerse cumplir en la práctica.\nHay pocos resultados tan importantes como este, por eso se trata de un teorema central en la teoría estadística y, disculpe que insistamos, el calificativo “central” no indica que esté en el centro de nada, como no debe estar necesariamente en el centro la estación central en una ciudad o el banco central en un país.",
    "crumbs": [
      "Miscelánea",
      "¿Debe decirse “Teorema central del límite” o “Teorema del límite central”?"
    ]
  },
  {
    "objectID": "0803_Grados_libertad.html",
    "href": "0803_Grados_libertad.html",
    "title": "¿Qué significan los llamados “grados de libertad”?",
    "section": "",
    "text": "Aunque el concepto de grados de libertad está muy presente en los métodos estadísticos, los libros de texto no suelen entrar en él con mucho detalle, quizá porque hacerlo implica meterse en el terreno de la geometría vectorial que complica las cosas y se aparta de los objetivos de un curso general de estadística. Nosotros, siguiendo con la intuición como principal arma, vamos a presentarlo primero desde un punto de vista geométrico para después pasar al contexto estadístico.\n\nVisión geométrica\nSi le piden que elija un par de números \\((x, y)\\) totalmente al azar, usted tiene libertad completa para su elección. Esos números pueden considerarse las coordenadas de un punto localizado en el plano \\(XY\\), el cual es un espacio bidimensional. El punto es libre de moverse en ambas direcciones, tiene dos grados de libertad.\nAhora supongamos que nos ponen a elegir un par de números cuya suma sea igual a 7. Está claro que sólo podemos elegir libremente uno de ellos, pues el segundo queda fijado una vez se conozca el primero. Aunque aquí también hay dos variables, sólo una es independiente, por lo que el número de grados de libertad se reduce de dos a uno. El punto ahora es libre de moverse en el plano \\(XY\\) pero restringido a permanecer sobre la recta \\(x+y=7\\). Esta línea es un espacio unidimensional que está contenido en el espacio bidimensional original.\nSupongamos ahora que nos piden escoger un par de números, tal que la suma de sus cuadrados sea 25. De nuevo, está claro que sólo somos libres de escoger uno de los números, pues una vez seleccionemos el primero el otro queda fijado. El punto en cuestión permanece en una circunferencia de radio 5 y con centro en el origen. La circunferencia también es un espacio unidimensional contenido en un plano bidimensional. El punto solo puede moverse hacia delante o hacia atrás a lo largo de la circunferencia y por eso tiene un solo grado de libertad. Hay dos números escogidos (\\(N = 2\\)) sujetos a una restricción (\\(r = 1\\)) y el número resultante de grados de libertad es \\(N-r=2-1=1\\).\nSupongamos ahora que imponemos simultáneamente las dos condiciones \\(x+y=7\\) y también \\(x^2+y^2=25\\). Si nosotros resolvemos algebraicamente estas ecuaciones, obtenemos que sólo son posibles dos soluciones \\(x=3\\), \\(y=4\\) o bien \\(x=4\\), \\(y=3\\). Ninguna variable puede escogerse a voluntad. El punto está restringido por la ecuación \\(x+y=7\\) a moverse a lo largo de una recta y además está restringido por la ecuación \\(x^2+y^2=25\\) a moverse a lo largo de una circunferencia. Las dos restricciones simultaneas lo confinan a la intersección entre la recta y la circunferencia, dejándolo sin libertad de movimiento, es decir sin grados de libertad.\nEstas ideas se pueden generalizar para \\(N&gt;2\\), de forma que cualquier conjunto de \\(N\\) números determinan un punto en el espacio \\(N\\)-dimensional. Si no se impone ninguna restricción, cada número es libre de variar independientemente de los otros y por lo tanto el número de grados de libertad es \\(N\\). Cada relación impuesta sobre ellos reduce el número de grados de libertad en 1. Cualquier ecuación de primer grado que conecte las \\(N\\) variables es un espacio de \\(N-1\\) dimensiones. Si por ejemplo, consideramos solamente los puntos cuya suma de coordenadas es una constante, \\(\\sum x_i=c\\), hemos limitado el punto a un espacio de \\(N-1\\) dimensiones.\nTambién una muestra de tamaño \\(N\\), a la que no se ha impuesto ninguna restricción, puede ser representada por un punto \\((X_1, X_2, X_3,\\, \\dotsi, X_N)\\) en un espacio \\(N\\)-dimensional con \\(N\\) grados de libertad. Ahora bien, si forzamos que su media sea \\(\\bar{X}\\) ya tenemos una restricción y, por tanto, \\(N-1\\) grados de libertad. Todas las muestras de tamaño \\(N\\) con la misma media \\(\\bar{X}\\), estarán representadas por los puntos que pertenecen al hiperplano \\(\\sum X_i=N\\bar{X}\\), que es un espacio de (\\(N-1\\)) dimensiones.\n\n\nGrados de libertad en la varianza muestral\nSeguramente las primeras reflexiones sobre la idea de grados de libertad en el contexto de la estadística surgen cuando queremos explicar por qué para calcular la varianza muestral se recomienda dividir por \\(n-1\\), en lugar de dividir por \\(n\\), siendo este es el número total de datos que componen la muestra.\nSabemos que la suma de las desviaciones de los datos con respecto a su media es siempre nula, es decir que \\(\\sum_{i=1}^n (x_i - \\bar{x})=0\\). Esto significa que de los \\(n\\) sumandos que tiene el numerador de la varianza solo \\(n-1\\) son independientes, es decir, sólo podemos “inventarnos” \\(n-1\\) si queremos que los \\(n\\) tengan la media definida.\nPor esta razón, aunque la varianza se ha calculado a partir de \\(n\\) datos, es importante el hecho de que estos tengan sólo \\(n-1\\) grados de libertad, ya que para obtener un estimador insesgado de la varianza poblacional, debemos dividir la suma de cuadrados por el número de sus grados de libertad, y no por el número de datos.\n\n\nGrados de libertad en las ecuaciones de regresión\nVeamos ahora que ocurre en el caso de querer ajustar una línea recta a un conjunto de puntos usando el método de los mínimos cuadrados. La familia de modelos a considerar es de la forma \\(y_i = \\beta_0+\\beta_1x_i+\\varepsilon_i\\) y de entre todas las posibles rectas, queremos aquella con coeficientes \\(b_0\\), \\(b_1\\) que haga mínima la suma de los cuadrados de los residuos \\(SCR\\). Para esto se realiza un proceso de optimización matemática, obteniéndose que dichos valores \\(b_0\\), \\(b_1\\) deben cumplir con las siguientes restricciones: \\[\\begin{equation*}\n    \\begin{split}\n        e_1+e_2+e_3+ \\dotsi + e_{n-1}+e_n &= 0 \\\\\n        e_1x_1 + e_2x_2 +e_3x_3 + \\dotsi + e_{n-1}x_{n-1}+e_nx_n &= 0\n    \\end{split}\n\\end{equation*}\\]\nLa primera restricción quita un grado de libertad a los residuos, ya que conocidos cualesquiera \\(n-1\\) queda unívocamente definido el enésimo. Además, esto implica que la recta debe pasar por el punto \\((\\bar{x}, \\bar{y})\\).\nPodemos imaginarnos que las posibilidades se restringen a un haz de rectas que pasan por \\((\\bar{x}\\), \\(\\bar{y})\\), pero de todas ellas escogeremos aquella que cumpla con la segunda restricción, con lo cual el error pierde otro grado de libertad, quedando con \\(n-2\\).\nEs conveniente saber que \\(SCR/(n-2)\\) es un estimador insesgado de la varianza del error \\(\\sigma^2\\) y que, en general, para un modelo de regresión múltiple con $ p $ parámetros (\\(p-1\\) variables predictoras), el número de grados de libertad de los residuos es \\((n-p)\\) y por lo tanto \\(SCR/(n-p)\\) es también un estimador insesgado para la varianza del error.\n\n\nGeneralización del concepto de grados de libertad\nUna definición formal de grados de libertad, muy orientada a su cálculo podría ser: ``Número de unidades independientes de información en una muestra, que son relevantes para la estimación de un parámetro o para el cálculo de un estadístico’’.\nEn el ejemplo del estadístico ``varianza’’ existe una sola restricción por lo que los grados de libertad se reducen a \\(n-1\\), y el número de unidades de información que consideramos a efectos de la estimación de la varianza poblacional son \\(n-1\\). De la misma forma, en un modelo de regresión con \\(n\\) puntos y \\(p\\) parámetros los residuos tienen \\(n-p\\) grados de libertad, por lo que en la estimación de la varianza de los errores \\(\\sigma^2\\) tenemos \\(n-p\\) unidades independientes de información y dividimos la suma de cuadrados por \\(n-p\\).\nEl número de grados de libertad también forma parte de la descripción de algunas distribuciones de probabilidad, que toman esta característica de su relación con ciertos estadísticos. Así, por ejemplo, si \\(X \\sim N(\\mu; \\sigma)\\) y \\(S\\) es un estimador de \\(\\sigma\\) calculado a partir de una muestra con \\(n-1\\) grados de libertad, entonces la variable \\((X-\\mu)/S\\) se distribuye según una \\(t\\) de Student con \\(n-1\\) grados de libertad (los de \\(S\\)). Para describir la variabilidad que presenta la varianza muestral \\(S^2\\) utilizamos la distribución Chi-cuadrado también con \\(n-1\\) grados de libertad (los de \\(S^2\\)). Finalmente, si tenemos dos muestras de tamaños \\(n_1\\) y \\(n_2\\) de una población Normal, el cociente \\(S_1^2/S_2^2\\) sigue una distribución \\(F\\) de Snedecor con \\(n_1-1\\) (los de la varianza del numerador) y \\(n_2-1\\) (los de la varianza del denominador) grados de libertad.",
    "crumbs": [
      "Miscelánea",
      "¿Qué significan los llamados “grados de libertad”?"
    ]
  },
  {
    "objectID": "0804_Loteria.html",
    "href": "0804_Loteria.html",
    "title": "¿Cuál es la mejor estrategia para que me toque la lotería?",
    "section": "",
    "text": "Si nos referimos sólo a juegos de azar, esos que se basan en la extracción de bolas de un bombo, esta pregunta no tiene respuesta, ya que no existe tal estrategia. Y es una lástima, porque a muchos les habrá parecido que esta era la pregunta más interesante del libro.\nPero por no hacer esta respuesta demasiado corta, haremos algunas consideraciones sobre los sorteos en que se compra un boleto con un número y sobre aquellos en los que se elige una combinación de 6 entre los números del 1 al 49 o similares.\n\nBoleto de lotería con un número\nSupongamos que los números disponibles son del 0 al 99.999 y que el número premiado se elige al azar. Es evidente que si todos tienen la misma probabilidad de salir aquí no hay táctica que valga. Sin embargo, existen algunas falacias bastante extendidas que podemos comentar. Por ejemplo:\n\nSi se compra en determinados lugares (ciudades, puntos de venta) es más fácil que toque que si se compra en otros. Los que mantienen esta postura la avalan con datos: En ese lugar que ellos dicen que da más premios, efectivamente en los últimos años ha dado muchos más que en ese otro donde es muy difícil que toque. La clave está en distinguir el número de premios de la probabilidad de que toque. El número de premios que caen en un lugar depende del número de boletos que se han vendido. Por eso, a la larga, tocan más premios en las ciudades grandes que en las pequeñas, pero esto no implica que tengamos más posibilidades de que nos toque si compramos el número en una ciudad grande. Las probabilidades son exactamente las mismas. Respecto a los puntos de venta, si en uno de ellos toca algún premio importante y se crea el clima de opinión de que allí es más fácil que toque, la gente irá más a comprar a ese lugar y, al venderse más, efectivamente aumenta la probabilidad de toque, aunque para el que compra la probabilidad no cambia en absoluto tanto si lo compra allí como en cualquier otro lugar.\nHay números “feos” que no hay que comprar porque nunca tocan. Si a alguien le ofrecen el número 01010 es posible que no lo quiera porque este es un número raro y le parecerá muy difícil que toque. Preferirá el 34.278 que es mucho más normal. Después resulta que toca un número como el 47.121, lo cual confirma la teoría de que los números que salen son normales, aunque, lamentablemente, no el “normal” que habíamos comprado. ¿Por qué toca muy pocas veces en números raros? Pues simplemente porque números raros hay pocos (ver al final). Visto de otra forma: ¿Por qué es más probable que toque fuera del intervalo 30.000–35.000 que dentro? Pues simplemente porque fuera hay más números que dentro, pero esto no hace que menospreciemos los números dentro de ese intervalo. Lo mismo ocurre con los números raros.\n\nConsejos: Si compra lotería hágalo cerca de su casa o donde le pille más a mano. Se ahorrará tiempo, gastos de desplazamiento, y quizá el disgusto de comprobar que ha tocado en el punto de venta de su calle y usted lo fue a comprar a otra ciudad. Y no rechace los números raros, especialmente si los ha visto y se va a acordar del número.\n\n\nElegir 6 números del 1 al 49 (o similar)\nEste es un juego muy popular en todo el mundo. Se conoce con diversos nombres como Lotería primitiva, Lotto, Loto 6/49, …. Hay premio a partir de 3 aciertos. Las probabilidades de acertar son (ver al final):\n\n\n\n\n\nNúmero de aciertos\nProbabilidad\n\n\n\n\n3\n1 en 56\n\n\n4\n1 en 1032\n\n\n5\n1 en 55.491\n\n\n5 + Complementario\n1 en 2.330.636\n\n\n6\n1 en 13.983.816\n\n\n\n\n\nAlgunas creencias sin fundamento:\n\nHay que apostar a los números que han salido menos, ya que como la probabilidad es la misma para todos y a la larga su frecuencia de aparición tiende a igualarse, será más probable que salgan los que menos han salido. Es verdad que a la larga las frecuencias de aparición tienden a igualarse, de la misma forma que si lanzamos muchas veces una moneda al aire, cuantas más veces la lancemos más cerca estará del 50 % la proporción de caras y cruces. Pero esto no quiere decir que después de 5 caras sea más probable que salga una cruz, la probabilidad siempre es constante para ambos resultados y de la misma forma ocurre con los números que salen en este tipo de sorteos. Los bombos no tienen memoria, y no saben lo que ha salido antes. Ni memoria ni sentimientos de justicia o igualdad. Simplemente las probabilidades son las mismas en todos los sorteos, independientemente de lo que haya salido en los sorteos anteriores.\nHay que apostar por los números que más salen, puesto que esos, por las razones que sean, son los que han demostrado tener más probabilidad de salir. Lo verdaderamente sorprendente sería que todos los números hubieran salido exactamente el mismo número de veces. Lo normal es que, por azar, unos hayan salido más y otros menos. Pero no hay ninguna razón para pensar que los que han salido más hasta ahora vayan a seguir saliendo más. Por la misma razón que antes las probabilidades son idénticas en cada sorteo.\nExisten estrategias que con ayuda de un ordenador permiten elaborar combinaciones múltiples que aumentan las probabilidades de ganar. Es posible incluso garantizar que se tendrá algún premio si se realiza un cierto número de apuestas adecuadamente seleccionadas. Pero si por ganar se entiende tener beneficios (premio – coste del juego), la tendencia es que cuanto más se juega más se pierde, con independencia de la estrategia que se siga. En otro tipo de apuestas, en las que el resultado no depende sólo del azar, como las quinielas de fútbol, sí pueden existir estrategias para aumentar la probabilidad de beneficio.\n\nConsejos: Aunque la probabilidad de que una combinación toque es la misma para todas ellas, cuanto mayor sea la cantidad a repartir más dinero ganará si le toca, por lo que tiene más emoción jugar cuando hay mucho dinero acumulado de otras semanas en las que no hubo ningún acertante. Por otra parte, como el premio se reparte entre los acertantes, parece una buena idea apostar por una combinación rara ya que tiene las mismas probabilidades de salir que cualquier otra y si nos toca probablemente seremos los únicos acertantes y cobraremos más dinero. Lo que es una combinación rara no está muy claro, y seguramente también depende de la disposición de los números en el boleto. En fin, marque los números que se le antojen o, todavía más cómodo, que los marque la máquina, y espere a ver si ha habido suerte, con la seguridad de que nadie ha usado una estrategia mejor que la suya.\n\\[ \\bullet \\;\\;\\;\\;\\; \\bullet \\;\\;\\;\\;\\; \\bullet \\]\n\nNúmeros raros: si por raro entendemos un número con sólo 1 ó 2 cifras distintas (por ejemplo, el 22.222 o el 22.552), números en los que aparece sólo una cifra tenemos 10 (00.000, 11.111, \\(\\dotsi\\), 99.999) y números en los que aparecen 2 cifras, si tenemos 4 iguales y una distinta, son: \\(10 \\cdot 9 \\cdot 5\\) (10 posibilidades para el primero, 9 para el segundo y 5 formas posibles de ordenarlos). Si tenemos 3 iguales por un lado y 2 iguales por otro: \\(10 \\cdot 9 \\cdot \\frac{5!}{2! \\cdot 3!}=900\\). Es decir que con este criterio, números raros hay 10 + 450 + 900 = 1.360 entre 100.000.\nProbabilidad de acertar en lotería 6/49 Para calcular estas probabilidades podemos usar la regla de casos favorables partido por casos posibles. Los casos posibles, es decir, las formas de elegir 6 números de un conjunto de 49 son las combinaciones de 49 tomados de 6 en 6, que notamos \\(\\binom{49}{6}\\). Los casos favorables para acertar 3 es el producto de los casos en que se pueden elegir los 3 que se aciertan de entre los 6 premiados \\(\\binom{6}{3}\\) por los casos en que se pueden elegir los 3 que no se aciertan de entre los 43 no premiados \\(\\binom{43}{3}\\). El resultado para la probabilidad de acertar 3 es: \\(\\binom{6}{3} \\cdot \\binom{43}{3} / \\binom{49}{6}\\) = 0,0176504. Análogamente, para 4 aciertos la probabilidad es \\(\\binom{6}{4} \\cdot \\binom{43}{2} / \\binom{49}{6}\\) = 0,0009686. La probabilidad de acertar 5, sin el número complementario, es \\(\\binom{6}{5} \\cdot \\binom{42}{1} / \\binom{49}{6}\\) = 0,0000180 (en el numerador aparece 42 porque el número no premiado se elige de entre los no premiados menos el complementario). La probabilidad de acertar 5 más el complementario es \\(\\binom{6}{5} / \\binom{49}{6}\\)= 0,0000004, ya que hay una sola forma de elegir el complementario. Y finalmente, la probabilidad de acertar los 6 es una entre todas las combinaciones posibles, es decir: \\(1 / \\binom{49}{6}\\) = 1 entre 14 millones, aproximadamente.",
    "crumbs": [
      "Miscelánea",
      "¿Cuál es la mejor estrategia para que me toque la lotería?"
    ]
  },
  {
    "objectID": "0805_Rojo_Negro.html",
    "href": "0805_Rojo_Negro.html",
    "title": "Acaba de salir 5 veces el rojo ¿debo apostar al negro?",
    "section": "",
    "text": "Respecto a las probabilidades de ganar en la ruleta, nos cuesta quitarnos de encima esa idea de que si la proporción de veces que la bola cae en rojo y en negro se va igualando a medida que se lanzan bolas, si han salido muchas negras seguidas, en las próximas tiradas deben aparecer más rojas que negras para que se cumpla la ley establecida.\nPero es bien sabido que ni las bolas ni la ruleta tienen memoria, lo que sí puede ocurrir es que la ruleta esté desequilibrada. Se pueden dar dos situaciones:\n\nLa ruleta está desequilibrada. Es posible que por alguna razón la ruleta no esté perfectamente equilibrada y la bola tenga tendencia a caer con más frecuencia en el rojo.\nLa ruleta está equilibrada. En este caso la probabilidad de que caiga en el rojo o en el negro es exactamente la misma.\n\nEn el primer caso habría que apostar al rojo y en el segundo es indiferente apostar a rojo o negro. Si aparece una racha de un color es más razonable apostar por ese color que por el otro. Si estamos en el caso 1 nuestra probabilidad de ganar será algo mayor y si estamos en el caso 2 será la misma.\nPor otra parte, las rachas de un mismo color son más habituales de lo que parece incluso estando la ruleta perfectamente equilibrada. Supongamos que una ruleta funciona 6 horas al día y se realiza un lanzamiento cada minuto, es decir, 360 lanzamientos por jornada. Hemos simulado los lanzamientos de 1000 jornadas y nos hemos fijado en la aparición de rachas. Los resultados están en la siguiente tabla:\n\n\n\n\n\n\n\n\n\nLongitud\nde la racha\nDías que ocurre\n(sobre 1000)\n\n\n\n\n5\n1000\n\n\n6\n998\n\n\n7\n937\n\n\n8\n755\n\n\n9\n492\n\n\n10\n304\n\n\n11\n159\n\n\n12\n73\n\n\n13\n50\n\n\n14\n22\n\n\n15\n13\n\n\n16\n7\n\n\n\n\n\nRachas de 5, 6 y hasta 7 veces el mismo color aparecen en casi todas las jornadas (en más de 900). Aproximadamente en la mitad de las jornadas aparecen rachas de 9 y una vez de cada 100 (esto sería 3 o 4 veces al año) aparecen rachas de hasta 15 o 16 veces seguidas el mismo color. Si en un casino hay 10 ruletas esas rachas tan largas se verán aproximadamente cada 10 días.\nPor tanto, lo raro es que no aparezcan rachas. Que aparezcan con la frecuencia prevista lo explica el azar y en ese caso no hay ninguna señal que nos ayude a tomar una mejor decisión.",
    "crumbs": [
      "Miscelánea",
      "Acaba de salir 5 veces el rojo ¿debo apostar al negro?"
    ]
  },
  {
    "objectID": "0806_Como_se_dice.html",
    "href": "0806_Como_se_dice.html",
    "title": "¿Cómo se dice? ¿Qué significa?",
    "section": "",
    "text": "En torno a la media\nCuando hablamos de la media solemos referirnos al valor medio de un conjunto de valores (la nota media de una asignatura) pero también puede ser un valor puramente teórico referido a una distribución de probabilidad (jugando a una determinada loteria se pierde una media de 30 céntimos por cada boleto que se compra). En el primer caso también se puede hablar de promedio y en el segundo de esperanza matemática.\n\n\n¿Varianza o variancia?\nLas dos son correctas y ambas aparecen en el diccionario de la RAE.\n\n\nOtros nombres para la desviación típica\nTambién se puede llamar desviación estándar pero no de otra manera, aunque algunos textos se refieren a ella como desviación tipo o desvío típico.\n\n\nDistribución Normal\nLlamarla “normal” fue, sin duda, una mala idea. Es una distribución “central” en la teoría estadística, pero no merece el calificativo de “normal” porque las otras no son raras. Para que quede claro que Normal no un adjetivo, cuando nos referimos a la distribución lo escribimos con mayúscula.\n\n\n¿Distribución Chi-cuadrado o Ji-cuadrado?\nLa letra griega \\(\\chi\\) en español se lee “ji”’’“. Así se indica en el diccionario de la RAE:”ji: Vigesimosegunda letra del alfabeto griego…“. Si se busca”chi” no se encuentra nada. Pero en inglés se escribe “chi” (en latex hay que poner ) y seguramente por esta razón es tan frecuente verlo también escrito de esta manera.\n\n\n¿F de Snedecor o F de Fisher?\nLa idea original sobre la utilidad de una distribución de este tipo fue de Fisher. Esta distribución en concreto fue definida por Snedecor y le llamó F en honor a Fisher. También se designa como distribución de Fisher-Snedecor o, simplemente, distribución F.\n\n\nError tipo I y error tipo II\nSi el que propuso estos nombres quería usar un lenguaje críptico y poco claro para complicar la vida a los estudiantes, no lo pudo hacer mejor. En el ámbito de los análisis clínicos se habla de falso positivo y falso negativo, que es lo mismo y se entiende mejor.\n\n\n¿Que significa \\(P(X=x)\\)?\nEn nuestra notación, como en las contraseñas, no es lo mismo que el nombre de una variable esté en mayúscula o en minúscula. \\(X\\) mayúscula representa una variable aleatoria en general, como las estaturas de las personas y la \\(x\\) minúscula se refiere a un valor concreto. Por tanto, la expresión anterior hay que entenderla como la probabilidad de que la variable aleatoria \\(X\\) tome el valor concreto \\(x\\). Dicho de otra manera, la \\(X\\) mayúscula siempre es una \\(X\\) mayúscula, la minúscula se podría sustituir por un número.\n\n\nLetras griegas y letras latinas\nUtilizamos letras griegas para designar parámetros de la población: \\(\\mu\\) para la media, \\(\\sigma\\) para la desviación típica o \\(\\rho\\) para el coeficiente de correlación. Los valores que calculamos con los datos de la muestra –o muestras– se escriben con letras latinas, a veces con algún añadido como en el caso de la media, que se designa con la misma letra que la variable aleatoria pero con una barra encima: \\(\\bar{x}\\); para la desviación típica usamos \\(s\\) y para el coeficiente de correlación \\(r\\). También hay excepciones, para una proporción en la población suele usarse \\(p\\) –no \\(\\pi\\)– y para referirnos a su estimador escribimos \\(\\hat{p}\\). En general, con un ``gorro’’ encima de una letra nos referimos al estimador del parámetro designado con esa letra.\n\n\nError\nLo que en estadística llamamos “error” no es una equivocación ni tiene ninguna connotación negativa. Nos referimos a la diferencia entre el valor observado y el valor real o entre el valor observado y el valor teórico según el modelo establecido. Esa diferencia no existiría si no hubiera una cierta imprecisión en los procesos de medida o no existiera variabilidad en las variables que estudiamos. Es un “error” inevitable. Seguramente sería mejor llamarle de otra forma, pero así se ha quedado.",
    "crumbs": [
      "Miscelánea",
      "¿Cómo se dice? ¿Qué significa?"
    ]
  },
  {
    "objectID": "0708_Recta_Origen_R2.html#footnotes",
    "href": "0708_Recta_Origen_R2.html#footnotes",
    "title": "¿Por qué cuando se ajusta la recta por el origen no se debe usar \\(R^2\\)",
    "section": "",
    "text": "Observe que no es suficiente con estar seguros de que si \\(X=0\\) entonces \\(Y=0\\). Al modelar el peso en función de la estatura sabemos que si la estatura es cero, el peso también será cero, pero no ajustamos a una recta por el origen porque los valores que se ajustan –valores reales– están lejos del origen y no se puede extrapolar la relación. ↩︎",
    "crumbs": [
      "Correlación y regresión",
      "¿Por qué cuando se ajusta la recta por el origen no se debe usar $R^2$"
    ]
  },
  {
    "objectID": "0710_Variables_cualitativas.html#footnotes",
    "href": "0710_Variables_cualitativas.html#footnotes",
    "title": "¿Se pueden usar variables cualitativas en ecuaciones de regresión?",
    "section": "",
    "text": "Son datos ficticios, hemos puesto unos valores que ilustren de forma clara la situación que queremos mostrar↩︎",
    "crumbs": [
      "Correlación y regresión",
      "¿Se pueden usar variables cualitativas en ecuaciones de regresión?"
    ]
  },
  {
    "objectID": "Lista.html",
    "href": "Lista.html",
    "title": "LISTA DE PREGUNTAS",
    "section": "",
    "text": "1. Estadística: Lo que es y lo que no es 1.1 ¿La estadística es una parte de las matemáticas? 1.2 ¿La estadística es una parte de las matemáticas? 1.3 ¿Qué es la estadística?  1.4 Qué es la ciencia de datos (o Data Science)\n2. Estadística Descriptiva 2.1 ¿Para qué sirve la mediana si ya tenemos la media aritmética?  2.2 ¿Tiene alguna aplicación práctica la media geométrica?  2.3 ¿Por qué damos tanta importancia a la variabilidad?  2.4 ¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?  2.5 ¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?  2.6 ¿Por qué la desviación típica es la medida típica de dispersión?  2.7 ¿Cuál es la forma “correcta” de calcular los cuartiles?  2.8 ¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?  2.9 ¿Qué hay que hacer cuando nos encontramos con valores atípicos?  2.10 ¿Para qué sirve la curtosis?  2.11 ¿Qué gráfico debo usar para representar mis datos? 2.12 ¿Qué gráficos NO debo usar para representar mis datos?  2.13. ¿Cuáles son los mejores programas para analizar datos gráficamente?\n3. Distribuciones de probabilidad  3.1 ¿Cómo se pasa de la frecuencia a la densidad de probabilidad?  3.2 ¿Cómo se sabe qué distribución sigue una variable aleatoria?  3.3 ¿Por qué se dice que la media es una variable aleatoria?  3.4 ¿De dónde sale la fórmula de la distribución Normal?  3.5 ¿Por qué para la distribución Normal solo se necesita la tabla de la N(0; 1)?  3.6 ¿Por qué la probabilidad de tener mi estatura es igual a cero?  3.7 ¿Existen variables con comportamiento contrario a la distribución Normal?  3.8 ¿De dónde sale la fórmula de la distribución de Poisson?  3.9 ¿Cómo se relaciona la varianza muestral con la distribución Chi-cuadrado?  3.10. ¿Por qué no es lo mismo sumar k veces una variable aleatoria que multiplicarla por k?\n4. Muestreo y Estimación  4.1 ¿Por qué nos creemos los resultados de una muestra sabiendo que si tomáramos otra serían distintos?  4.2 ¿De dónde sale la expresión del intervalo de confianza?  4.3 ¿Qué es el factor de corrección por población finita?  4.4 ¿Cuántos elementos debe tener una muestra para que las conclusiones sean fiables?  4.5 ¿Qué relación hay entre tamaño de muestra y tamaño de población?  4.6 ¿Qué tipo de muestreo conviene elegir?  4.7 ¿Es lo mismo muestrea aleatoria que muestra representativa?  4.8 ¿Por qué cuesta acertar en los sondeos electorales?  4.9 ¿Qué es un estimador de máxima verosimilitud?\n5. Contraste de hipótesis  [5.1 ¿Qué es un contraste de hipótesis?]  [5.2 ¿Por qué es controvertido el uso del contraste de hipótesis?]  [5.3 ¿Cómo elegir la hipótesis alternativa que conviene plantear?]  [5.4 ¿Por qué se habla de “no rechazo” y no de “aceptación”?]  [5.5 ¿Cómo se sabe hacia qué lado hay que mirar el área de cola?]  [5.6 ¿A partir de qué p-valor se debe rechazar la hipótesis nula?]  [5.7 ¿Qué tipos de error se pueden cometer en un contraste de hipótesis?]  [5.8 ¿Es lo mismo diferencia significativa que diferencia importante?]  [5.9 ¿Es correcto multiplicar por dos el área de la cola en los test de igualdad de varianzas?]\n6. Diseño de experimentos  [6.1 ¿Cómo que diseño de experimentos? ¿no es eso de física o de química?]  [6.2 ¿Por qué no se usa el test de la t-Student para comparar más de dos tratamientos?]  [6.3 ¿Por qué se llama Análisis de la Varianza si lo que se compara son medias?]  [6.4 ¿Por qué no hay que mover las variables una a una?]  [6.5 ¿Cómo es posible estudiar por separado el efecto de cada variable?]  [6.6 ¿Cómo se puede escribir una ecuación para la respuesta con los resultados de un diseño factorial?]  [6.7 ¿Qué es un diseño bloqueado?]  [6.8 ¿Por qué se suponen no significativas las interacciones de tres o más factores?]  [6.9 ¿Qué hacer si al aleatorizar aparece el orden estándar de la matriz de diseño?]\n7. Correlación y regresión  [7.1 ¿Cómo se justifica la fórmula de la covarianza?]  [7.2 ¿De dónde sale la fórmula del coeficiente de correlación?]  [7.3 ¿Cómo se calculan los valores críticos del coeficiente de correlación?]  [7.4 ¿Sirven las tablas del coeficiente de correlación si X e Y no son Normales?]  [7.5 ¿Por qué se utiliza el método de los mínimos cuadrados?]  [7.6 ¿Por qué los coeficientes de una ecuación de regresión son variables aleatorias?]  [7.7 ¿Cómo se interpreta el valor de R2]  [7.8 ¿Por qué cuando se ajusta la recta por el origen no se debe usar R2]  [7.9 ¿Por qué hace falta el valor de R2 -ajustado si ya tenemos el de R2?]  [7.10 ¿Se pueden usar variables cualitativas en ecuaciones de regresión?]  7.11 [¿Por qué las variables que se incluyen en el modelo no necesariamente son las más correlacionadas con la respuesta?]\n8. Miscelánea  [8.1 Cuando se habla de transformación logarítmica ¿se refiere al logaritmo decimal o al neperiano?]  [8.2 ¿Debe decirse “Teorema central del límite” o “Teorema del límite central”?]  [8.3 ¿Qué significan los llamados “grados de libertad”?] [ 8.4 ¿Cuál es la mejor estrategia para que me toque la lotería?]  [8.5 Acaba de salir 5 veces el rojo ¿debo apostar al negro?]  [8.6 ¿Cómo se dice? ¿Qué significa?]",
    "crumbs": [
      "LISTA DE PREGUNTAS"
    ]
  },
  {
    "objectID": "0501_Que_es.html#footnotes",
    "href": "0501_Que_es.html#footnotes",
    "title": "5.1 ¿Qué es un contraste de hipótesis?",
    "section": "",
    "text": "que, por cierto, no aparecen por arte de magia. Su obtención es la parte más delicada e importante del estudio.↩︎",
    "crumbs": [
      "Contraste de hipótesis",
      "5.1 ¿Qué es un contraste de hipótesis?"
    ]
  }
]