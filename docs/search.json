[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística. Preguntas frecuentes",
    "section": "",
    "text": "PRESENTACIÓN\nRespondemos a preguntas que pueden surgir en un curso general de estadística. Tratan sobre el material del curso y también sobre temas que pueden aparecer en discusiones sobre lo que es la estadística, sus dificultades y sus aplicaciones.\nEs el resultado de nuestra experienca moviéndonos en este terreno y esperamos que sea útil a estudiantes, profesores que empiezan, e intersados por la estadística en general. Cualquier comentario o sugerencia será bienvenido.\nVersión 4.0 (Marzo de 2026)\n\nAutores\n\nRoberto Behar, profesor en la Universidad del Valle, en Cali, Colombia.\nPere Grima, profesor en la Universitat Politècnica de Catalunya, en Barcelona, España\n\n\n\nLibro impreso\nSe puede comprar en Amazon.es o Amazon.com. Está impreso en color, encuadernado con tapa blanda e incluye prólogo, índices y referencias.\n\n\nLicencia\nSe publica bajo una licencia Creative Commons: CC BY-NC-ND 4.0.",
    "crumbs": [
      "PRESENTACIÓN"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "Prologo_1E.html",
    "href": "Prologo_1E.html",
    "title": "Prólogo a la primera edición",
    "section": "",
    "text": "Muchos de los que alguna vez hemos sido estudiantes de un curso de Estadística, recordamos momentos en los que intentábamos entender, no siempre con éxito, las razones por las cuales había que hacer las cosas de una determinada manera. ¿Por qué dividir por n-1 al calcular la desviación estándar? ¿Por qué no dividir por el número total de datos? El tiempo disponible en los cursos no permite explicarlo todo y en ocasiones el profesor, en su intento por dar una explicación al estudiante que pregunta, responde usando términos como “grados de libertad” o “estimador insesgado”, lo cual puede generar más dudas de las que aclara.\nPor otra parte, a través de nuestra experiencia ayudando a profesionales de la Medicina, la Administración o la Ingeniería en el uso de métodos estadísticos, hemos comprobado que los conceptos o las técnicas con que se trabaja no siempre están del todo claras. ¿Cómo hay que interpretar el p-valor que da el listado del ordenador? ¿Es lo mismo diferencia significativa que diferencia importante? Esta falta de seguridad en su manejo hace que muchas veces se evite hacer uso de todas las posibilidades que brinda la estadística, con lo que se pierde la oportunidad de obtener una información que puede resultar muy útil para la toma de decisiones.\nTambién en un ámbito no estrictamente profesional existen muchas dudas “populares” en torno a la Estadística: ¿cómo es que con una muestra de 2.000 personas puede conocerse razonablemente bien la opinión de un país de 40 millones de habitantes?, o lo que es todavía más sorprendente, ¿cómo es que esas 2.000 personas también serían suficientes para una población de 100 millones? Y ligada con estas, si la Estadística es tan potente, ¿por qué cuesta tanto acertar en los sondeos electorales?\nEste texto pretende dar respuesta a muchas de estas preguntas y nuestra intención es que sea útil tanto a los estudiantes de los cursos de estadística que se imparten en la universidad, como a los profesionales que están interesados en refrescar sus ideas o aclarar dudas concretas, y también a todas aquellas personas interesadas en esta disciplina que quieran resolver algunas de sus dudas.\nSin ser exhaustivos, pues siempre es posible aumentar la lista con nuevas preguntas, hemos tratado de cubrir un amplio espectro, tratando dudas en estadística descriptiva, distribuciones de probabilidad, estimación, contraste de hipótesis, comparación de poblaciones, correlación y regresión, diseño de experimentos, estudios de capacidad y control de procesos y un apartado para dudas varias, como las relacionadas con los grados de libertad y el teorema central del límite, entre otras.\nMuchas preguntas tienen un carácter general e introductorio y son “aptas para todos los públicos”, pero otras tratan sobre temas específicos en el contexto de las ecuaciones de regresión, el diseño de experimentos o el control estadístico de procesos. En este último caso se requiere un cierto nivel de conocimientos sobre el tema, aunque si la pregunta despierta interés, seguramente ya se sabe lo suficiente para entender la respuesta. En todos los casos se ha intentado usar un lenguaje coloquial, recurriendo a la intuición y apoyándose en la metáfora, pero procurando que no haya pérdida en el rigor.\nSe ha intentado también que cada respuesta sea lo más autocontenida posible, es decir, lo suficientemente completa, para que no requiera de otras para su adecuada comprensión. De todas maneras, en cada uno de los temas que se tratan, se han colocado las dudas y sus respuestas en el orden que consideramos más efectivo, de tal manera que un lector que desee leer todas las preguntas de un apartado en forma secuencial vaya ganando elementos para comprender mejor la siguiente.\nDejando claro que cualquier falta en la virtud de este trabajo es de exclusiva responsabilidad de los autores, deseamos poner de manifiesto nuestro agradecimiento a todos nuestros compañeros en las tareas docentes, seguramente la mejor fuente de información que hemos tenido. Lluís Marco, de la Universitat Politècnica de Catalunya y Guillermo de León, de la Universidad Veracruzana nos sugirieron algunas de las preguntas que se incorporan y también ideas y posibles enfoques para muchas respuestas, además de leer los originales y sugerir numerosas mejoras. Rafael Antonio Klinger y Eloina Mesa, de la Universidad del Valle, también leyeron los originales y realizaron muchas sugerencias que han mejorado notablemente la claridad de las respuestas.\nDeseamos agradecer también a la Agencia Española de Coo-peración Internacional (AECI) y a nuestras Universidades, la Universidad del Valle y la Universitat Politècnica de Catalunya, las ayudas y facilidades obtenidas para la realización de este trabajo.\nMuy probablemente, no podremos evitar la frustración de algunos de nuestros lectores al buscar en vano alguna duda que no fue tratada aquí, o al no quedar del todo satisfechos con alguna respuesta. Nuestra aspiración es poder recoger todas las sugerencias y apreciaciones que nos permitan realizar un proceso mejora continua de nuestro trabajo, por lo que agradeceremos todos los comentarios y sugerencias que nos hagan llegar a través de la página web: www.55RespuestasEstadistica.com \\ \\ Barcelona y Santiago de Cali, Mayo de 2004",
    "crumbs": [
      "Prólogo a la primera edición"
    ]
  },
  {
    "objectID": "0101_Estadistica_Matematicas.html",
    "href": "0101_Estadistica_Matematicas.html",
    "title": "¿La estadística es una parte de las matemáticas?",
    "section": "",
    "text": "La materia prima de los análisis estadísticos son los datos –en general numéricos– y como los números pertenecen al reino de las matemáticas, muchas veces se considera que la estadística es una parte de las matemáticas. Los métodos estadísticos, por supuesto, usan las matemáticas, pero la estadística tiene un enfoque, unos objetivos y una metodología que son diferentes.\nEl pensamiento matemático es deductivo. Se parte de unos axiomas y mediante la lógica se deducen unos teoremas que se cumplen siempre. Este proceso deductivo persigue la resolución de problemas que se sitúan en el ámbito de los modelos abstractos, de lo teórico, y su resolución exige prestar mucha atención a la notación que se usa y a la aplicación de las reglas, propiedades y otros teoremas demostrados previamente.\nEl pensamiento estadístico es inductivo. Se parte de unos datos y a partir de ellos se estiman características de la población de la que provienen. El cómo seleccionar y evaluar la calidad de esos datos también forma parte del problema. Mientras que las matemáticas buscan encontrar soluciones exactas en el mundo de lo simbólico, en estadística estamos intentando buscar soluciones aproximadas pero útiles. En matemáticas un solo caso que no se cumpla ya es suficiente para declarar que una proposición es falsa. En estadística sabemos que el hecho de que un fumador de cajetilla diaria llegue a los 90 años no invalida la teoría de que el tabaco perjudica la salud.\nLa estadística sirve para responder preguntas en el terreno de la investigación empírica, preguntas del tipo: ¿Cuál de las resinas disponibles da mejores resultados en una depuradora de agua? ¿qué principio activo es más eficaz para curar una enfermedad? ¿Qué porcentaje de ciudadanos está de acuerdo con la política del gobierno? Estas preguntas no se pueden responder desde las matemáticas. Hay que hacer un experimento o una encuesta y sabemos que las conclusiones que se extraigan no serán un teorema matemático. Si se repite el experimento/encuesta saldrán otros resultados, pero tenemos herramientas matemáticas que, bajo ciertos supuestos, nos permiten responder a las preguntas planteadas informando también sobre la confianza con la que damos nuestras respuestas.\nDesde luego, la estadística tiene en la matemática una de sus herramientas más útiles. La teoría de la probabilidad –uno de los pilares de la estadística– se desarrolla íntegramente con el proceso deductivo de la matemática. La teoría de la probabilidad sí es una parte de las matemáticas. Necesitamos la teoría de las distribuciones de probabilidad para calcular probabilidades en el terreno de lo práctico.\nPero el enfoque y las prioridades de la estadística no son los mismos que los de las matemáticas. No son lo mismo, ni la estadística es una parte de las matemáticas.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿La estadística es una parte de las matemáticas?"
    ]
  },
  {
    "objectID": "0102_Probabilidad_Estadistica.html",
    "href": "0102_Probabilidad_Estadistica.html",
    "title": "¿El cálculo de probabilidades es una parte de la estadística?",
    "section": "",
    "text": "La teoría de la probabilidad y el cálculo de probabilidades son una parte de las matemáticas. Una parte que puede resultar muy útil en el marco de un análisis estadístico, pero no creemos que deba considerarse parte de la estadística.\nEn los problemas de cálculo de probabilidades se suponen conocidas las características de la población (que en muchos casos es una población teórica) y nos preguntamos por las características de una muestra obtenida de esa población. Ejemplos típicos de problemas de cálculo de probabilidades son:\n\n¿Cuál es la probabilidad de que realizando una apuesta nos toque el primer premio de la lotería primitiva (una lotería tipo 6/49)?\nSi una máquina fabrica un 3% de piezas defectuosas ¿Cuál es la probabilidad de que en un lote de 30 piezas haya alguna defectuosa?\n\nEn estadística nos ocupamos justo de lo contrario. Conocemos las características de una muestra que consideramos representativa de su población y lo que interesa es estimar (“hacernos una idea de”) las características de esa población. Ni que decir tiene que la muestra no vine dada y hay que pensar en la mejor manera de elegirla con los recursos disponibles. Después habrá que analizar los valores obtenidos para realizar las estimaciones. Todo esto, desde plantear claramente las preguntas que se desea responder hasta explicar las conclusiones a que se ha llegado, está lleno de dificultades que no tienen nada que ver con el cálculo de probabilidades. Problemas de estadística serían:\n\nCon base en los resultados de un sondeo electoral, estimar el número de escaños que obtendrá un partido en las próximas elecciones.\nA partir de los resultados de un estudio clínico, determinar si un nuevo medicamento es más eficaz que el usado habitualmente.\n\nClaro que nuestras estimaciones o nuestras conclusiones nunca son apuestas seguras y ahí es donde aparece el lenguaje de la probabilidad: Informamos sobre la probabilidad de que el número de escaños se encuentre entre determinados valores, o afirmamos que con una determinada probabilidad de error (que se fija de antemano y que se designa “nivel de significación”) puede decirse que el nuevo medicamento es eficaz. Pero, en general, el uso que hacemos de la probabilidad no requiere saber resolver problemas complicados de combinatoria o de cálculo de probabilidades. Basta con unas reglas bastante sencillas y al alcance de todos.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿El cálculo de probabilidades es una parte de la estadística?"
    ]
  },
  {
    "objectID": "0103_Que_es_Estadistica.html",
    "href": "0103_Que_es_Estadistica.html",
    "title": "¿Qué es la estadística?",
    "section": "",
    "text": "Existen muchas definiciones de lo que es la estadística. En el ámbito académico una de las más cortas y acertadas nos la dio un estudiante cuando discutíamos este tema el primer día de clase: “La estadística es una asignatura”. Desde luego tenía razón.\nSeguramente la estadística es la asignatura que aparece en los planes de estudios de más titulaciones, pero no podemos decir que sea la más apreciada. Muchos estudiantes la consideran una asignatura más bien antipática, donde se realizan consideraciones ininteligibles que poco o nada tiene que ver con su vocación y sus intereses. Quizá por eso, una vez superada se produce un cierto desapego y la estadística se que queda en eso, en un asignatura.\nY por si esto fuera poco, en las antípodas de la visión formal y académica, se tiene también una visión un tanto despectiva donde la estadística se relaciona con porcentajes tendenciosos, con gráficos manipulados y con números que siempre hay manera de presentar de la forma que convenga y, claro, unas técnicas que sirven lo mismo para justificar que algo es blanco como que es negro, no son nada fiables para saber de que color son las cosas.\n\nUn poco de historia\nLa estadística como “cuentas del Estado” (de ahí su nombre) surgió cuando los gobernantes necesitaron conocer cuantas personas vivían en sus dominios, el volumen de las cosechas o los impuestos que cada familia debía pagar, y de eso hace ya miles de años. Esto significaba recoger datos y ordenarlos, tabularlos y quizá realizar algunos cálculos que estarían dentro de lo que hoy denominamos”estadística descriptiva”. Esto fue la estadística hasta los inicios del siglo XX, hace cuatro días.\nCon unas motivaciones totalmente distintas –en este caso relacionadas con la búsqueda de estrategias en los juegos de azar –, en el siglo XVII se empezó a estudiar seriamente (“matemáticamente”) el cálculo de probabilidades. Más tarde, la estadística clásica encontró en las probabilidades el lenguaje y las herramientas que le permitían hacer estimaciones sobre la población conociendo solo una parte e informando sobre el grado de incertidumbre de sus conclusiones. Esto aumentó enormemente sus posibilidades y su campo de actuación.\nLa estadística que se explica en los cursos introductorios se creó, fundamentalmente, en la primera mitad del siglo XX. Al inicio de esta nueva época los métodos estadísticos se desarrollaron en torno a aplicaciones concretas (seguros de vida, ciencias naturales, industria, agricultura…) pero el interés por crear nuevos métodos para el análisis de los datos (¡estaba todo por hacer!) se despegó de las aplicaciones prácticas, especialmente en el ámbito académico, y se empezaron a crear matemáticas que poco o nada tenían que ver con el estudio de la realidad que nos rodea. Esta irrupción de las matemáticas en la estadística también ha tenido repercusiones en la docencia. Muchas veces los profesores de estadística son y actúan como profesores de matemáticas, lo cual seguramente tiene bastante que ver con las causas del desafecto por la asignatura en aquellos estudiantes para los cuales su vocación es otra.\n\n\nEstadística y adquisición de conocimiento\nMejoramos nuestra conocimiento a base de plantearnos preguntas e intentar responderlas. La estadística juega un papel protagonista cuando para responder a esas preguntan se necesitan datos. Ejemplos de preguntas podrían ser:\n\n\nBiología: ¿Cómo evoluciona el número de ejemplares de cierto tipo de ave en un territorio?\nMedicina: ¿És eficaz una nueva vacuna?\nMedio ambiente: ¿Qué porcentaje de plástico se recicla?\nEconomía: ¿Cuánto están subiendo los precios?\nIngeniería: ¿Qué catalizador aumenta más el rendimiento de una reacción química?\nMarqueting: ¿Qué tipo de envoltorio logra mayores ventas?\nPrevisiones: ¿Cuánta electricidad se consumirá mañana?\n\n\nLa estadística trata de cómo recoger y de cómo analizar los datos para responder a las preguntas planteadas. Raramente se consiguen todos los datos que nos gustaría tener, y menos todavía con las características deseadas, pero la estadística tiene herramientas para enfrentarse a estas situaciones y sacar el máximo provecho de los recursos disponibles, todo esto, como ya sabemos, con una medida conocida de la confianza con que podemos ofrecer nuestras conclusiones.\nLa estadística está muy relacionada con el método científico, que se basa en la observación, medición, experimentación, planteamiento y contraste de las hipótesis con datos experimentales… También cabe poner de manifiesto que el “elemento desencadenante”, lo que pone en marcha el proceso, es la pregunta que nos planteamos. No nos gusta analizar datos “para ver lo que sale”, siempre buscamos algo y saber lo que se busca -hacerse la pregunta adecuada- también es importante. Obtener los datos necesarios suele ser la parte más delicada y laboriosa. Una vez se tienen los datos, muchas veces las preguntas se pueden responder con análisis gráficos sencillos, aunque en otros casos hay que recurrir a técnicas más sofisticadas.\n\n\nNuestra definición\nLa estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos en el proceso de adquisición de nuevos conocimientos, en un ambiente en el cual casi siempre están presentes la variabilidad y la incertidumbre.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿Qué es la estadística?"
    ]
  },
  {
    "objectID": "0104_DataScience.html",
    "href": "0104_DataScience.html",
    "title": "¿Qué es la ciencia de datos (o Data Science)?",
    "section": "",
    "text": "El mantra que tanto hemos repetido en las clases de Estadística de que “los datos son siempre un recurso escaso” dejó de ser cierto en muchos casos, aunque en muchos otros (en los sondeos electorales, sin ir más lejos) sigue siendo tan válido como siempre.\nCada vez es más habitual capturar datos y enviarlos automáticamente a esa nube que parece no tener límites. Por ejemplo, las grandes instalaciones de aire acondicionado pueden colocar sensores que captan la presión del aire o las vibraciones en puntos clave de las máquinas y envían a la nube esos valores que pueden ser recuperados y analizados desde cualquier lugar. Es también muy típico el ejemplo de los supermercados que pueden almacenar la información de lo que ha comprado cada uno de sus clientes, pudiendo realizar también un seguimiento detallado de la evolución de las compras de los que tienen tarjeta de fidelidad.\nDespués de ser capaces de almacenar tantos datos, lo siguiente es intentar sacar provecho de ellos. ¿Cuándo conviene cambiar los filtros o sustituir una pieza que está a punto de romperse? ¿qué oferta conviene realizar a determinado tipo de clientes? En muchos casos basta con aplicar técnicas clásicas de análisis exploratorio de datos o con la construcción de modelos conceptualmente muy sencillos, pero en otros es necesario utilizar técnicas más sofisticadas y, en todos los casos, el manejo y la gestión de grandes volúmenes de datos entraña unas dificultades específicas.\nBásicamente, lo que se ha dado en llamar “Ciencia de Datos” es un conjunto de conocimientos relacionados con la captación, almacenamiento y análisis de datos para crear algoritmos que permitan identificar patrones, casi siempre con el objetivo de hacer previsiones. Algunos de estos algoritmos son capaces de reajustarse automáticamente aprendiendo de sus errores (machine learning). En terrenos como la identificación de imágenes (reconocimiento facial) o de sonidos (“Alexa, ¿qué hora es?”) son excelentes. También en otros casos, como la previsión de valores que evolucionan en el tiempo, el uso de unos algoritmos llamados redes neuronales suele ofrecer mejores resultados que los métodos clásicos.\nTambién es verdad que no es oro todo lo que reluce. Seguramente algunas de sus posibilidades han sido sobrevaloradas por empresas consultoras que ven en estas técnicas con nombre sugerente (Inteligencia artificial, deep learning…) la posibilidad de vender nuevos productos.\nUna peculiaridad de esos algoritmos es que actúan como ``cajas negras’’ en las que se tienen unas variables de entrada \\(X\\), y otras de salida \\(Y\\), y lo que se pretende es tener buenas previsiones de los valores de \\(Y\\) dado un conjunto de valores de \\(X\\), pero sin llegar a entender cómo esos valores de \\(X\\) están afectando a los de \\(Y\\). El no conocer las relaciones causa-efecto limita sus posibilidades en la solución de problemas cuando es necesario conocer cuales son las causas que los provocan para poder plantear soluciones eficaces. Por otra parte, el esfuerzo que se realiza intentado obtener información de grandes volúmenes de datos de dudosa calidad (muchas veces misión imposible) sería mejor reorientarlo a plantearse qué datos se necesitan y planificar su recogida con el rigor y la estructura adecuadas para que de manera transparente y fiable se pueda obtener la información deseada así como un mejor conocimiento del proceso en estudio.\nEs un tema controvertido si la “Ciencia de Datos” debe ser considerada una parte de la estadística o si se trata de una nueva disciplina. Nuestra opinión es que depende de lo que entendamos por estadística. Si estadística es la parte de las matemáticas que se dedica a crear métodos estadísticos, entonces realmente la ciencia de datos es una nueva disciplina, mucho más orientada a la resolución de problemas prácticos. Si, tal como nosotros pensamos, la estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos, no hay ninguna duda de que la ciencia de datos encaja perfectamente en esa definición.\nEn cualquier caso, entender el funcionamiento de esos algoritmos, ser capaces de programar y de interactuar con grandes volúmenes de datos, así como conocer las posibilidades de almacenamiento y computación en la nube son habilidades muy demandadas y con un gran futuro.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿Qué es la ciencia de datos (o *Data Science*)?"
    ]
  },
  {
    "objectID": "0201_Mediana.html",
    "href": "0201_Mediana.html",
    "title": "¿Para qué sirve la mediana si ya tenemos la media aritmética?",
    "section": "",
    "text": "La media aritmética es una excelente medida de tendencia central, muy usada y también muy apreciada, a veces demasiado, como cuando se pretende resumir en ella toda la información que contienen los datos. La mediana tiene unas propiedades de las que carece la media, por lo que es un buen complemento informativo e incluso puede ser una medida más útil en algunos casos. Vamos a ver estas propiedades.\n\nEs más robusta que la media frente a la presencia de anomalías. Supongamos que nuestros datos son:\n2; 5; 6; 7 y 9\nLa media es 5,6 y la mediana es 6. Si al introducir los datos al ordenador nos equivocamos y en último lugar en vez de 9 introducimos 99, la media pasa a ser 23,8 mientras que la mediana sigue siendo 6.\nPor su propia definición, la mediana deja un 50% de las observaciones por debajo y otro 50% por encima y esto le da unas ventajas que la media no tiene. Si queremos saber si en nuestra empresa estamos entre los que cobran más o entre los que cobran menos, debemos comparar nuestro salario con la mediana, no con la media. Si sólo hay 10 trabajadores y los salarios son (en las unidades que corresponda):\n0,8; 0,8; 0,9; 0,9; 1,0; 1,0; 1,1; 1,1; 1,2 y 10\ntodos menos uno (en este caso el 90%) están por debajo de la media, que es 1,88. Esto no pasa nunca con la mediana: si estamos por encima de la mediana, estamos con el 50% de los que más cobran. Otro ejemplo. Si en un examen las notas van de 0 a 10 y se aprueba sacando una nota igual o superior a 5, si la nota media es 5 no sabemos cuántos han aprobado. Si se han examinado 50 estudiantes, puede ser que 41 hayan suspendido con un 4; 8 hayan sacado un 10 y uno haya obtenido un 6. Esto da media 5, aunque el 82% ha suspendido. Si la mediana es 5, seguro que la mitad han aprobado.\n\nSi la distribución de los datos es simétrica, la media y la mediana coinciden y entonces todo son ventajas. En una distribución Normal la media y la mediana son iguales, por tanto, si los valores que tenemos provienen de una Normal, la media y la mediana no andarán muy lejos una de otra. En cualquier caso, siempre podemos calcular las dos y aprovechar lo mejor de cada una.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Para qué sirve la mediana si ya tenemos la media aritmética?"
    ]
  },
  {
    "objectID": "0202_Media_geometrica.html",
    "href": "0202_Media_geometrica.html",
    "title": "¿Tiene alguna aplicación práctica la media geométrica?",
    "section": "",
    "text": "Sí la tiene, pero mucho menos que la media aritmética. Un caso típico de uso de la media geométrica lo tenemos en el cálculo del valor medio de una tasa de crecimiento. Si una población tenía 10.000 habitantes en el año cero, creció el primer año a una tasa del 5 %, el segundo a una tasa del 20 % y el tercer año al 50 % ¿A que tasa promedio ha crecido en estos tres años?\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacióninicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n1\n10.000\n0,05\n1,05\n10.500\n\n\n2\n10.500\n0,20\n1,20\n12.600\n\n\n3\n12.600\n0,50\n1,50\n18.900\n\n\n\n\nSi calculamos la media aritmética de la tasa de crecimiento tenemos: \\((0,05 + 0,20 + 0,50)/3 = 0,25\\) y el factor medio de expansión sería \\(1,25\\). Pero si la población hubiera crecido los tres años de esta forma, no se llegaría al mismo resultado final:\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacióninicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n1\n10.000\n0,25\n1,25\n12.500\n\n\n2\n12.500\n0,25\n1,25\n15.625\n\n\n3\n15.625\n0,25\n1,25\n19.531\n\n\n\n\nPor tanto, la media aritmética no es un buen indicador de la tasa media de crecimiento.\nSi la población crece a una tasa constante \\(i\\), para que al final del tercer año tenga el mismo efecto que las tasas del ejemplo, se debe verificar que:\n\\[ 10\\,000(1+i)(1+i)(1+i)=10\\,000(1+0,05)(1+0,20)(1+0,50) \\]\nDe donde:\n\\[(1+i)= \\sqrt[3]{1,05 \\cdot 1,20 \\cdot 1,50}=1,2364\\]\nSi se hubiera tenido este factor de expansión cada año (nótese que es la media geométrica), hubiera conducido a una población final igual a la que tenemos.\nCuriosidades sobre la media geométrica son:\n\nA diferencia de la media aritmética, la media geométrica sólo se define para números positivos.\nLa media geométrica nunca es mayor que la media aritmética. La demostración para el caso de 2 valores es fácil por reducción al absurdo. Supongamos que: \\(\\sqrt{ab} &gt; (a+b)/2\\), entonces \\(ab &gt; (a^2+2ab+b^2)/4\\), de donde: \\(0 &gt;a^2-2ab+b^2\\). Como \\(a^2-2ab+b^2=(a-b)^2\\) es imposible que este valor sea negativo, luego es imposible que \\(\\sqrt{ab}&gt;(a+b)/2\\).\n\nY ya puestos a hablar de otras medias, podemos hacer un comentario sobre la media armónica, mucho menos conocida pero también útil en algunos casos.\nSe define la media armónica de \\(x_1, x_2, ..., x_N\\) como:\n\\[Mh = \\frac{N}{\\large{\\frac{1}{x_1}+\\frac{1}{x_2}+...+\\frac{1}{x_N}}}\\]\nParece que esto sea un retorcimiento sin ningún interés, pero no. Si un coche recorre cierta distancia a una velocidad de 100 km/h y vuelve por el mismo camino a 120 km/h, la velocidad media a que ha realizado el viaje es:\n\\[Mh = \\frac{2}{\\large{\\frac{1}{100}+\\frac{1}{120}}} = 109,1 \\text{ km/h}\\]\ny no 110 km/h como en principio se podría pensar.\nObserve que la velocidad es igual a la distancia recorrida dividida por el tiempo tardado en recorrerla,\nes decir \\(v=d/t\\) y por tanto \\(t=d/v\\). En nuestro caso, si la distancia a recorrer es \\(d\\), el tiempo tardado en la ida es \\(t_1 =d/100\\) y el tiempo tardado en el regreso es \\(t_2 =d/120\\). De esta manera el tiempo total invertido en todo el recorrido \\((2d)\\) será \\(t=t_1+t_2\\) y la velocidad media se calcula de la forma:\n\\[ \\text{Velocidad media} = \\frac{\\text{Distancia total recorrida}}{\\text{Tiempo total empleado}} = \\frac{2d}{\\large{\\frac{d}{100}+\\frac{d}{120}}} \\]\nOtro ejemplo: Un avión recorre 3000 km. Los 1000 primeros a 700 km/h, los 1000 siguientes a 800 km/h, y los 1000 restantes a 900 km/h ¿Cuál ha sido su velocidad media? No ha sido 800 km/h sino 791,6 km/h.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Tiene alguna aplicación práctica la media geométrica?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html",
    "href": "0203_Variabilidad.html",
    "title": "¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "Porque considerar la variabilidad es fundamental para describir la realidad, para entenderla y para tomar mejores decisiones.\nEs muy conocido el chiste que dice que si un señor se come un pollo y otro no come nada, la estadística lo explicará diciendo que en promedio se han comido medio pollo cada uno. Hace gracia por lo descabellado que es contar así las cosas, pero lo hacemos con más frecuencia de la que creemos. Por ejemplo, cuando se habla de la renta per cápita de un país se está hablando del medio pollo que se come cada uno, sin hacer ninguna referencia a si todos comen más o menos lo mismo o si unos comen mucho y otros prácticamente nada. En el terreno de la educación, cuando se dan los resultados de las pruebas PISA se dan unos valores por países y pocos se preguntan sobre las diferencias dentro de cada país, lo cual también es una información relevante.\nEn el ámbito de la gestión de empresas, supongamos que debe elegir entre dos proveedores que son iguales en todo (precio, calidad, etc.) excepto en el plazo de entrega: uno tarda un promedio de 4,25 días y el otro de 5,75, ¿con cuál se queda? Seguramente habrá pensado que con el que sirve más rápido, pero 4,25 es el promedio de: 3, 5, 4, 3, 7, 4, 2 y 6, mientras que 5,75 lo es de: 6, 5, 6, 6, 6, 5, 6 y 6. ¿Qué piensa ahora? Es más previsible el que tarda 5,75 y seguro que usted se podrá organizar mejor con este. Con el otro deberá hacer los pedidos un mínimo de 7 días antes, y alguna vez lo recibirá a los 2 días y no sabrá donde ponerlo.\nEn el mundo industrial ignorar la variabilidad también conduce a una visión equivocada del funcionamiento de las cosas. Veamos un ejemplo donde usaremos la ley de Ohm (Recuerde: I=V/R, si esto no le suena de nada puede saltarse este párrafo). Supongamos que le encargan fabricar un lote de circuitos muy sencillos que solo constan de un fuente de alimentación (V) y de una resistencia (R). Vamos a suponer que el voltaje de la fuente de alimentación siempre es igual a 100 V mientras que las resistencias presentan una cierta variabilidad y tienen un valor real que es igual al valor nominal ±5 \\(\\Omega\\). Se desea que en cada circuito la intensidad sea de 10 A y se considerará defectuoso si esa intensidad está fuera del intervalo 10±3 A ¿de qué valor nominal debe pedir las resistencias para minimizar la proporción de circuitos defectuosos? Quizá usted está pensando que si se quiere tener I=10 A, si V=100 V se debe pedir R=10 \\(\\Omega\\). Esto sería verdad si no hubiera variabilidad pero en nuestro caso habría que pedirlas de 11 \\(\\Omega\\)1.\nEn el ámbito de la medicina, para que una vacuna o un nuevo medicamento sean aprobados deben probarse en una amplia muestra de las personas a que va dirigido. Si todos fuéramos iguales -si no hubiera variabilidad- bastaría hacer la prueba en una sola persona, una cualquiera, y si en esa funciona funcionaría en todas.\nEn fin, si no existiera la variabilidad no habría estadística. Ni estadística, ni evolución de las especies ni muchas otras cosas. Tampoco estaríamos nosotros.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0204_Varianza_cuadrado.html",
    "href": "0204_Varianza_cuadrado.html",
    "title": "¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?",
    "section": "",
    "text": "Cuando se calcula la varianza, las diferencias entre cada valor y la media se elevan al cuadrado para evitar que se compensen las positivas con las negativas. Esto provoca que sus unidades sean el cuadrado de las que tienen los datos, lo cual resulta poco intuitivo y difícil de interpretar (no parece natural medir la variabilidad de longitudes en unidades de superficie). Este problema se resuelve usando una nueva medida que es la raíz cuadrada de la varianza: la desviación típica. Todos hemos pensado alguna vez que se podría evitar tener esas dos medidas usando el valor absoluto de las diferencias en vez de su cuadrado. Así ya estaríamos midiendo la variabilidad en las mismas unidades que los datos.\nNo lo hacemos porque saldríamos perdiendo. La varianza tiene unas propiedades extraordinarias que ni de lejos presenta esa nueva medida usando el módulo. Vamos a desarrollar unas ideas que nos permitirán justificarlo.\nUtilizaremos los datos representados en la figura 1 en la cual también hemos representado un valor (a), en principio arbitrario, con el propósito de descubrir donde conviene colocarlo para que sea un “buen representante” de este conjunto de datos.\n\n\n\n\n\n\nFigura 1: ¿Dónde colocar un “buen representante” de estos datos?\n\n\n\nEn principio \\(a\\) puede ser cualquier número real pero le vamos a exigir algunos requisitos asociados con nuestra idea de lo que significa “buen representante”, lo cual restringirá el conjunto de valores que puede asumir. Veamos dos criterios para seleccionar el valor de \\(a\\).\n\nCriterio 1\nEscoger el que minimiza la función \\(f(a)\\), definida de la forma:\n\\[f(a)=\\frac{ \\sum_{i=1}^{N} \\left| x_i-a\\right| } {N} \\]\nDonde \\(N\\) es el número de datos y los \\(x_i\\) son sus valores. Como la distancia promedio depende sólo de \\(a\\) le hemos llamado \\(f(a)\\). El valor que minimiza esta función y que por tanto es el mejor representante de los datos con el criterio aplicado no es la media sino la mediana.\nAl valor mínimo de \\(f(a)\\) le llamamos desviación media \\(DM\\) con respecto a la mediana, y su fórmula es: \\[DM=\\frac{ \\sum_{i=1}^{N} \\left| x_i-Me\\right| } {N} \\] En nuestro ejemplo, la mediana es 15,5. Esto significa que de todos los números reales, 15,5 es el que está más cerca de los datos de acuerdo con este criterio. Por tanto, la desviación media para nuestros datos es: \\[ DM = \\frac{\\left|10-15,5\\right|+\\left|12-15,5\\right|+...+\\left|20-15,5\\right|}{10}=2,3 \\]\n\n\nCriterio 2\nEscoger el que hace menor la media de los cuadrados de la distancia de los datos al valor (a). Es decir, el que minimiza la función:\n\\[g(a)=\\frac{ \\sum_{i=1}^{N} ( x_i-a)^2 } {N} \\]\nEn este caso el mejor valor de (a) puede deducirse derivando (g(a)) con respecto de (a), igualando a cero y despejando su valor. Veamos:\n\\[\\frac{\\text{d} g(a)}{\\text{d} a} = \\frac{-2}{N} \\sum_{i=1}^{N}(x_i-a) = 0\\] Por tanto \\(\\sum_{i=1}^{N}(x_i-a) = 0\\), de donde se deduce que \\(\\sum x_i =N \\cdot a\\) y despejando \\(a\\) tenemos: \\[ a = \\sum_{i=1}^{N} \\frac{x_i}{N} \\]\nObserve que en este caso el valor de \\(a\\) sí coincide con la media aritmética (le llamamos \\(\\mu\\)). Si hacemos la segunda derivada vemos que siempre es positiva, lo cual confirma que el punto crítico es \\(a=\\mu\\) y que el valor mínimo de \\(g(a)\\) es la varianza de \\(X\\) (le llamamos \\(\\sigma^2\\)). Con los datos de nuestro ejemplo \\(\\mu\\) = 15,1 y el valor mínimo que toma \\(g(a)\\) es \\(\\sigma^2\\)= 7,89. Sacando raíz cuadrada se obtiene la desviación típica \\(\\sigma\\) = 2,81.\n¿Por qué se prefiere usar la varianza, deducida a través del criterio 2, en lugar de la desviación media, deducida aplicando el criterio 1? Veamos algunas razones:\n\nLos desarrollos anteriores ponen de manifiesto que la media, medida descriptiva por excelencia, está asociada de forma más natural con la varianza que con la \\(DM\\).\nLa \\(DM\\) incluye en su expresión la función “valor absoluto” que se comporta mal desde un punto de vista matemático, mientras que la función cuadrática es muy fácilmente tratable. Observe, por ejemplo, que la demostración de que la media hace mínimo el promedio de los cuadrados se ha realizado de forma casi inmediata, mientras que probar que la mediana hace mínima la media de las distancias es bastante más complejo.\nLa desviación estándar \\(\\sigma\\) de la población es usada para definir la distribución más famosa y útil, como es la Normal. Esto posibilita la construcción de intervalos de confianza para estimar, por ejemplo, la media de la población, lo que sería mucho más complejo si se usara la \\(D\\).\nLa varianza es una suma de cuadrados que se puede descomponer en diversos sumandos dando origen al llamado “Análisis de la Varianza”. El desarrollo de la teoría de los modelos lineales está basado en gran parte en el criterio de los mínimos cuadrados, que es el mismo en que está basada la varianza. Cuando la población origen de los datos es Normal, el cociente de varianzas muestrales sigue una distribución conocida, llamada \\(F\\) de Snedecor.\nLa varianza de una suma de variables aleatorias se calcula de una forma muy fácil, especialmente si las variables son independientes. Por ejemplo, en un proceso de envasado, si el peso del envase tiene una varianza \\(V(X)\\) y la varianza del contenido es \\(V(Y)\\), la varianza del conjunto es \\(V(X+Y) = V(X) + V(Y)\\).\n\nNada de esto podríamos hacer si intentamos usar la desviación media como medida de dispersión. En síntesis, la teoría estadística desarrollada en base a la varianza es muy rica, y no se conoce nada parecido para la desviación media.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?"
    ]
  },
  {
    "objectID": "0205_Dividir_n_1.html",
    "href": "0205_Dividir_n_1.html",
    "title": "¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?",
    "section": "",
    "text": "Para hacer más fácil la explicación vamos a trabajar con un ejemplo suponiendo que conocemos la población completa, lujo que no tendremos en la práctica. Los elementos que componen la población, junto con sus mediciones respectivas, son:\n\n    \n\n\n  \n\n(A)\n(B)\n(C)\n(D)\n(E)\n(F)\n\n\n\n\n2\n6\n8\n10\n10\n12\n\n\n  \n \n\nEn primer lugar ilustraremos la propiedad de insesgamiento de un estimador para el caso de la media, con la cual estamos más familiarizados, y luego repetiremos la experiencia para el caso que nos ocupa de la varianza.\nLa media poblacional \\(\\mu\\), de los datos del ejemplo, es:\n\\[\\mu = \\frac{2+6+8+10+10+12}{6}=8\\]\nSupongamos que nosotros queremos estimar (“hacernos una idea”) el valor \\(\\mu\\), usando una muestra aleatoria de \\(n = 2\\) unidades. En este caso, en que la población consta sólo de 6 unidades, podemos hacer un listado de todas las muestras que pueden resultar al escoger dos unidades al azar. Estas muestras aparecen enumeradas en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\n11\n\n\n12\n\n\n13\n\n\n14\n\n\n15\n\n\n\n\nUnidades de la muestra\n\n\nAB\n\n\nAC\n\n\nAD\n\n\nAE\n\n\nAF\n\n\nBC\n\n\nBD\n\n\nBE\n\n\nBF\n\n\nCD\n\n\nCE\n\n\nCF\n\n\nDE\n\n\nDF\n\n\nEF\n\n\n\n\nValores en la muestra\n\n\n26\n\n\n28\n\n\n210\n\n\n210\n\n\n212\n\n\n68\n\n\n610\n\n\n610\n\n\n612\n\n\n810\n\n\n810\n\n\n812\n\n\n1010\n\n\n1012\n\n\n1012\n\n\n\n\nMedia muestral\n\n\n4\n\n\n5\n\n\n6\n\n\n6\n\n\n7\n\n\n7\n\n\n8\n\n\n8\n\n\n9\n\n\n9\n\n\n9\n\n\n10\n\n\n10\n\n\n11\n\n\n11\n\n\n\n\n\n\nCuando se seleccione al azar una muestra de dos unidades, el resultado será necesariamente alguna de estas 15 posibles combinaciones de 2 elementos, con su media \\(\\bar{x}\\) correspondiente.\nDecimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\) si el promedio de todas las posibles medias coincide exactamente con la media de la población. Para verificarlo, hagamos el promedio de nuestras 15 posibles medias: \\[ \\frac{4+5+6+6+7+7+8+8+9+9+9+10+10+11+11}{15}=8 \\]\nEl promedio coincide con \\(\\mu\\). Esto pasa en todos los casos, independientemente del tipo de población o del tamaño de la muestra, por eso decimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\).\nVeamos ahora si el estadístico: \\[  S_{n}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n} \\]\ndonde \\(n\\) es el tamaño de las muestras, es un estimador insesgado para la varianza \\(\\sigma_{N}^{2}\\), calculada como: \\[  \\sigma_{N}^{2}= \\frac{ \\sum_{i=1}^{N}{(x_i-\\mu)^2} }{N} \\]\ndonde \\(N\\) es el tamaño de la población. Queremos saber si el promedio de los valores de \\(S_{n}^{2}\\), para cada una de las posibles muestras, da el valor de \\(\\sigma_{N}^{2}\\) y para averiguarlo, en primer lugar vamos a calcular la varianza poblacional:\n\\[  \\sigma_{N}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6} = 10,67 \\]\nAhora calculamos la varianza para cada muestra de 2 unidades, con la fórmula: \\[  S_{n}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2} \\]\nobteniéndose los resultados que aparecen en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\n11\n\n\n12\n\n\n13\n\n\n14\n\n\n15\n\n\n\n\nValores en la muestra\n\n\n26\n\n\n28\n\n\n210\n\n\n210\n\n\n212\n\n\n68\n\n\n610\n\n\n610\n\n\n612\n\n\n810\n\n\n810\n\n\n812\n\n\n1010\n\n\n1012\n\n\n1012\n\n\n\n\nMedia muestral\n\n\n4\n\n\n9\n\n\n16\n\n\n16\n\n\n25\n\n\n1\n\n\n4\n\n\n4\n\n\n9\n\n\n1\n\n\n1\n\n\n4\n\n\n0\n\n\n1\n\n\n1\n\n\n\n\n\n\n\nVeamos si el promedio de las posibles varianzas muestrales, coincide con 10,67 que es el valor obtenido para \\(\\sigma_{N}^{2}\\).\n\\[ \\bar{S}^2 = \\frac{4+9+16+16+25+1+4+4+9+...+1}{15} = 6,4 \\]\nNo coincide y, por tanto, \\(S_{n}^{2}\\) no es un estimador insesgado de \\(\\sigma_{N}^{2}\\). Sin embargo \\(S_{n-1}^{2}\\), definido de la forma: \\[  S_{n-1}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n-1} \\]\naunque tampoco es un estimador insesgado para \\(\\sigma_{N}^{2}\\), sí lo es para \\(\\sigma_{N-1}^{2}\\) definido como: \\[  \\sigma_{N-1}^{2}= \\frac{ \\sum_{i=1}^{N-1}{(x_i-\\mu)^2} }{N-1} \\]\nEfectivamente, \\(\\sigma_{N-1}^{2\\) tiene el valor: \\[  \\sigma_{N-1}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6-1} = 12,8 \\]\nY si calculamos \\(S_{n-1}^{2}\\) para cada una de nuestras muestras deberemos aplicar la fórmula:\n\\[  S_{n-1}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2-1} = \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{1}  \\]\nEs decir que todos los valores de la varianza que aparecen en la tabla anterior, quedan ahora multiplicados por 2 y por lo tanto la media de las varianzas queda también multiplicada por 2, es decir:\n\\[ \\bar{S}_{n-1}^{2}= 2\\cdot 6,4 = 12,8 \\]\nQuizá este resultado decepcione, y hasta sorprenda, porque seguramente lo esperado era que \\(S_{n-1}^{2}\\) fuera un estimador insesgado de \\(\\sigma_{N}^{2}\\) y no de \\(\\sigma_{N-1}^{2}\\), pero no hay que preocuparse demasiado. A efectos prácticos es casi lo mismo cuando la población es grande, y nosotros no vamos a estimar a través de muestras las características de una población de 6 elementos (en nuestro ejemplo esta ha sido una población “de juguete” para entender lo que estábamos haciendo). Cuando estimemos la varianza de una población se tratará de una población grande, en la que \\(\\sigma_{N}^{2}\\) será prácticamente igual a \\(\\sigma_{N-1}^{2}\\). En realidad, el caso más frecuente es tener poblaciones teóricas (infinitas), en las que es exactamente lo mismo \\(\\sigma_{N}^{2}\\) que \\(\\sigma_{N-1}^{2}\\).",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?"
    ]
  },
  {
    "objectID": "0206_Desviacion_tipica.html",
    "href": "0206_Desviacion_tipica.html",
    "title": "¿Por qué la desviación típica es la medida típica de dispersión?",
    "section": "",
    "text": "Existen diversas razones por las que la desviación típica –o desviación estándar– es tan valorada y tan necesaria en el ámbito de la Estadística. Una de esas razones es formar con la media una “pareja perfecta” para describir el comportamiento de muchas variables aleatorias. Otra podría ser el formar parte del ``ADN’’ de la distribución Normal. Veamos algunos de sus méritos.\n\nRelación con la media y con la distribución Normal}\nSi una variable aleatoria tiene distribución Normal, basta conocer su media y su desviación típica para calcular cualquier probabilidad relacionada con los valores que puede tomar. Si el peso de unos paquetes de azúcar sigue una distribución Normal con una media de 1000 g y una desviación típica de 15 g, podemos decir que aproximadamente el 95 % de los paquetes tendrán un peso comprendido entre 970 y 1030 g, y también podemos decir que el 68 % tendrá un peso comprendido entre 985 y 1015. Además, podríamos responder cualquier pregunta similar, por ejemplo qué porcentaje de paquetes tendrá un peso por debajo de 980 g (será el 9 %).\n\n\nImportancia en otras distribuciones\nSi la variable considerada no sigue una distribución Normal ¿sigue siendo útil la desviación típica? La respuesta es sorprendente. Si la variable sigue un modelo de probabilidad exponencial, o de Poisson, o una distribución Gamma, o una Beta, entre otras, también podemos usar la media y la desviación típica para responder preguntas de naturaleza similar a las planteadas antes.\n\n\nCuando no se conoce la distribución\n¿Sirve la desviación típica para hacer cálculos aproximados de probabilidades asociadas a una variable aleatoria si no tenemos ni idea de cual es su distribución? Esta pregunta la respondió el matemático ruso Pafnuty Chebyshev (su apellido se puede ver escrito de distintas formas) en la conocida como desigualdad de Chebyshev. La idea es que para una amplia variedad de distribuciones, en el intervalo \\(\\mu \\pm k\\sigma\\) se tiene como mínimo una proporción de observaciones igual a \\(1-1/k^2\\). Es decir, si \\(k=\\sqrt{2}\\), el intervalo es \\(\\mu \\pm \\sqrt{2}\\sigma\\) y podemos afirmar que, con independencia del tipo de distribución, tendremos como mínimo el 50 % de las observaciones dentro de ese intervalo, y si \\(k=2\\) tendremos como mínimo el 75 %. Una curiosa propiedad en la que nuestra pareja media–desviación típica también es protagonista.\n\n\nSu papel en la estimación de la media poblacional\nEn muchas situaciones nuestro interés está en estimar la media poblacional \\(\\mu\\). Para ello tomamos una muestra y calculamos su media \\(\\bar{x}\\) para hacernos una idea del valor desconocido del parámetro \\(\\mu\\).\nCada vez que se tome una muestra, el valor de la media muestral \\(\\bar{x}\\) cambiará, pero sabemos que si tomamos muchas muestras de tamaño \\(n\\), sus medias estarán alrededor del verdadero valor de la media poblacional \\(\\mu\\). Pero decir que están alrededor de \\(\\mu\\) no significa que estén cerca de \\(\\mu\\). ¿Cómo podemos saber que tan cerca están? En la respuesta a esta pregunta la desviación típica también tiene un papel protagonista. La desviación típica de esas medias muestrales es igual a la desviación típica de la población dividida por \\(\\sqrt{n}\\). Esto es verdad para las distribuciones, no solo para la Normal.\n\n\nEstandarización de los datos\nSi le dicen que una vaca pesa 600 kg, a no ser que usted sea ganadero, probablemente ese valor no le dirá si la vaca está muy delgada o si tiene el peso correcto. Sin embargo, si le dicen que su peso está a 0,6 desviaciones típicas por encima de la media podrá deducir que el 73 % de las vacas de ese tipo tienen un peso por debajo y un 27 % por encima, luego la vaca no está delgada.\nUsando un ejemplo más académico, lo mismo ocurre con los residuos que se obtienen después de ajustar una ecuación de regresión. Que un residuo sea igual a 10 no nos dice si es grande o pequeño, es mucho más informativo que nos digan a cuantas desviaciones típicas está de la media, que en este caso siempre es cero. A ese valor se le llama residuo estandarizado.\nEn definitiva, la desviación típica aparece en muchos contextos y con mucha relevancia. El calificativo “típica” resulta en este caso apropiado y bien merecido.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué la desviación típica es la medida típica de dispersión?"
    ]
  },
  {
    "objectID": "0207_Cuartiles_correcta.html",
    "href": "0207_Cuartiles_correcta.html",
    "title": "¿Cuál es la forma correcta de calcular los cuartiles?",
    "section": "",
    "text": "Existen diferentes criterios para determinar los valores de los cuartiles y no todos dan el mismo resultado. Veamos algunos ejemplos.\nJohn Tukey, creador de los boxplots, identifica los cuartiles buscando las medianas de los valores que quedan por encima y por debajo de la mediana global. En la determinación de las medianas de cada mitad de datos incluye la mediana global si el número de datos es impar, pero no la incluye si es par. Por ejemplo, para los datos 2, 4, 6, 8 y 10 (número impar) tenemos:\n\n\n\n\n\n\n\nY si los datos son 2, 4, 6, y 8 (número par):\n\n\n\n\n\n\n\nDavid Moore y George McCabe en su libro “Introduction to the Practice of Statistics”, muy valorado por su carácter pedagógico e innovador, proponen un método similar al de Tukey pero sin incluir la mediana global en la determinación de las medianas de cada una de las mitades. Cuando el número de datos es par el valor de los cuartiles coincide con el método de Tukey, pero en general no coincide cuando el número de datos es impar.\n\n\n\n\n\n\n\nEl paquete de software estadístico Minitab utiliza las expresiones \\(0,25(n+1)\\) y \\(0,75(n+1)\\) para determinar las posiciones de \\(Q_1\\) y \\(Q_3\\) respectivamente. Si la posición obtenida para \\(Q_1\\) es, por ejemplo, 1,25, su valor estará comprendido entre \\(x_1\\) y \\(x_2\\) interpolando de la forma: \\(Q_1 = x_1 + 0,25(x_2-x_1)\\). Utilizando los mismos datos que en los ejemplos anteriores resultaaa:\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8, 10  Posición de \\(Q_1\\): \\(\\;0.25 \\cdot 6 = 1.5\\); \\(\\;\\) Valor de \\(Q_1\\): \\(\\; 2  +0.5(4-2) = 3\\)  Posición de \\(Q_3\\): $;0.75 = 4.5); \\(\\;\\) Valor de \\(Q_3\\): \\(\\; 8 + 0.5(10-8) = 9\\)\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8  Posición \\(Q_1\\): \\(\\;0.25 \\cdot 5 = 1.25)\\); \\(\\;\\) Valor \\(Q_1\\): \\(\\; 2 + 0.25(4-2) = 2.5)\\)  Posición \\(Q_3\\): \\(\\;0.75 \\cdot 5 = 3.75)\\); \\(\\;\\) Valor \\(Q_3\\): \\(\\; 6 + 0.75(8-6) = 7.5)\\)\nExcel dispone de la función CUARTIL que identifica la posición de los cuartiles mediante las expresiones: \\(0.25(n-1)+1\\) y \\(0.75(n-1)+1\\) y los calcula interpolando igual que hace Minitab. Seguramente no satisfechos con su forma de identificar los cuartiles, en las últimas versiones se ha mantenido esa función (se indica que por compatibilidad con versiones anteriores) y se han añadido:\n\n\nCUARTIL.INC: Coincide con la función CUARTIL.\nCUARTIL.EXC: Identifica los cuartiles de la misma forma que Minitab.\n\n\nEn la figura 1 se muestran los cuartiles de nuestros datos con las funciones de Excel (versión 2019).\n\n\n\n\n\n\nFigura 1: Cálculo de los cuartiles con Excel\n\n\n\nEn resumen, los valores obtenidos con los métodos comentados han sido:\n\n\n\n\n\n\n\n\n\n\n\nMétodo\n  Datos: 2, 4, 6, 8\nDatos: 2, 4, 6, 8, 10\n\n\n    Q1\nQ3    \n    Q1\nQ3    \n\n\nTukey\nMoore y McCabe\nMinitab\nExcel, CUARTIL.INC\nExcel, CUARTIL.EXC\n    3\n    3\n    2.5\n    3.5\n    2.5\n7  \n7  \n7.5  \n6.5  \n7.5  \n    4\n    3\n    3\n    4\n    3\n8  \n9  \n9  \n8  \n9  \n\n\n\n\n¿Qué método es el correcto? ¿Cuál debemos utilizar? En la práctica no importa demasiado. Solo se está interesado en conocer los cuartiles cuando el conjunto de datos es grande (nunca si tenemos solo 4 o 5 datos) y en este caso las diferencias entre los distintos métodos no son relevantes. Por ejemplo, si tenemos 500 valores, la posición del primer cuartil con el método de Minitab es 125,25 y con la función CUARTIL.INC de Excel es 125,75. Como habrá poca diferencia entre los valores que ocupan las posiciones 125 y 126, la diferencia en el valor del cuartil no será relevante.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Cuál es la forma correcta de calcular los cuartiles?"
    ]
  },
  {
    "objectID": "0208_Anomalias_boxplot.html",
    "href": "0208_Anomalias_boxplot.html",
    "title": "¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?",
    "section": "",
    "text": "Parece que ese 1,5 es un número caprichoso. También el 1 o el 2 podrían ser buenos candidatos con la ventaja de ser más sencillos, pero veamos que ocurriría si fueran estos los elegidos.\nEn primer lugar debemos tener en cuenta que los valores que aparecen en la zona de anomalías de un boxplot tienen sentido como tales anomalías, si la población de la que provienen es Normal. Consideremos por tanto una distribución Normal, y puestos a elegir una tomaremos \\(Z \\sim N(0;1)\\) ya que los cálculos serán más sencillos y no va a restringir nuestras conclusiones. Para determinar los cuartiles buscamos el valor de \\(z\\) que deja un área de cola de 0,25 y resulta ser: \\(Z_{0,25} = 0,674\\). Por tanto, el rango intercuartílico de una distribución \\(N(0;1)\\) es: \\(IQR = 0,674 - (-0,674) = 1,348\\).\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1 \\cdot IQR}\\)\nEn este caso, fijándonos en el lado derecho, la zona de anomalías empieza en \\(Q_3 + 1 \\cdot IQR = 0,674 + 1,348 = 2,022\\), y \\(P(Z&gt;2,022) = 0,02\\). Por tanto, la probabilidad de que un valor que pertenezca a la distribución considerada aparezca en la zona de anomalías es del 4% (2% por cada lado).\n\n\n\n\n\n\nFigura 1: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 2 \\cdot IQR}\\)\nSi en vez de 1 tomamos el valor 2 como multiplicador del rango intercuartílico, tendremos que: \\(Q_3 + 2 \\cdot IQR = 0,674 + 2 \\cdot 1,348 = 3,37\\) y \\(P(Z&gt;3,37) = 0,0004\\), por lo la probabilidad de que un valor aparezca como anomalía es 0,0008.\n\n\n\n\n\n\nFigura 2: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\nJohn Tukey, que fue el primero en plantear el uso de los boxplots, ya contempló la posibilidad de usar los valores 1 o 2, pero consideró que 1 es demasiado pequeño ya que la zona de anomalías con este criterio incluye valores que no merecen ser considerados como tales, y el valor 2 resulta excesivamente grande ya que aleja demasiado esta zona y por tanto pueden pasar desapercibidos valores que deben ser considerados como anómalos.\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1,5 \\cdot IQR}\\)\nDescartado el 1 y el 2, y estando claro que el más adecuado es un valor entre ellos, aparece la opción del 1,5 como número más sencillo. Este valor define una zona de anomalías con probabilidades muy razonables (p = 0,007) así que este fue el valor que se propuso y así se ha quedado.",
    "crumbs": [
      "Estadística descriptiva",
      "¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?"
    ]
  },
  {
    "objectID": "0209_Valores_atipicos.html",
    "href": "0209_Valores_atipicos.html",
    "title": "¿Qué hay que hacer cuando nos encontramos con valores atípicos?",
    "section": "",
    "text": "Para empezar vamos a decir dos cosas que : 1) ignorarlos como si no existieran o 2) eliminarlos inmediatamente sin más consideraciones.\nSeguramente el error más frecuente es no preocuparse de su posible existencia lanzándose directamente a realizar el test que corresponda. Actuando de esta forma se corre el riesgo de trabajar con algún dato erróneo, ya sea por problemas de formato, porque está en unidades que no corresponden, porque ha habido un error en la medida, o por otras razones. Realizar el test con datos erróneos puede conducir a unas conclusiones totalmente equivocadas.\nTambién puede darse el caso de que los valores sean correctos pero no convenga tomarlos en consideración. Supongamos que se desea analizar si un coche de policía aparcado en la orilla de la carretera recuerda a los conductores cual es la velocidad máxima en ese tramo. Para ello, con un radar oculto, se mide la velocidad de los vehículos en una zona en que la máxima permitida es de 60 km/h. Las velocidades obtenidas (también en km/h) son:\n\n    \n \n\n65\n66\n80\n57\n57\n74\n55\n58\n65\n60\n77\n\n\n\n\n72\n63\n55\n74\n67\n63\n25\n57\n20\n68\n22\n\n\n\n\n61\n59\n77\n72\n23\n67\n58\n66\n71\n56\n63\n\n\n\n\nA continuación se hacen las mismas mediciones pero colocando un coche de la policía aparcado de forma visible al lado de la carretera. En este caso las velocidades son:\n\n  \n\n\n55\n55\n63\n58\n62\n57\n59\n70\n22\n58\n56\n63\n\n\n\n\n55\n61\n58\n60\n24\n55\n75\n58\n61\n63\n20\n63\n\n\n\n\n62\n55\n25\n80\n61\n61\n60\n59\n73\n60\n50\n60\n\n \n\nSi realizamos el test de la \\(t\\) de Student para muestras independientes contrastando la hipótesis nula de que las velocidades medias son iguales frente a la alternativa de que con el coche de la policía son menores, se obtiene un p-valor de 0,167, por lo que del estudio no se podría deducir que el coche de policía tiene efecto disuasorio.\nSin embargo, realizando el análisis exploratorio de los datos, se obtiene el gráfico de la figura 1 en el que se observan unos valores atípicos, tanto con coche de la policía como sin él, que corresponden a vehículos que han pasado a unos 20-25 km/h. ¿Qué hay que hacer con estos valores? Lo primero es preguntarse a qué corresponden, cómo se han producido. En este caso se llega a la conclusión de que corresponden a vehículos de transporte agrícola que siempre van a esta velocidad, porque no pueden ir a más. Está claro que la posible influencia del método disuasorio no va con este tipo de vehículos y lo más razonable es excluirlos del estudio.\n\n\n\n\n\n\nFigura 1: Velocidades de paso (km/h) con valores atípicos (1)\n\n\n\nAl eliminar estos valores disminuye la variabilidad de las muestras y la diferencia de medias pasa a ser claramente significativa.\nPero tampoco hay que caer en la tentación de eliminar las anomalías automáticamente. Si los valores obtenidos hubieran sido los que se reflejan en la figura 2, que son iguales que los anteriores añadiendo 115, 118, 120 y 117 a la velocidad sin coche de policía, tendríamos que en este grupo hay dos conjuntos de valores atípicos, los dos aproximadamente a la misma distancia del centro de los datos, pero aunque hemos visto que era razonable quitar el conjunto de los valores bajos, no hay ninguna razón para quitar el de los altos, que corresponden a coches que circulan a una velocidad mucho mayor a la permitida.\n\n\n\n\n\n\nFigura 2: Velocidades de paso (km/h) con valores atípicos (2)\n\n\n\nOtro aspecto a tener en cuenta es que el análisis de las anomalías puede ser la parte más interesante del estudio. El gráfico de la figura 3 muestra la relación entre el rendimiento y temperatura en una reacción química. Aparecen unos valores claramente anómalos, ¿qué hacer con estos valores? ¿eliminarlos y olvidarse de ellos?\n\n\n\n\n\n\nFigura 3: Rendimiento en función de la temperatura\n\n\n\nSi lo hiciéramos así nos perderíamos la oportunidad de incorporar información valiosa a nuestro conocimiento del proceso. Lo más adecuado sería preguntarnos: ¿Por qué se han dado estas situaciones?, ¿qué ha ocurrido a 185 grados para que se hayan producido unos rendimientos tan anormalmente altos?, ¿por qué una vez a 205 grados y se obtuvo un rendimiento tan bajo? Es posible que la respuesta a estas preguntas aporte una información que puede ser muy útil para tener un mayor dominio del proceso.\nEn definitiva, ante un valor atípico lo que hay que hacer es intentar averiguar el por qué se ha producido. Si está claro que la causa es un error se elimina y asunto resuelto. Si no es un error habrá que valorar la conveniencia de incluirlo en el estudio, según sea la razón por la cual se ha producido y la frecuencia con que se esperan valores similares.\nTambién es verdad que en algunos casos uno no sabe si mantener el valor atípico o quitarlo. Cuando se da esta situación una buena idea es realizar el análisis con y sin la presunta anomalía. Si se obtienen las mismas conclusiones la disyuntiva deja de tener importancia. En caso contrario el resultado va a ser dudoso hagamos lo que hagamos, a no ser que podamos recoger más datos.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué hay que hacer cuando nos encontramos con valores atípicos?"
    ]
  },
  {
    "objectID": "0210_Curtosis.html",
    "href": "0210_Curtosis.html",
    "title": "¿Para qué sirve la curtosis?",
    "section": "",
    "text": "La curtosis es una medida de las llamadas “de forma” que cuantifica lo esbelta o aplanada que es una distribución de probabilidad (versión poblacional) o su equivalente cuando se refiere a un conjunto de datos (versión muestral). Se toma como referencia el valor que corresponde a la distribución Normal. Si una distribución tiene una curtosis mayor que la Normal hay que interpretarlo como que su parte central es más picuda (con más “apuntamiento”), y si el valor es menor será más plana, lo cual se traduce en que sus colas son más “pesadas”, es decir, que es más probable encontrar valores alejados de la media.\nSobre cual es el valor de la curtosis para la distribución Normal existen dos criterios. Su fórmula definida de forma natural es: \\(E(X-\\mu)^4]/\\mu^4\\) y para la Normal, con independencia del valor de sus parámetros, da un valor igual a 3. Para tomar este valor como referencia, también se define como la expresión anterior menos 3, de forma que para la Normal es igual a cero. Cuando se dan valores de la curtosis, no siempre está claro cual es el criterio con que se ha calculado. Algunos textos se refieren a la curtosis como el resultado de aplicar la expresión anterior y al como ese valor menos 3.\nA pesar de que la curtosis está relacionada con la forma de la distribución, no es una medida de variabilidad. Una distribución uniforme definida en el intervalo (\\(-\\sqrt{3};\\; \\sqrt{3}\\)) tiene \\(\\mu\\) = 0 y \\(\\sigma\\) = 1, al igual que una N(0; 1), pero la uniforme tiene una curtosis de 9/5, mientras que en la Normal es igual a 3.\nEn la mayoría de paquetes estadísticos cuando se piden las estadísticas descriptivas, además de las típicas medidas de tendencia central y de dispersión se obtiene la curtosis y su inseparable compañero, el coeficiente de asimetría (en inglés ), que seguramente son las medidas menos atendidas.\n¿Para que sirven? Ambas son útiles para caracterizar las distribuciones de probabilidad a nivel teórico, especialmente en campos como los mercados financieros, o en hidrología, donde los valores extremos se dan con mayor probabilidad que en la distribución Normal y pueden tener consecuencias muy importantes. También juegan un papel destacado en algunas situaciones en las que para evaluar la robustez de un método o de un estimador, conviene probar con distribuciones de colas livianas y de colas pesadas, es decir, con distinta curtosis.\nSin embargo, tienen poco interés para describir la forma que presentan los valores de una muestra. Es mejor hacer un gráfico, como un diagrama de puntos o un histograma. El gráfico no puede ser sustituido por estas medidas, que tampoco aportan nada relevante cuando ya se tiene.\nAdemás, son malos estimadores de los valores correspondientes a la población. La figura 1 muestra los valores de la curtosis obtenidos por simulación de muestras de tamaño 10, 20, 50 y 100, de una población exponencial con \\(\\lambda\\)=1, a la que corresponde una curtosis igual a 9. Ya se ve que la estimación es sesgada, especialmente con muestras pequeñas, pero incluso con muestras tan grandes como n=100, un porcentaje muy alto de las estimaciones subestiman la curtosis verdadera. También se observa mucha variabilidad en los resultados, ya que los valores extremos afectan mucho al aparecer en la fórmula elevados a la cuarta potencia.\n\n\n\n\n\n\n\nFigura 1: Valores de la curtosis en muestras del tamaño n que se indica obtenidas de una distribución exponencial (curtosis = 9).\n\n\n\n\nSi lo que pretendemos es utilizar los valores de la curtosis y el coeficiente de asimetría para predecir el tipo de distribución de que provienen los datos, también lo tenemos mal. La figura 2 muestra los valores de ambas medidas calculadas para 100 muestras de tamaño \\(n = 50\\) de la misma distribución exponencial que hemos usado antes. Los verdaderos valores de la distribución (Curtosis = 9; Asimetría = 2) están marcados con un cuadrado rojo. Ya se ve que los valores muestrales no permiten identificar este punto como aquel que representa los parámetros que se están estimando.\n\n\n\n\n\n\nFigura 2: Valores de la curtosis y del coeficiente de asimetría de 100 muestras de tamaño 50 de una distribución exponencial. Los valores de la población están marcados con un cuadrado rojo.\n\n\n\n\nEn resumen tanto la curtosis como el coeficiente de asimetría forman parte de las señas de identidad de una distribución de probabilidad y tienen interés en el marco de la caracterización de los modelos teóricos, pero como medidas descriptivas son muy poco fiables.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Para qué sirve la curtosis?"
    ]
  },
  {
    "objectID": "0211_Graficos_usar.html",
    "href": "0211_Graficos_usar.html",
    "title": "¿Qué gráfico debo usar para representar mis datos?",
    "section": "",
    "text": "Naturalmente, depende del tipo de datos y de las características que queramos observar. Veamos algunas recomendaciones para las situaciones más habituales.\n\nVariabilidad\nEl histograma es una buena opción cuando el interés se centra en la variabilidad de los datos, la forma de su distribución, el valor en que están centrados y el rango en que se mueven. La figura 1 compara la producción de dos máquinas que elaboran un producto con un peso que debe estar en el intervalo 210 \\(\\pm\\) 10 g. Se han añadido unas líneas que muestran el valor objetivo y los límites de tolerancia. Se ve muy claro que se debería ajustar la máquina 1.\n\n\n\n\n\n\nFigura 1: Histogramas de los pesos producidos por dos máquinas\n\n\n\nSi se tienen pocos datos, un diagrama de puntos puede ser más adecuado. La figura 2 muestra que los valores del grupo A se sitúan en torno a 10 mientras que en el grupo B tienden a ser mayores.\n\n\n\n\n\n\nFigura 2: Diagramas de puntos para comparar dos conjutos de datos\n\n\n\n\n\nEvolución\nEl diagrama en serie de tiempo es el más adecuado cuando interesa observar la evolución de una variable. La figura 3 muestra los diámetros de 180 piezas consecutivas fabricadas por dos tornos. Se han añadido los límites de tolerancia y se aprecia claramente que los valores del torno B presentan una tendencia que conduce a la producción de piezas defectuosas.\n\n\n\n\n\n\nFigura 3: Evolución del diámetro de las piezas producidas\n\n\n\n\n\nRelación entre dos variables cuantitativas\nLa mejor forma de visualizar esta relación es a través de un gráfico de dispersión, como los de la figura 4, que ilustran la relación entre la velocidad máxima y la potencia de un conjunto 30 coches.\n\n\n\n\n\n\nFigura 4: Diagramas de dispersión. Versión clásica e incluyendo también información sobre una tercera variable cuantitativa y otra cualitativa\n\n\n\nA la izquierda tenemos un diagrama clásico en el que todos los puntos son del mismo tamaño y color. En el de la derecha los puntos se han sustituido por círculos de área proporcional a una tercera variable cuantitativa, que en este caso son las emisiones de CO2. Además, cada círculo es de un color que depende de si el motor es de gasolina o diesel. Estos gráficos con círculos de diferente tamaño que incorporan una nueva variable a la representación, se suelen denominar diagramas de burbujas.\n\n\nRelación entre una variable cuantitativa y otra cualitativa\nSe pueden usar diagramas similares al de dispersión: para cada valor de la variable cualitativa -en el eje horiontal- se colocan los puntos que representan los valores de la variable cuantitativa (figura 5, izquierda). Para evitar que los puntos queden superpuestos y se pierda información sobre su cantidad, muchos programas incluyen la opción “jitter” que les da un cierto “temblor” sacrificando precisión en sus coordenadas pero ganando en visión de cantidad.\nUna alternativa, especialmente recomendable si se tienen muchos puntos, es representar boxplots como en la figura de la derecha.\n\n\n\n\n\n\nFigura 5: Variable cuantitativa en función de los de otra cualitativa\n\n\n\n\n\nFrecuencias para variables discretas o cualitativas\nEl uso de diagramas de barras suele ser la forma más clara de representar estos datos. Son similares al histograma pero las barras no se tocan, ya que no hay continuidad en la variable que representan. Los programas que realizan este tipo de gráficos también permiten estratificar las barras tal como se muestra en la figura 6 derecha.\n\n\n\n\n\n\nFigura 6: Volumen de ventas en distintas zonas del país. A la derecha, estratificado por tipo de producto.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué gráfico debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0212_Graficos_NO_usar.html",
    "href": "0212_Graficos_NO_usar.html",
    "title": "¿Qué gráfico NO debo usar para representar mis datos?",
    "section": "",
    "text": "Los gráficos que no se deben usar pueden ser muchos. Aquí comentamos algunas “tentaciones” que conviene evitar, especialmente en contextos científicos y técnicos donde el objetivo es transmitir la información de la forma más clara y fidedigna posible.\n\nGráficos con tres dimensiones\nDeben evitarse porque la profundidad no aporta ninguna información y en cambio dificulta la interpretación de las escalas. Algunas veces se utilizan en contextos publicitarios en que se prioriza el impacto visual.\n\n\n\n\n\n\n\n\n\n\n\nFigura 1: Gráficos con una tercera dimensión y sin ella. En estos últimos la información se percibe de forma más clara y directa.\n\n\n\n\n\nDiagramas de pastel, especialmente con tres dimensiones\nLos diagramas de pastel (circulares o de queso, o pizza, si lo prefiere) son representaciones muy utilizadas aunque no tan apreciadas en contextos científico-técnicos donde -en general- se prefieren los diagramas de barras. Si se representan en tres dimensiones y desgajando un sector que se quiere destacar ya entramos en el terreno de los gráficos tendenciosos. Una alternativa similar que transmite la información de forma más clara son los llamados gráficos donut.\n\n\n\n\n\n\nFigura 2: En el gráfico de la izquierda parece que el mayor sector corresponde a la sanidad, cuando en realidad no es así.\n\n\n\n\n\nGráficos que ocupan mucho espacio y contienen poca información\nDedicar media página de un informe, o toda la pantalla de una presentación, a un gráfico de pastel que solo da un porcentaje (de la población con acceso a internet, por ejemplo) no parece una buena forma de aprovechar el papel o las pantallas de la presentación. Es más grave si se van presentando este tipo de gráficos de forma repetitiva (un diagrama para cada región, por ejemplo).\n\n\nGráficos con escalas tendenciosas\nAdaptar la escala del eje vertical según convenga es un conocido recurso para influir en la impresión que da el gráfico. La figura 3 podría representar las medidas de audiencia de cuatro cadenas de televisión. En el gráfico de la izquierda se observan unas diferencias muy claras y TV1 parece tener la mitad de la audiencia que TV4. Sin embargo, si la escala parte de cero, que es lo correcto cuando se realizan comparaciones, apenas se aprecian esas diferencias.\n\n\n\n\n\n\nFigura 3: En las comparaciones, lo correcto es partir de cero.\n\n\n\nEn los gráficos en serie temporal, si la escala vertical cubre todo el rango de variación de los datos, dará la impresión de que se ha producido un gran cambio, pero si se parte de cero, puede ocurrir que ese cambio -poco o mucho- apenas se note. En este caso, un buen criterio es que el rango de variación ocupe unos \\(2/3\\) de la amplitud de la escala.\n\n\n\n\n\n\nFigura 4: En los diagramas temporales se recomienda que el rango de variación de los datos ocupe 2/3 de la amplitud de la escala.\n\n\n\n\n\nComparar situaciones usando distintas escalas\nObserve los histogramas de la figura 5. Parece que la máquina 2 produce con más variabilidad que la 1 pero no es así. Los dos histogramas se han construido con los mismos datos. El problema está en que las escalas son distintas.\n\n\n\n\n\n\nFigura 5: No es lo que parece. Ojo con las escalas.\n\n\n\n\n\nRectas de tendencia\nNo deben añadirse líneas de tendencia cuando la mayoría de los puntos están amontonados en poco espacio. En la figura 6 hay 50 puntos en el intervalo 1 \\(\\leq\\) X \\(\\leq\\) 10 que no muestran ninguna relación entre X e Y (gráfico de la derecha). Solo 3 puntos apartados del resto, que seguramente son valores singulares o anómalos, no pueden marcar la tendencia de todo el conjunto de datos.\n\n\n\n\n\n\nFigura 6: La recta no representa la relación entre X e Y.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué gráfico NO debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html#footnotes",
    "href": "0203_Variabilidad.html#footnotes",
    "title": "¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "El circuito es defectuoso si su intensidad está por debajo de 7 A o por encima de 13 A, es decir, si la resistencia que se coloca está por encima de 14,3 \\(\\Omega\\) o por debajo de 7,7 \\(\\Omega\\). Para huir de esos valores lo mejor es pedir un valor nominal que esté en el centro, es decir: (7,7+14,3)/2 = 11 \\(\\Omega\\). &lt;&gt;↩︎",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0213_Software.html",
    "href": "0213_Software.html",
    "title": "¿Cuales son los mejores programas para analizar datos gráficamente?",
    "section": "",
    "text": "En internet hay muchas páginas donde se explica cuales son los mejores paquetes para la representación gráfica de datos. Sin tener un conocimiento exhaustivo de todo lo que existe –que además va cambiando–, creemos que vale la pena tener presentes las siguientes opciones:\n\nHojas de cálculo\nA menudo injustamente ignoradas en los ambientes universitarios más allá del ámbito de la gestión de empresas. Tienen muchas posibilidades y vale la pena dedicar tiempo a conocer sus posibilidades. Los recursos para el filtrado de datos y la realización de las llamadas “tablas dinámicas” permiten realizar análisis detallados con bastante facilidad.\n\n\nSoftware para la construcción de “Cuadros de control” (Dahsboards)\nUno de los más conocidos es Power BI, que se relaciona muy bien con Excel y tiene muchas posibilidades para la creación de gráficos interactivos: se hace clic sobre una parte del gráfico y se abren otros gráficos que detallan esa parte. Existen otros softwares de este tipo (como Tableau) pero son caros y solo al alcance de las empresas. Power BI es gratuito si se instala localmente, es decir, solo analiza datos que están en el mismo ordenador donde se ha instalado. Esto es útil para aprender su funcionamiento y también para usarlo en el ámbito académico. Las empresas tienen sus datos en bases de datos centralizadas (o eso quisieran) y necesitan la versión de pago.\n\n\nLenguajes de programación para análisis estadísticos\nEl más usado en el ámbito universitario –y nunca defrauda– es R. Existen numerosas librerías que se pueden instalar fácilmente y que amplían las posibilidades del paquete base. Cabe destacar la librería Shiny que permite crear interficies amigables e interactivas que se pueden distribuir como una página web. La ventaja de R es que es gratuito y que tiene muchas posibilidades pero hay que dedicar tiempo a dominarlo y, si no se usa, se olvida rápido. Una alternativa a R es el lenguaje Python, también con muchas librerías para realizar análisis estadísticos.\n\n\nPaquetes de software estadístico gratuitos\nUna buena opción son los paquetes de software que utilizan el lenguaje y los algoritmos de R añadiendo una presentación con menús, de forma que el proceso de aprendizaje es muy corto y toda la energía se puede dedicar al análisis de los datos. De este tipo tenemos, entre otros:\n\nBlueSky Statistics: Tiene muchas posibilidades de análisis gráfico e incluye también una gran variedad de técnicas estadísticas. Tiene un aspecto muy profesional, con una versión gratuita (más que suficiente para los objetivos de un curso introductorio) y también una versión de pago, con más servicios, para empresas.\nJamovi: Es el que más nos gusta para un curso introductorio. Limpio y claro, prácticamente no necesita explicación. Permite realizar las representaciones gráficas más habituales y aplicar las técnicas de análisis que se incluyen los primeros cursos. Presenta también la peculiaridad de que se pueden añadir “paquetes” desarrolados por otras personas –igual que con R– lo que puede darle mucho recorrido.\nJASP: Es intuitivo y fácil de usar. Vale la pena tenerlo en cuenta. Con muchas posibilidades de análisis –incluyendo estadística bayesiana– que van más allá de los contenidos de un curso de introductorio.\nR Comander: Ha sido durante muchos años la interfaz utilizada para facilitar el uso de R en cursos introductorios. Se ha convertido en un estándar pero creemos que ahora existen mejores alternativas.\n\n\n\nPaquetes de software estadístico de pago\nHay bastantes, aunque unos pocos destacan sobre el resto. Nosotros usamos Minitab que tiene la ventaja de ser muy fácil de usar. Existen licencias anuales con precios especiales para estudiantes y también licencias de campus para universidades que permiten a los estudiantes instalarse una copia en su ordenador personal (la licencia es anual pero se puede ir renovando mientras se es estudiante). Además de una amplia gama de representaciones gráficas incluye la posibilidad de realizar análisis estadísticos avanzados. El problema es que si el acceso gratuito tiene fecha de caducidad, como ocurre con las licencias de campus para estudiantes, hay que buscar una alternativa.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Cuales son los mejores programas para analizar datos gráficamente?"
    ]
  }
]