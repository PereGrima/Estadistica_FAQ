[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística. Preguntas frecuentes",
    "section": "",
    "text": "PRESENTACIÓN\nRespondemos a preguntas que pueden surgir en un curso general de estadística. Tratan sobre el material del curso y también sobre temas que pueden aparecer en discusiones sobre lo que es la estadística, sus dificultades y sus aplicaciones.\nEs el resultado de nuestra experienca moviéndonos en este terreno y esperamos que sea útil a estudiantes, profesores que empiezan, e intersados por la estadística en general. Cualquier comentario o sugerencia será bienvenido.\nVersión 4.0 (Marzo de 2026)\n\nAutores\n\nRoberto Behar, profesor en la Universidad del Valle, en Cali, Colombia.\nPere Grima, profesor en la Universitat Politècnica de Catalunya, en Barcelona, España\n\n\n\nLibro impreso\nSe puede comprar en Amazon.es o Amazon.com. Está impreso en color, encuadernado con tapa blanda e incluye prólogo, índices y referencias.\n\n\nLicencia\nSe publica bajo una licencia Creative Commons: CC BY-NC-ND 4.0.",
    "crumbs": [
      "PRESENTACIÓN"
    ]
  },
  {
    "objectID": "0213_Software.html",
    "href": "0213_Software.html",
    "title": "¿Cuales son los mejores programas para analizar datos gráficamente?",
    "section": "",
    "text": "En internet hay muchas páginas donde se explica cuales son los mejores paquetes para la representación gráfica de datos. Sin tener un conocimiento exhaustivo de todo lo que existe –que además va cambiando–, creemos que vale la pena tener presentes las siguientes opciones:\n\nHojas de cálculo\nA menudo injustamente ignoradas en los ambientes universitarios más allá del ámbito de la gestión de empresas. Tienen muchas posibilidades y vale la pena dedicar tiempo a conocer sus posibilidades. Los recursos para el filtrado de datos y la realización de las llamadas “tablas dinámicas” permiten realizar análisis detallados con bastante facilidad.\n\n\nSoftware para la construcción de “Cuadros de control” (Dahsboards)\nUno de los más conocidos es Power BI, que se relaciona muy bien con Excel y tiene muchas posibilidades para la creación de gráficos interactivos: se hace clic sobre una parte del gráfico y se abren otros gráficos que detallan esa parte. Existen otros softwares de este tipo (como Tableau) pero son caros y solo al alcance de las empresas. Power BI es gratuito si se instala localmente, es decir, solo analiza datos que están en el mismo ordenador donde se ha instalado. Esto es útil para aprender su funcionamiento y también para usarlo en el ámbito académico. Las empresas tienen sus datos en bases de datos centralizadas (o eso quisieran) y necesitan la versión de pago.\n\n\nLenguajes de programación para análisis estadísticos\nEl más usado en el ámbito universitario –y nunca defrauda– es R. Existen numerosas librerías que se pueden instalar fácilmente y que amplían las posibilidades del paquete base. Cabe destacar la librería Shiny que permite crear interficies amigables e interactivas que se pueden distribuir como una página web. La ventaja de R es que es gratuito y que tiene muchas posibilidades pero hay que dedicar tiempo a dominarlo y, si no se usa, se olvida rápido. Una alternativa a R es el lenguaje Python, también con muchas librerías para realizar análisis estadísticos.\n\n\nPaquetes de software estadístico gratuitos\nUna buena opción son los paquetes de software que utilizan el lenguaje y los algoritmos de R añadiendo una presentación con menús, de forma que el proceso de aprendizaje es muy corto y toda la energía se puede dedicar al análisis de los datos. De este tipo tenemos, entre otros:\n\nBlueSky Statistics: Tiene muchas posibilidades de análisis gráfico e incluye también una gran variedad de técnicas estadísticas. Tiene un aspecto muy profesional, con una versión gratuita (más que suficiente para los objetivos de un curso introductorio) y también una versión de pago, con más servicios, para empresas.\nJamovi: Es el que más nos gusta para un curso introductorio. Limpio y claro, prácticamente no necesita explicación. Permite realizar las representaciones gráficas más habituales y aplicar las técnicas de análisis que se incluyen los primeros cursos. Presenta también la peculiaridad de que se pueden añadir “paquetes” desarrolados por otras personas –igual que con R– lo que puede darle mucho recorrido.\nJASP: Es intuitivo y fácil de usar. Vale la pena tenerlo en cuenta. Con muchas posibilidades de análisis –incluyendo estadística bayesiana– que van más allá de los contenidos de un curso de introductorio.\nR Comander: Ha sido durante muchos años la interfaz utilizada para facilitar el uso de R en cursos introductorios. Se ha convertido en un estándar pero creemos que ahora existen mejores alternativas.\n\n\n\nPaquetes de software estadístico de pago\nHay bastantes, aunque unos pocos destacan sobre el resto. Nosotros usamos Minitab que tiene la ventaja de ser muy fácil de usar. Existen licencias anuales con precios especiales para estudiantes y también licencias de campus para universidades que permiten a los estudiantes instalarse una copia en su ordenador personal (la licencia es anual pero se puede ir renovando mientras se es estudiante). Además de una amplia gama de representaciones gráficas incluye la posibilidad de realizar análisis estadísticos avanzados. El problema es que si el acceso gratuito tiene fecha de caducidad, como ocurre con las licencias de campus para estudiantes, hay que buscar una alternativa.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Cuales son los mejores programas para analizar datos gráficamente?"
    ]
  },
  {
    "objectID": "0101_Estadistica_Matematicas.html",
    "href": "0101_Estadistica_Matematicas.html",
    "title": "¿La estadística es una parte de las matemáticas?",
    "section": "",
    "text": "La materia prima de los análisis estadísticos son los datos –en general numéricos– y como los números pertenecen al reino de las matemáticas, muchas veces se considera que la estadística es una parte de las matemáticas. Los métodos estadísticos, por supuesto, usan las matemáticas, pero la estadística tiene un enfoque, unos objetivos y una metodología que son diferentes.\nEl pensamiento matemático es deductivo. Se parte de unos axiomas y mediante la lógica se deducen unos teoremas que se cumplen siempre. Este proceso deductivo persigue la resolución de problemas que se sitúan en el ámbito de los modelos abstractos, de lo teórico, y su resolución exige prestar mucha atención a la notación que se usa y a la aplicación de las reglas, propiedades y otros teoremas demostrados previamente.\nEl pensamiento estadístico es inductivo. Se parte de unos datos y a partir de ellos se estiman características de la población de la que provienen. El cómo seleccionar y evaluar la calidad de esos datos también forma parte del problema. Mientras que las matemáticas buscan encontrar soluciones exactas en el mundo de lo simbólico, en estadística estamos intentando buscar soluciones aproximadas pero útiles. En matemáticas un solo caso que no se cumpla ya es suficiente para declarar que una proposición es falsa. En estadística sabemos que el hecho de que un fumador de cajetilla diaria llegue a los 90 años no invalida la teoría de que el tabaco perjudica la salud.\nLa estadística sirve para responder preguntas en el terreno de la investigación empírica, preguntas del tipo: ¿Cuál de las resinas disponibles da mejores resultados en una depuradora de agua? ¿qué principio activo es más eficaz para curar una enfermedad? ¿Qué porcentaje de ciudadanos está de acuerdo con la política del gobierno? Estas preguntas no se pueden responder desde las matemáticas. Hay que hacer un experimento o una encuesta y sabemos que las conclusiones que se extraigan no serán un teorema matemático. Si se repite el experimento/encuesta saldrán otros resultados, pero tenemos herramientas matemáticas que, bajo ciertos supuestos, nos permiten responder a las preguntas planteadas informando también sobre la confianza con la que damos nuestras respuestas.\nDesde luego, la estadística tiene en la matemática una de sus herramientas más útiles. La teoría de la probabilidad –uno de los pilares de la estadística– se desarrolla íntegramente con el proceso deductivo de la matemática. La teoría de la probabilidad sí es una parte de las matemáticas. Necesitamos la teoría de las distribuciones de probabilidad para calcular probabilidades en el terreno de lo práctico.\nPero el enfoque y las prioridades de la estadística no son los mismos que los de las matemáticas. No son lo mismo, ni la estadística es una parte de las matemáticas.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿La estadística es una parte de las matemáticas?"
    ]
  },
  {
    "objectID": "0102_Probabilidad_Estadistica.html",
    "href": "0102_Probabilidad_Estadistica.html",
    "title": "¿El cálculo de probabilidades es una parte de la estadística?",
    "section": "",
    "text": "La teoría de la probabilidad y el cálculo de probabilidades son una parte de las matemáticas. Una parte que puede resultar muy útil en el marco de un análisis estadístico, pero no creemos que deba considerarse parte de la estadística.\nEn los problemas de cálculo de probabilidades se suponen conocidas las características de la población (que en muchos casos es una población teórica) y nos preguntamos por las características de una muestra obtenida de esa población. Ejemplos típicos de problemas de cálculo de probabilidades son:\n\n¿Cuál es la probabilidad de que realizando una apuesta nos toque el primer premio de la lotería primitiva (una lotería tipo 6/49)?\nSi una máquina fabrica un 3% de piezas defectuosas ¿Cuál es la probabilidad de que en un lote de 30 piezas haya alguna defectuosa?\n\nEn estadística nos ocupamos justo de lo contrario. Conocemos las características de una muestra que consideramos representativa de su población y lo que interesa es estimar (“hacernos una idea de”) las características de esa población. Ni que decir tiene que la muestra no vine dada y hay que pensar en la mejor manera de elegirla con los recursos disponibles. Después habrá que analizar los valores obtenidos para realizar las estimaciones. Todo esto, desde plantear claramente las preguntas que se desea responder hasta explicar las conclusiones a que se ha llegado, está lleno de dificultades que no tienen nada que ver con el cálculo de probabilidades. Problemas de estadística serían:\n\nCon base en los resultados de un sondeo electoral, estimar el número de escaños que obtendrá un partido en las próximas elecciones.\nA partir de los resultados de un estudio clínico, determinar si un nuevo medicamento es más eficaz que el usado habitualmente.\n\nClaro que nuestras estimaciones o nuestras conclusiones nunca son apuestas seguras y ahí es donde aparece el lenguaje de la probabilidad: Informamos sobre la probabilidad de que el número de escaños se encuentre entre determinados valores, o afirmamos que con una determinada probabilidad de error (que se fija de antemano y que se designa “nivel de significación”) puede decirse que el nuevo medicamento es eficaz. Pero, en general, el uso que hacemos de la probabilidad no requiere saber resolver problemas complicados de combinatoria o de cálculo de probabilidades. Basta con unas reglas bastante sencillas y al alcance de todos.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿El cálculo de probabilidades es una parte de la estadística?"
    ]
  },
  {
    "objectID": "0103_Que_es_Estadistica.html",
    "href": "0103_Que_es_Estadistica.html",
    "title": "¿Qué es la estadística?",
    "section": "",
    "text": "Existen muchas definiciones de lo que es la estadística. En el ámbito académico una de las más cortas y acertadas nos la dio un estudiante cuando discutíamos este tema el primer día de clase: “La estadística es una asignatura”. Desde luego tenía razón.\nSeguramente la estadística es la asignatura que aparece en los planes de estudios de más titulaciones, pero no podemos decir que sea la más apreciada. Muchos estudiantes la consideran una asignatura más bien antipática, donde se realizan consideraciones ininteligibles que poco o nada tiene que ver con su vocación y sus intereses. Quizá por eso, una vez superada se produce un cierto desapego y la estadística se que queda en eso, en un asignatura.\nY por si esto fuera poco, en las antípodas de la visión formal y académica, se tiene también una visión un tanto despectiva donde la estadística se relaciona con porcentajes tendenciosos, con gráficos manipulados y con números que siempre hay manera de presentar de la forma que convenga y, claro, unas técnicas que sirven lo mismo para justificar que algo es blanco como que es negro, no son nada fiables para saber de que color son las cosas.\n\nUn poco de historia\nLa estadística como “cuentas del Estado” (de ahí su nombre) surgió cuando los gobernantes necesitaron conocer cuantas personas vivían en sus dominios, el volumen de las cosechas o los impuestos que cada familia debía pagar, y de eso hace ya miles de años. Esto significaba recoger datos y ordenarlos, tabularlos y quizá realizar algunos cálculos que estarían dentro de lo que hoy denominamos”estadística descriptiva”. Esto fue la estadística hasta los inicios del siglo XX, hace cuatro días.\nCon unas motivaciones totalmente distintas –en este caso relacionadas con la búsqueda de estrategias en los juegos de azar –, en el siglo XVII se empezó a estudiar seriamente (“matemáticamente”) el cálculo de probabilidades. Más tarde, la estadística clásica encontró en las probabilidades el lenguaje y las herramientas que le permitían hacer estimaciones sobre la población conociendo solo una parte e informando sobre el grado de incertidumbre de sus conclusiones. Esto aumentó enormemente sus posibilidades y su campo de actuación.\nLa estadística que se explica en los cursos introductorios se creó, fundamentalmente, en la primera mitad del siglo XX. Al inicio de esta nueva época los métodos estadísticos se desarrollaron en torno a aplicaciones concretas (seguros de vida, ciencias naturales, industria, agricultura…) pero el interés por crear nuevos métodos para el análisis de los datos (¡estaba todo por hacer!) se despegó de las aplicaciones prácticas, especialmente en el ámbito académico, y se empezaron a crear matemáticas que poco o nada tenían que ver con el estudio de la realidad que nos rodea. Esta irrupción de las matemáticas en la estadística también ha tenido repercusiones en la docencia. Muchas veces los profesores de estadística son y actúan como profesores de matemáticas, lo cual seguramente tiene bastante que ver con las causas del desafecto por la asignatura en aquellos estudiantes para los cuales su vocación es otra.\n\n\nEstadística y adquisición de conocimiento\nMejoramos nuestra conocimiento a base de plantearnos preguntas e intentar responderlas. La estadística juega un papel protagonista cuando para responder a esas preguntan se necesitan datos. Ejemplos de preguntas podrían ser:\n\n\nBiología: ¿Cómo evoluciona el número de ejemplares de cierto tipo de ave en un territorio?\nMedicina: ¿És eficaz una nueva vacuna?\nMedio ambiente: ¿Qué porcentaje de plástico se recicla?\nEconomía: ¿Cuánto están subiendo los precios?\nIngeniería: ¿Qué catalizador aumenta más el rendimiento de una reacción química?\nMarqueting: ¿Qué tipo de envoltorio logra mayores ventas?\nPrevisiones: ¿Cuánta electricidad se consumirá mañana?\n\n\nLa estadística trata de cómo recoger y de cómo analizar los datos para responder a las preguntas planteadas. Raramente se consiguen todos los datos que nos gustaría tener, y menos todavía con las características deseadas, pero la estadística tiene herramientas para enfrentarse a estas situaciones y sacar el máximo provecho de los recursos disponibles, todo esto, como ya sabemos, con una medida conocida de la confianza con que podemos ofrecer nuestras conclusiones.\nLa estadística está muy relacionada con el método científico, que se basa en la observación, medición, experimentación, planteamiento y contraste de las hipótesis con datos experimentales… También cabe poner de manifiesto que el “elemento desencadenante”, lo que pone en marcha el proceso, es la pregunta que nos planteamos. No nos gusta analizar datos “para ver lo que sale”, siempre buscamos algo y saber lo que se busca -hacerse la pregunta adecuada- también es importante. Obtener los datos necesarios suele ser la parte más delicada y laboriosa. Una vez se tienen los datos, muchas veces las preguntas se pueden responder con análisis gráficos sencillos, aunque en otros casos hay que recurrir a técnicas más sofisticadas.\n\n\nNuestra definición\nLa estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos en el proceso de adquisición de nuevos conocimientos, en un ambiente en el cual casi siempre están presentes la variabilidad y la incertidumbre.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿Qué es la estadística?"
    ]
  },
  {
    "objectID": "0104_DataScience.html",
    "href": "0104_DataScience.html",
    "title": "¿Qué es la ciencia de datos (o Data Science)?",
    "section": "",
    "text": "El mantra que tanto hemos repetido en las clases de Estadística de que “los datos son siempre un recurso escaso” dejó de ser cierto en muchos casos, aunque en muchos otros (en los sondeos electorales, sin ir más lejos) sigue siendo tan válido como siempre.\nCada vez es más habitual capturar datos y enviarlos automáticamente a esa nube que parece no tener límites. Por ejemplo, las grandes instalaciones de aire acondicionado pueden colocar sensores que captan la presión del aire o las vibraciones en puntos clave de las máquinas y envían a la nube esos valores que pueden ser recuperados y analizados desde cualquier lugar. Es también muy típico el ejemplo de los supermercados que pueden almacenar la información de lo que ha comprado cada uno de sus clientes, pudiendo realizar también un seguimiento detallado de la evolución de las compras de los que tienen tarjeta de fidelidad.\nDespués de ser capaces de almacenar tantos datos, lo siguiente es intentar sacar provecho de ellos. ¿Cuándo conviene cambiar los filtros o sustituir una pieza que está a punto de romperse? ¿qué oferta conviene realizar a determinado tipo de clientes? En muchos casos basta con aplicar técnicas clásicas de análisis exploratorio de datos o con la construcción de modelos conceptualmente muy sencillos, pero en otros es necesario utilizar técnicas más sofisticadas y, en todos los casos, el manejo y la gestión de grandes volúmenes de datos entraña unas dificultades específicas.\nBásicamente, lo que se ha dado en llamar “Ciencia de Datos” es un conjunto de conocimientos relacionados con la captación, almacenamiento y análisis de datos para crear algoritmos que permitan identificar patrones, casi siempre con el objetivo de hacer previsiones. Algunos de estos algoritmos son capaces de reajustarse automáticamente aprendiendo de sus errores (machine learning). En terrenos como la identificación de imágenes (reconocimiento facial) o de sonidos (“Alexa, ¿qué hora es?”) son excelentes. También en otros casos, como la previsión de valores que evolucionan en el tiempo, el uso de unos algoritmos llamados redes neuronales suele ofrecer mejores resultados que los métodos clásicos.\nTambién es verdad que no es oro todo lo que reluce. Seguramente algunas de sus posibilidades han sido sobrevaloradas por empresas consultoras que ven en estas técnicas con nombre sugerente (Inteligencia artificial, deep learning…) la posibilidad de vender nuevos productos.\nUna peculiaridad de esos algoritmos es que actúan como ``cajas negras’’ en las que se tienen unas variables de entrada \\(X\\), y otras de salida \\(Y\\), y lo que se pretende es tener buenas previsiones de los valores de \\(Y\\) dado un conjunto de valores de \\(X\\), pero sin llegar a entender cómo esos valores de \\(X\\) están afectando a los de \\(Y\\). El no conocer las relaciones causa-efecto limita sus posibilidades en la solución de problemas cuando es necesario conocer cuales son las causas que los provocan para poder plantear soluciones eficaces. Por otra parte, el esfuerzo que se realiza intentado obtener información de grandes volúmenes de datos de dudosa calidad (muchas veces misión imposible) sería mejor reorientarlo a plantearse qué datos se necesitan y planificar su recogida con el rigor y la estructura adecuadas para que de manera transparente y fiable se pueda obtener la información deseada así como un mejor conocimiento del proceso en estudio.\nEs un tema controvertido si la “Ciencia de Datos” debe ser considerada una parte de la estadística o si se trata de una nueva disciplina. Nuestra opinión es que depende de lo que entendamos por estadística. Si estadística es la parte de las matemáticas que se dedica a crear métodos estadísticos, entonces realmente la ciencia de datos es una nueva disciplina, mucho más orientada a la resolución de problemas prácticos. Si, tal como nosotros pensamos, la estadística es la disciplina que trata de la recogida y el análisis de datos para responder a las preguntas que nos planteamos, no hay ninguna duda de que la ciencia de datos encaja perfectamente en esa definición.\nEn cualquier caso, entender el funcionamiento de esos algoritmos, ser capaces de programar y de interactuar con grandes volúmenes de datos, así como conocer las posibilidades de almacenamiento y computación en la nube son habilidades muy demandadas y con un gran futuro.",
    "crumbs": [
      "Estadística. Lo que es y lo que no es",
      "¿Qué es la ciencia de datos (o *Data Science*)?"
    ]
  },
  {
    "objectID": "0201_Mediana.html",
    "href": "0201_Mediana.html",
    "title": "¿Para qué sirve la mediana si ya tenemos la media aritmética?",
    "section": "",
    "text": "La media aritmética es una excelente medida de tendencia central, muy usada y también muy apreciada, a veces demasiado, como cuando se pretende resumir en ella toda la información que contienen los datos. La mediana tiene unas propiedades de las que carece la media, por lo que es un buen complemento informativo e incluso puede ser una medida más útil en algunos casos. Vamos a ver estas propiedades.\n\nEs más robusta que la media frente a la presencia de anomalías. Supongamos que nuestros datos son:\n2; 5; 6; 7 y 9\nLa media es 5,6 y la mediana es 6. Si al introducir los datos al ordenador nos equivocamos y en último lugar en vez de 9 introducimos 99, la media pasa a ser 23,8 mientras que la mediana sigue siendo 6.\nPor su propia definición, la mediana deja un 50% de las observaciones por debajo y otro 50% por encima y esto le da unas ventajas que la media no tiene. Si queremos saber si en nuestra empresa estamos entre los que cobran más o entre los que cobran menos, debemos comparar nuestro salario con la mediana, no con la media. Si sólo hay 10 trabajadores y los salarios son (en las unidades que corresponda):\n0,8; 0,8; 0,9; 0,9; 1,0; 1,0; 1,1; 1,1; 1,2 y 10\ntodos menos uno (en este caso el 90%) están por debajo de la media, que es 1,88. Esto no pasa nunca con la mediana: si estamos por encima de la mediana, estamos con el 50% de los que más cobran. Otro ejemplo. Si en un examen las notas van de 0 a 10 y se aprueba sacando una nota igual o superior a 5, si la nota media es 5 no sabemos cuántos han aprobado. Si se han examinado 50 estudiantes, puede ser que 41 hayan suspendido con un 4; 8 hayan sacado un 10 y uno haya obtenido un 6. Esto da media 5, aunque el 82% ha suspendido. Si la mediana es 5, seguro que la mitad han aprobado.\n\nSi la distribución de los datos es simétrica, la media y la mediana coinciden y entonces todo son ventajas. En una distribución Normal la media y la mediana son iguales, por tanto, si los valores que tenemos provienen de una Normal, la media y la mediana no andarán muy lejos una de otra. En cualquier caso, siempre podemos calcular las dos y aprovechar lo mejor de cada una.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Para qué sirve la mediana si ya tenemos la media aritmética?"
    ]
  },
  {
    "objectID": "0202_Media_geometrica.html",
    "href": "0202_Media_geometrica.html",
    "title": "¿Tiene alguna aplicación práctica la media geométrica?",
    "section": "",
    "text": "Sí la tiene, pero mucho menos que la media aritmética. Un caso típico de uso de la media geométrica lo tenemos en el cálculo del valor medio de una tasa de crecimiento. Si una población tenía 10.000 habitantes en el año cero, creció el primer año a una tasa del 5 %, el segundo a una tasa del 20 % y el tercer año al 50 % ¿A que tasa promedio ha crecido en estos tres años?\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacióninicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n1\n10.000\n0,05\n1,05\n10.500\n\n\n2\n10.500\n0,20\n1,20\n12.600\n\n\n3\n12.600\n0,50\n1,50\n18.900\n\n\n\n\nSi calculamos la media aritmética de la tasa de crecimiento tenemos: \\((0,05 + 0,20 + 0,50)/3 = 0,25\\) y el factor medio de expansión sería \\(1,25\\). Pero si la población hubiera crecido los tres años de esta forma, no se llegaría al mismo resultado final:\n\n\n\n\n\n\n\n\n\n\n\nAño\nPoblacióninicial\nTasa de crecimiento\nFactor de expansión\nPoblación al final del año\n\n\n1\n10.000\n0,25\n1,25\n12.500\n\n\n2\n12.500\n0,25\n1,25\n15.625\n\n\n3\n15.625\n0,25\n1,25\n19.531\n\n\n\n\nPor tanto, la media aritmética no es un buen indicador de la tasa media de crecimiento.\nSi la población crece a una tasa constante \\(i\\), para que al final del tercer año tenga el mismo efecto que las tasas del ejemplo, se debe verificar que:\n\\[ 10\\,000(1+i)(1+i)(1+i)=10\\,000(1+0,05)(1+0,20)(1+0,50) \\]\nDe donde:\n\\[(1+i)= \\sqrt[3]{1,05 \\cdot 1,20 \\cdot 1,50}=1,2364\\]\nSi se hubiera tenido este factor de expansión cada año (nótese que es la media geométrica), hubiera conducido a una población final igual a la que tenemos.\nCuriosidades sobre la media geométrica son:\n\nA diferencia de la media aritmética, la media geométrica sólo se define para números positivos.\nLa media geométrica nunca es mayor que la media aritmética. La demostración para el caso de 2 valores es fácil por reducción al absurdo. Supongamos que: \\(\\sqrt{ab} &gt; (a+b)/2\\), entonces \\(ab &gt; (a^2+2ab+b^2)/4\\), de donde: \\(0 &gt;a^2-2ab+b^2\\). Como \\(a^2-2ab+b^2=(a-b)^2\\) es imposible que este valor sea negativo, luego es imposible que \\(\\sqrt{ab}&gt;(a+b)/2\\).\n\nY ya puestos a hablar de otras medias, podemos hacer un comentario sobre la media armónica, mucho menos conocida pero también útil en algunos casos.\nSe define la media armónica de \\(x_1, x_2, ..., x_N\\) como:\n\\[Mh = \\frac{N}{\\large{\\frac{1}{x_1}+\\frac{1}{x_2}+...+\\frac{1}{x_N}}}\\]\nParece que esto sea un retorcimiento sin ningún interés, pero no. Si un coche recorre cierta distancia a una velocidad de 100 km/h y vuelve por el mismo camino a 120 km/h, la velocidad media a que ha realizado el viaje es:\n\\[Mh = \\frac{2}{\\large{\\frac{1}{100}+\\frac{1}{120}}} = 109,1 \\text{ km/h}\\]\ny no 110 km/h como en principio se podría pensar.\nObserve que la velocidad es igual a la distancia recorrida dividida por el tiempo tardado en recorrerla,\nes decir \\(v=d/t\\) y por tanto \\(t=d/v\\). En nuestro caso, si la distancia a recorrer es \\(d\\), el tiempo tardado en la ida es \\(t_1 =d/100\\) y el tiempo tardado en el regreso es \\(t_2 =d/120\\). De esta manera el tiempo total invertido en todo el recorrido \\((2d)\\) será \\(t=t_1+t_2\\) y la velocidad media se calcula de la forma:\n\\[ \\text{Velocidad media} = \\frac{\\text{Distancia total recorrida}}{\\text{Tiempo total empleado}} = \\frac{2d}{\\large{\\frac{d}{100}+\\frac{d}{120}}} \\]\nOtro ejemplo: Un avión recorre 3000 km. Los 1000 primeros a 700 km/h, los 1000 siguientes a 800 km/h, y los 1000 restantes a 900 km/h ¿Cuál ha sido su velocidad media? No ha sido 800 km/h sino 791,6 km/h.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Tiene alguna aplicación práctica la media geométrica?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html",
    "href": "0203_Variabilidad.html",
    "title": "¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "Porque considerar la variabilidad es fundamental para describir la realidad, para entenderla y para tomar mejores decisiones.\nEs muy conocido el chiste que dice que si un señor se come un pollo y otro no come nada, la estadística lo explicará diciendo que en promedio se han comido medio pollo cada uno. Hace gracia por lo descabellado que es contar así las cosas, pero lo hacemos con más frecuencia de la que creemos. Por ejemplo, cuando se habla de la renta per cápita de un país se está hablando del medio pollo que se come cada uno, sin hacer ninguna referencia a si todos comen más o menos lo mismo o si unos comen mucho y otros prácticamente nada. En el terreno de la educación, cuando se dan los resultados de las pruebas PISA se dan unos valores por países y pocos se preguntan sobre las diferencias dentro de cada país, lo cual también es una información relevante.\nEn el ámbito de la gestión de empresas, supongamos que debe elegir entre dos proveedores que son iguales en todo (precio, calidad, etc.) excepto en el plazo de entrega: uno tarda un promedio de 4,25 días y el otro de 5,75, ¿con cuál se queda? Seguramente habrá pensado que con el que sirve más rápido, pero 4,25 es el promedio de: 3, 5, 4, 3, 7, 4, 2 y 6, mientras que 5,75 lo es de: 6, 5, 6, 6, 6, 5, 6 y 6. ¿Qué piensa ahora? Es más previsible el que tarda 5,75 y seguro que usted se podrá organizar mejor con este. Con el otro deberá hacer los pedidos un mínimo de 7 días antes, y alguna vez lo recibirá a los 2 días y no sabrá donde ponerlo.\nEn el mundo industrial ignorar la variabilidad también conduce a una visión equivocada del funcionamiento de las cosas. Veamos un ejemplo donde usaremos la ley de Ohm (Recuerde: I=V/R, si esto no le suena de nada puede saltarse este párrafo). Supongamos que le encargan fabricar un lote de circuitos muy sencillos que solo constan de un fuente de alimentación (V) y de una resistencia (R). Vamos a suponer que el voltaje de la fuente de alimentación siempre es igual a 100 V mientras que las resistencias presentan una cierta variabilidad y tienen un valor real que es igual al valor nominal ±5 \\(\\Omega\\). Se desea que en cada circuito la intensidad sea de 10 A y se considerará defectuoso si esa intensidad está fuera del intervalo 10±3 A ¿de qué valor nominal debe pedir las resistencias para minimizar la proporción de circuitos defectuosos? Quizá usted está pensando que si se quiere tener I=10 A, si V=100 V se debe pedir R=10 \\(\\Omega\\). Esto sería verdad si no hubiera variabilidad pero en nuestro caso habría que pedirlas de 11 \\(\\Omega\\)1.\nEn el ámbito de la medicina, para que una vacuna o un nuevo medicamento sean aprobados deben probarse en una amplia muestra de las personas a que va dirigido. Si todos fuéramos iguales -si no hubiera variabilidad- bastaría hacer la prueba en una sola persona, una cualquiera, y si en esa funciona funcionaría en todas.\nEn fin, si no existiera la variabilidad no habría estadística. Ni estadística, ni evolución de las especies ni muchas otras cosas. Tampoco estaríamos nosotros.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0203_Variabilidad.html#footnotes",
    "href": "0203_Variabilidad.html#footnotes",
    "title": "¿Por qué damos tanta importancia a la variabilidad?",
    "section": "",
    "text": "El circuito es defectuoso si su intensidad está por debajo de 7 A o por encima de 13 A, es decir, si la resistencia que se coloca está por encima de 14,3 \\(\\Omega\\) o por debajo de 7,7 \\(\\Omega\\). Para huir de esos valores lo mejor es pedir un valor nominal que esté en el centro, es decir: (7,7+14,3)/2 = 11 \\(\\Omega\\). &lt;&gt;↩︎",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué damos tanta importancia a la variabilidad?"
    ]
  },
  {
    "objectID": "0204_Varianza_cuadrado.html",
    "href": "0204_Varianza_cuadrado.html",
    "title": "¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?",
    "section": "",
    "text": "Cuando se calcula la varianza, las diferencias entre cada valor y la media se elevan al cuadrado para evitar que se compensen las positivas con las negativas. Esto provoca que sus unidades sean el cuadrado de las que tienen los datos, lo cual resulta poco intuitivo y difícil de interpretar (no parece natural medir la variabilidad de longitudes en unidades de superficie). Este problema se resuelve usando una nueva medida que es la raíz cuadrada de la varianza: la desviación típica. Todos hemos pensado alguna vez que se podría evitar tener esas dos medidas usando el valor absoluto de las diferencias en vez de su cuadrado. Así ya estaríamos midiendo la variabilidad en las mismas unidades que los datos.\nNo lo hacemos porque saldríamos perdiendo. La varianza tiene unas propiedades extraordinarias que ni de lejos presenta esa nueva medida usando el módulo. Vamos a desarrollar unas ideas que nos permitirán justificarlo.\nUtilizaremos los datos representados en la figura 2 en la cual también hemos representado un valor (a), en principio arbitrario, con el propósito de descubrir donde conviene colocarlo para que sea un “buen representante” de este conjunto de datos.\n\n\n\n\n\n\nFigura 1: ¿Dónde colocar un “buen representante” de estos datos?\n\n\n\nEn principio \\(a\\) puede ser cualquier número real pero le vamos a exigir algunos requisitos asociados con nuestra idea de lo que significa “buen representante”, lo cual restringirá el conjunto de valores que puede asumir. Veamos dos criterios para seleccionar el valor de \\(a\\).\n\nCriterio 1\nEscoger el que minimiza la función \\(f(a)\\), definida de la forma:\n\\[f(a)=\\frac{ \\sum_{i=1}^{N} \\left| x_i-a\\right| } {N} \\]\nDonde \\(N\\) es el número de datos y los \\(x_i\\) son sus valores. Como la distancia promedio depende sólo de \\(a\\) le hemos llamado \\(f(a)\\). El valor que minimiza esta función y que por tanto es el mejor representante de los datos con el criterio aplicado no es la media sino la mediana.\nAl valor mínimo de \\(f(a)\\) le llamamos desviación media \\(DM\\) con respecto a la mediana, y su fórmula es: \\[DM=\\frac{ \\sum_{i=1}^{N} \\left| x_i-Me\\right| } {N} \\] En nuestro ejemplo, la mediana es 15,5. Esto significa que de todos los números reales, 15,5 es el que está más cerca de los datos de acuerdo con este criterio. Por tanto, la desviación media para nuestros datos es: \\[ DM = \\frac{\\left|10-15,5\\right|+\\left|12-15,5\\right|+...+\\left|20-15,5\\right|}{10}=2,3 \\]\n\n\nCriterio 2\nEscoger el que hace menor la media de los cuadrados de la distancia de los datos al valor (a). Es decir, el que minimiza la función:\n\\[g(a)=\\frac{ \\sum_{i=1}^{N} ( x_i-a)^2 } {N} \\]\nEn este caso el mejor valor de (a) puede deducirse derivando (g(a)) con respecto de (a), igualando a cero y despejando su valor. Veamos:\n\\[\\frac{\\text{d} g(a)}{\\text{d} a} = \\frac{-2}{N} \\sum_{i=1}^{N}(x_i-a) = 0\\] Por tanto \\(\\sum_{i=1}^{N}(x_i-a) = 0\\), de donde se deduce que \\(\\sum x_i =N \\cdot a\\) y despejando \\(a\\) tenemos: \\[ a = \\sum_{i=1}^{N} \\frac{x_i}{N} \\]\nObserve que en este caso el valor de \\(a\\) sí coincide con la media aritmética (le llamamos \\(\\mu\\)). Si hacemos la segunda derivada vemos que siempre es positiva, lo cual confirma que el punto crítico es \\(a=\\mu\\) y que el valor mínimo de \\(g(a)\\) es la varianza de \\(X\\) (le llamamos \\(\\sigma^2\\)). Con los datos de nuestro ejemplo \\(\\mu\\) = 15,1 y el valor mínimo que toma \\(g(a)\\) es \\(\\sigma^2\\)= 7,89. Sacando raíz cuadrada se obtiene la desviación típica \\(\\sigma\\) = 2,81.\n¿Por qué se prefiere usar la varianza, deducida a través del criterio 2, en lugar de la desviación media, deducida aplicando el criterio 1? Veamos algunas razones:\n\nLos desarrollos anteriores ponen de manifiesto que la media, medida descriptiva por excelencia, está asociada de forma más natural con la varianza que con la \\(DM\\).\nLa \\(DM\\) incluye en su expresión la función “valor absoluto” que se comporta mal desde un punto de vista matemático, mientras que la función cuadrática es muy fácilmente tratable. Observe, por ejemplo, que la demostración de que la media hace mínimo el promedio de los cuadrados se ha realizado de forma casi inmediata, mientras que probar que la mediana hace mínima la media de las distancias es bastante más complejo.\nLa desviación estándar \\(\\sigma\\) de la población es usada para definir la distribución más famosa y útil, como es la Normal. Esto posibilita la construcción de intervalos de confianza para estimar, por ejemplo, la media de la población, lo que sería mucho más complejo si se usara la \\(D\\).\nLa varianza es una suma de cuadrados que se puede descomponer en diversos sumandos dando origen al llamado “Análisis de la Varianza”. El desarrollo de la teoría de los modelos lineales está basado en gran parte en el criterio de los mínimos cuadrados, que es el mismo en que está basada la varianza. Cuando la población origen de los datos es Normal, el cociente de varianzas muestrales sigue una distribución conocida, llamada \\(F\\) de Snedecor.\nLa varianza de una suma de variables aleatorias se calcula de una forma muy fácil, especialmente si las variables son independientes. Por ejemplo, en un proceso de envasado, si el peso del envase tiene una varianza \\(V(X)\\) y la varianza del contenido es \\(V(Y)\\), la varianza del conjunto es \\(V(X+Y) = V(X) + V(Y)\\).\n\nNada de esto podríamos hacer si intentamos usar la desviación media como medida de dispersión. En síntesis, la teoría estadística desarrollada en base a la varianza es muy rica, y no se conoce nada parecido para la desviación media.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué en la fórmula de la varianza se utiliza el cuadrado en vez del módulo?"
    ]
  },
  {
    "objectID": "0205_Dividir_n_1.html",
    "href": "0205_Dividir_n_1.html",
    "title": "¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?",
    "section": "",
    "text": "Para hacer más fácil la explicación vamos a trabajar con un ejemplo suponiendo que conocemos la población completa, lujo que no tendremos en la práctica. Los elementos que componen la población, junto con sus mediciones respectivas, son:\n\n    \n\n\n  \n\n(A)\n(B)\n(C)\n(D)\n(E)\n(F)\n\n\n\n\n2\n6\n8\n10\n10\n12\n\n\n  \n \n\nEn primer lugar ilustraremos la propiedad de insesgamiento de un estimador para el caso de la media, con la cual estamos más familiarizados, y luego repetiremos la experiencia para el caso que nos ocupa de la varianza.\nLa media poblacional \\(\\mu\\), de los datos del ejemplo, es:\n\\[\\mu = \\frac{2+6+8+10+10+12}{6}=8\\]\nSupongamos que nosotros queremos estimar (“hacernos una idea”) el valor \\(\\mu\\), usando una muestra aleatoria de \\(n = 2\\) unidades. En este caso, en que la población consta sólo de 6 unidades, podemos hacer un listado de todas las muestras que pueden resultar al escoger dos unidades al azar. Estas muestras aparecen enumeradas en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\n11\n\n\n12\n\n\n13\n\n\n14\n\n\n15\n\n\n\n\nUnidades de la muestra\n\n\nAB\n\n\nAC\n\n\nAD\n\n\nAE\n\n\nAF\n\n\nBC\n\n\nBD\n\n\nBE\n\n\nBF\n\n\nCD\n\n\nCE\n\n\nCF\n\n\nDE\n\n\nDF\n\n\nEF\n\n\n\n\nValores en la muestra\n\n\n26\n\n\n28\n\n\n210\n\n\n210\n\n\n212\n\n\n68\n\n\n610\n\n\n610\n\n\n612\n\n\n810\n\n\n810\n\n\n812\n\n\n1010\n\n\n1012\n\n\n1012\n\n\n\n\nMedia muestral\n\n\n4\n\n\n5\n\n\n6\n\n\n6\n\n\n7\n\n\n7\n\n\n8\n\n\n8\n\n\n9\n\n\n9\n\n\n9\n\n\n10\n\n\n10\n\n\n11\n\n\n11\n\n\n\n\n\n\nCuando se seleccione al azar una muestra de dos unidades, el resultado será necesariamente alguna de estas 15 posibles combinaciones de 2 elementos, con su media \\(\\bar{x}\\) correspondiente.\nDecimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\) si el promedio de todas las posibles medias coincide exactamente con la media de la población. Para verificarlo, hagamos el promedio de nuestras 15 posibles medias: \\[ \\frac{4+5+6+6+7+7+8+8+9+9+9+10+10+11+11}{15}=8 \\]\nEl promedio coincide con \\(\\mu\\). Esto pasa en todos los casos, independientemente del tipo de población o del tamaño de la muestra, por eso decimos que \\(\\bar{x}\\) es un estimador insesgado de \\(\\mu\\).\nVeamos ahora si el estadístico: \\[  S_{n}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n} \\]\ndonde \\(n\\) es el tamaño de las muestras, es un estimador insesgado para la varianza \\(\\sigma_{N}^{2}\\), calculada como: \\[  \\sigma_{N}^{2}= \\frac{ \\sum_{i=1}^{N}{(x_i-\\mu)^2} }{N} \\]\ndonde \\(N\\) es el tamaño de la población. Queremos saber si el promedio de los valores de \\(S_{n}^{2}\\), para cada una de las posibles muestras, da el valor de \\(\\sigma_{N}^{2}\\) y para averiguarlo, en primer lugar vamos a calcular la varianza poblacional:\n\\[  \\sigma_{N}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6} = 10,67 \\]\nAhora calculamos la varianza para cada muestra de 2 unidades, con la fórmula: \\[  S_{n}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2} \\]\nobteniéndose los resultados que aparecen en la siguiente tabla:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuestra nº\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\n11\n\n\n12\n\n\n13\n\n\n14\n\n\n15\n\n\n\n\nValores en la muestra\n\n\n26\n\n\n28\n\n\n210\n\n\n210\n\n\n212\n\n\n68\n\n\n610\n\n\n610\n\n\n612\n\n\n810\n\n\n810\n\n\n812\n\n\n1010\n\n\n1012\n\n\n1012\n\n\n\n\nMedia muestral\n\n\n4\n\n\n9\n\n\n16\n\n\n16\n\n\n25\n\n\n1\n\n\n4\n\n\n4\n\n\n9\n\n\n1\n\n\n1\n\n\n4\n\n\n0\n\n\n1\n\n\n1\n\n\n\n\n\n\n\nVeamos si el promedio de las posibles varianzas muestrales, coincide con 10,67 que es el valor obtenido para \\(\\sigma_{N}^{2}\\).\n\\[ \\bar{S}^2 = \\frac{4+9+16+16+25+1+4+4+9+...+1}{15} = 6,4 \\]\nNo coincide y, por tanto, \\(S_{n}^{2}\\) no es un estimador insesgado de \\(\\sigma_{N}^{2}\\). Sin embargo \\(S_{n-1}^{2}\\), definido de la forma: \\[  S_{n-1}^{2}= \\frac{ \\sum_{i=1}^{n}{(x_i-\\bar{x})^2} }{n-1} \\]\naunque tampoco es un estimador insesgado para \\(\\sigma_{N}^{2}\\), sí lo es para \\(\\sigma_{N-1}^{2}\\) definido como: \\[  \\sigma_{N-1}^{2}= \\frac{ \\sum_{i=1}^{N-1}{(x_i-\\mu)^2} }{N-1} \\]\nEfectivamente, \\(\\sigma_{N-1}^{2\\) tiene el valor: \\[  \\sigma_{N-1}^{2}= \\frac{(2-8)^2+(6-8)^2+(8-8)^2+...+(12-8)^2}{6-1} = 12,8 \\]\nY si calculamos \\(S_{n-1}^{2}\\) para cada una de nuestras muestras deberemos aplicar la fórmula:\n\\[  S_{n-1}^{2}= \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{2-1} = \\frac{ (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 }{1}  \\]\nEs decir que todos los valores de la varianza que aparecen en la tabla anterior, quedan ahora multiplicados por 2 y por lo tanto la media de las varianzas queda también multiplicada por 2, es decir:\n\\[ \\bar{S}_{n-1}^{2}= 2\\cdot 6,4 = 12,8 \\]\nQuizá este resultado decepcione, y hasta sorprenda, porque seguramente lo esperado era que \\(S_{n-1}^{2}\\) fuera un estimador insesgado de \\(\\sigma_{N}^{2}\\) y no de \\(\\sigma_{N-1}^{2}\\), pero no hay que preocuparse demasiado. A efectos prácticos es casi lo mismo cuando la población es grande, y nosotros no vamos a estimar a través de muestras las características de una población de 6 elementos (en nuestro ejemplo esta ha sido una población “de juguete” para entender lo que estábamos haciendo). Cuando estimemos la varianza de una población se tratará de una población grande, en la que \\(\\sigma_{N}^{2}\\) será prácticamente igual a \\(\\sigma_{N-1}^{2}\\). En realidad, el caso más frecuente es tener poblaciones teóricas (infinitas), en las que es exactamente lo mismo \\(\\sigma_{N}^{2}\\) que \\(\\sigma_{N-1}^{2}\\).",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué cuando se calcula la varianza de una muestra se divide por n-1?"
    ]
  },
  {
    "objectID": "0206_Desviacion_tipica.html",
    "href": "0206_Desviacion_tipica.html",
    "title": "¿Por qué la desviación típica es la medida típica de dispersión?",
    "section": "",
    "text": "Existen diversas razones por las que la desviación típica –o desviación estándar– es tan valorada y tan necesaria en el ámbito de la Estadística. Una de esas razones es formar con la media una “pareja perfecta” para describir el comportamiento de muchas variables aleatorias. Otra podría ser el formar parte del ``ADN’’ de la distribución Normal. Veamos algunos de sus méritos.\n\nRelación con la media y con la distribución Normal}\nSi una variable aleatoria tiene distribución Normal, basta conocer su media y su desviación típica para calcular cualquier probabilidad relacionada con los valores que puede tomar. Si el peso de unos paquetes de azúcar sigue una distribución Normal con una media de 1000 g y una desviación típica de 15 g, podemos decir que aproximadamente el 95 % de los paquetes tendrán un peso comprendido entre 970 y 1030 g, y también podemos decir que el 68 % tendrá un peso comprendido entre 985 y 1015. Además, podríamos responder cualquier pregunta similar, por ejemplo qué porcentaje de paquetes tendrá un peso por debajo de 980 g (será el 9 %).\n\n\nImportancia en otras distribuciones\nSi la variable considerada no sigue una distribución Normal ¿sigue siendo útil la desviación típica? La respuesta es sorprendente. Si la variable sigue un modelo de probabilidad exponencial, o de Poisson, o una distribución Gamma, o una Beta, entre otras, también podemos usar la media y la desviación típica para responder preguntas de naturaleza similar a las planteadas antes.\n\n\nCuando no se conoce la distribución\n¿Sirve la desviación típica para hacer cálculos aproximados de probabilidades asociadas a una variable aleatoria si no tenemos ni idea de cual es su distribución? Esta pregunta la respondió el matemático ruso Pafnuty Chebyshev (su apellido se puede ver escrito de distintas formas) en la conocida como desigualdad de Chebyshev. La idea es que para una amplia variedad de distribuciones, en el intervalo \\(\\mu \\pm k\\sigma\\) se tiene como mínimo una proporción de observaciones igual a \\(1-1/k^2\\). Es decir, si \\(k=\\sqrt{2}\\), el intervalo es \\(\\mu \\pm \\sqrt{2}\\sigma\\) y podemos afirmar que, con independencia del tipo de distribución, tendremos como mínimo el 50 % de las observaciones dentro de ese intervalo, y si \\(k=2\\) tendremos como mínimo el 75 %. Una curiosa propiedad en la que nuestra pareja media–desviación típica también es protagonista.\n\n\nSu papel en la estimación de la media poblacional\nEn muchas situaciones nuestro interés está en estimar la media poblacional \\(\\mu\\). Para ello tomamos una muestra y calculamos su media \\(\\bar{x}\\) para hacernos una idea del valor desconocido del parámetro \\(\\mu\\).\nCada vez que se tome una muestra, el valor de la media muestral \\(\\bar{x}\\) cambiará, pero sabemos que si tomamos muchas muestras de tamaño \\(n\\), sus medias estarán alrededor del verdadero valor de la media poblacional \\(\\mu\\). Pero decir que están alrededor de \\(\\mu\\) no significa que estén cerca de \\(\\mu\\). ¿Cómo podemos saber que tan cerca están? En la respuesta a esta pregunta la desviación típica también tiene un papel protagonista. La desviación típica de esas medias muestrales es igual a la desviación típica de la población dividida por \\(\\sqrt{n}\\). Esto es verdad para las distribuciones, no solo para la Normal.\n\n\nEstandarización de los datos\nSi le dicen que una vaca pesa 600 kg, a no ser que usted sea ganadero, probablemente ese valor no le dirá si la vaca está muy delgada o si tiene el peso correcto. Sin embargo, si le dicen que su peso está a 0,6 desviaciones típicas por encima de la media podrá deducir que el 73 % de las vacas de ese tipo tienen un peso por debajo y un 27 % por encima, luego la vaca no está delgada.\nUsando un ejemplo más académico, lo mismo ocurre con los residuos que se obtienen después de ajustar una ecuación de regresión. Que un residuo sea igual a 10 no nos dice si es grande o pequeño, es mucho más informativo que nos digan a cuantas desviaciones típicas está de la media, que en este caso siempre es cero. A ese valor se le llama residuo estandarizado.\nEn definitiva, la desviación típica aparece en muchos contextos y con mucha relevancia. El calificativo “típica” resulta en este caso apropiado y bien merecido.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Por qué la desviación típica es la medida típica de dispersión?"
    ]
  },
  {
    "objectID": "0207_Cuartiles_correcta.html",
    "href": "0207_Cuartiles_correcta.html",
    "title": "¿Cuál es la forma correcta de calcular los cuartiles?",
    "section": "",
    "text": "Existen diferentes criterios para determinar los valores de los cuartiles y no todos dan el mismo resultado. Veamos algunos ejemplos.\nJohn Tukey, creador de los boxplots, identifica los cuartiles buscando las medianas de los valores que quedan por encima y por debajo de la mediana global. En la determinación de las medianas de cada mitad de datos incluye la mediana global si el número de datos es impar, pero no la incluye si es par. Por ejemplo, para los datos 2, 4, 6, 8 y 10 (número impar) tenemos:\n\n\n\n\n\n\n\nY si los datos son 2, 4, 6, y 8 (número par):\n\n\n\n\n\n\n\nDavid Moore y George McCabe en su libro “Introduction to the Practice of Statistics”, muy valorado por su carácter pedagógico e innovador, proponen un método similar al de Tukey pero sin incluir la mediana global en la determinación de las medianas de cada una de las mitades. Cuando el número de datos es par el valor de los cuartiles coincide con el método de Tukey, pero en general no coincide cuando el número de datos es impar.\n\n\n\n\n\n\n\nEl paquete de software estadístico Minitab utiliza las expresiones \\(0,25(n+1)\\) y \\(0,75(n+1)\\) para determinar las posiciones de \\(Q_1\\) y \\(Q_3\\) respectivamente. Si la posición obtenida para \\(Q_1\\) es, por ejemplo, 1,25, su valor estará comprendido entre \\(x_1\\) y \\(x_2\\) interpolando de la forma: \\(Q_1 = x_1 + 0,25(x_2-x_1)\\). Utilizando los mismos datos que en los ejemplos anteriores resultaaa:\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8, 10  Posición de \\(Q_1\\): \\(\\;0.25 \\cdot 6 = 1.5\\); \\(\\;\\) Valor de \\(Q_1\\): \\(\\; 2  +0.5(4-2) = 3\\)  Posición de \\(Q_3\\): $;0.75 = 4.5); \\(\\;\\) Valor de \\(Q_3\\): \\(\\; 8 + 0.5(10-8) = 9\\)\n\\(\\bullet \\;\\) Datos: 2, 4, 6, 8  Posición \\(Q_1\\): \\(\\;0.25 \\cdot 5 = 1.25)\\); \\(\\;\\) Valor \\(Q_1\\): \\(\\; 2 + 0.25(4-2) = 2.5)\\)  Posición \\(Q_3\\): \\(\\;0.75 \\cdot 5 = 3.75)\\); \\(\\;\\) Valor \\(Q_3\\): \\(\\; 6 + 0.75(8-6) = 7.5)\\)\nExcel dispone de la función CUARTIL que identifica la posición de los cuartiles mediante las expresiones: \\(0.25(n-1)+1\\) y \\(0.75(n-1)+1\\) y los calcula interpolando igual que hace Minitab. Seguramente no satisfechos con su forma de identificar los cuartiles, en las últimas versiones se ha mantenido esa función (se indica que por compatibilidad con versiones anteriores) y se han añadido:\n\n\nCUARTIL.INC: Coincide con la función CUARTIL.\nCUARTIL.EXC: Identifica los cuartiles de la misma forma que Minitab.\n\n\nEn la figura 1 se muestran los cuartiles de nuestros datos con las funciones de Excel (versión 2019).\n\n\n\n\n\n\nFigura 1: Cálculo de los cuartiles con Excel\n\n\n\nEn resumen, los valores obtenidos con los métodos comentados han sido:\n\n\n\n\n\n\n\n\n\n\n\nMétodo\n  Datos: 2, 4, 6, 8\nDatos: 2, 4, 6, 8, 10\n\n\n    Q1\nQ3    \n    Q1\nQ3    \n\n\nTukey\nMoore y McCabe\nMinitab\nExcel, CUARTIL.INC\nExcel, CUARTIL.EXC\n    3\n    3\n    2.5\n    3.5\n    2.5\n7  \n7  \n7.5  \n6.5  \n7.5  \n    4\n    3\n    3\n    4\n    3\n8  \n9  \n9  \n8  \n9  \n\n\n\n\n¿Qué método es el correcto? ¿Cuál debemos utilizar? En la práctica no importa demasiado. Solo se está interesado en conocer los cuartiles cuando el conjunto de datos es grande (nunca si tenemos solo 4 o 5 datos) y en este caso las diferencias entre los distintos métodos no son relevantes. Por ejemplo, si tenemos 500 valores, la posición del primer cuartil con el método de Minitab es 125,25 y con la función CUARTIL.INC de Excel es 125,75. Como habrá poca diferencia entre los valores que ocupan las posiciones 125 y 126, la diferencia en el valor del cuartil no será relevante.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Cuál es la forma correcta de calcular los cuartiles?"
    ]
  },
  {
    "objectID": "0208_Anomalias_boxplot.html",
    "href": "0208_Anomalias_boxplot.html",
    "title": "¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?",
    "section": "",
    "text": "Parece que ese 1,5 es un número caprichoso. También el 1 o el 2 podrían ser buenos candidatos con la ventaja de ser más sencillos, pero veamos que ocurriría si fueran estos los elegidos.\nEn primer lugar debemos tener en cuenta que los valores que aparecen en la zona de anomalías de un boxplot tienen sentido como tales anomalías, si la población de la que provienen es Normal. Consideremos por tanto una distribución Normal, y puestos a elegir una tomaremos \\(Z \\sim N(0;1)\\) ya que los cálculos serán más sencillos y no va a restringir nuestras conclusiones. Para determinar los cuartiles buscamos el valor de \\(z\\) que deja un área de cola de 0,25 y resulta ser: \\(Z_{0,25} = 0,674\\). Por tanto, el rango intercuartílico de una distribución \\(N(0;1)\\) es: \\(IQR = 0,674 - (-0,674) = 1,348\\).\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1 \\cdot IQR}\\)\nEn este caso, fijándonos en el lado derecho, la zona de anomalías empieza en \\(Q_3 + 1 \\cdot IQR = 0,674 + 1,348 = 2,022\\), y \\(P(Z&gt;2,022) = 0,02\\). Por tanto, la probabilidad de que un valor que pertenezca a la distribución considerada aparezca en la zona de anomalías es del 4% (2% por cada lado).\n\n\n\n\n\n\nFigura 1: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 2 \\cdot IQR}\\)\nSi en vez de 1 tomamos el valor 2 como multiplicador del rango intercuartílico, tendremos que: \\(Q_3 + 2 \\cdot IQR = 0,674 + 2 \\cdot 1,348 = 3,37\\) y \\(P(Z&gt;3,37) = 0,0004\\), por lo la probabilidad de que un valor aparezca como anomalía es 0,0008.\n\n\n\n\n\n\nFigura 2: Zona de anomalías con el criterio de \\(\\pm 1 \\cdot IQR\\)\n\n\n\nJohn Tukey, que fue el primero en plantear el uso de los boxplots, ya contempló la posibilidad de usar los valores 1 o 2, pero consideró que 1 es demasiado pequeño ya que la zona de anomalías con este criterio incluye valores que no merecen ser considerados como tales, y el valor 2 resulta excesivamente grande ya que aleja demasiado esta zona y por tanto pueden pasar desapercibidos valores que deben ser considerados como anómalos.\n\n\nAnomalías a partir de Cuartiles \\(\\boldsymbol{\\pm 1,5 \\cdot IQR}\\)\nDescartado el 1 y el 2, y estando claro que el más adecuado es un valor entre ellos, aparece la opción del 1,5 como número más sencillo. Este valor define una zona de anomalías con probabilidades muy razonables (p = 0,007) así que este fue el valor que se propuso y así se ha quedado.",
    "crumbs": [
      "Estadística descriptiva",
      "¿De dónde sale el 1,5 utilizado para marcar las anomalías en un boxplot?"
    ]
  },
  {
    "objectID": "0209_Valores_atipicos.html",
    "href": "0209_Valores_atipicos.html",
    "title": "¿Qué hay que hacer cuando nos encontramos con valores atípicos?",
    "section": "",
    "text": "Para empezar vamos a decir dos cosas que : 1) ignorarlos como si no existieran o 2) eliminarlos inmediatamente sin más consideraciones.\nSeguramente el error más frecuente es no preocuparse de su posible existencia lanzándose directamente a realizar el test que corresponda. Actuando de esta forma se corre el riesgo de trabajar con algún dato erróneo, ya sea por problemas de formato, porque está en unidades que no corresponden, porque ha habido un error en la medida, o por otras razones. Realizar el test con datos erróneos puede conducir a unas conclusiones totalmente equivocadas.\nTambién puede darse el caso de que los valores sean correctos pero no convenga tomarlos en consideración. Supongamos que se desea analizar si un coche de policía aparcado en la orilla de la carretera recuerda a los conductores cual es la velocidad máxima en ese tramo. Para ello, con un radar oculto, se mide la velocidad de los vehículos en una zona en que la máxima permitida es de 60 km/h. Las velocidades obtenidas (también en km/h) son:\n\n    \n \n\n65\n66\n80\n57\n57\n74\n55\n58\n65\n60\n77\n\n\n\n\n72\n63\n55\n74\n67\n63\n25\n57\n20\n68\n22\n\n\n\n\n61\n59\n77\n72\n23\n67\n58\n66\n71\n56\n63\n\n\n\n\nA continuación se hacen las mismas mediciones pero colocando un coche de la policía aparcado de forma visible al lado de la carretera. En este caso las velocidades son:\n\n  \n\n\n55\n55\n63\n58\n62\n57\n59\n70\n22\n58\n56\n63\n\n\n\n\n55\n61\n58\n60\n24\n55\n75\n58\n61\n63\n20\n63\n\n\n\n\n62\n55\n25\n80\n61\n61\n60\n59\n73\n60\n50\n60\n\n \n\nSi realizamos el test de la \\(t\\) de Student para muestras independientes contrastando la hipótesis nula de que las velocidades medias son iguales frente a la alternativa de que con el coche de la policía son menores, se obtiene un p-valor de 0,167, por lo que del estudio no se podría deducir que el coche de policía tiene efecto disuasorio.\nSin embargo, realizando el análisis exploratorio de los datos, se obtiene el gráfico de la figura 1 en el que se observan unos valores atípicos, tanto con coche de la policía como sin él, que corresponden a vehículos que han pasado a unos 20-25 km/h. ¿Qué hay que hacer con estos valores? Lo primero es preguntarse a qué corresponden, cómo se han producido. En este caso se llega a la conclusión de que corresponden a vehículos de transporte agrícola que siempre van a esta velocidad, porque no pueden ir a más. Está claro que la posible influencia del método disuasorio no va con este tipo de vehículos y lo más razonable es excluirlos del estudio.\n\n\n\n\n\n\nFigura 1: Velocidades de paso (km/h) con valores atípicos (1)\n\n\n\nAl eliminar estos valores disminuye la variabilidad de las muestras y la diferencia de medias pasa a ser claramente significativa.\nPero tampoco hay que caer en la tentación de eliminar las anomalías automáticamente. Si los valores obtenidos hubieran sido los que se reflejan en la figura 2, que son iguales que los anteriores añadiendo 115, 118, 120 y 117 a la velocidad sin coche de policía, tendríamos que en este grupo hay dos conjuntos de valores atípicos, los dos aproximadamente a la misma distancia del centro de los datos, pero aunque hemos visto que era razonable quitar el conjunto de los valores bajos, no hay ninguna razón para quitar el de los altos, que corresponden a coches que circulan a una velocidad mucho mayor a la permitida.\n\n\n\n\n\n\nFigura 2: Velocidades de paso (km/h) con valores atípicos (2)\n\n\n\nOtro aspecto a tener en cuenta es que el análisis de las anomalías puede ser la parte más interesante del estudio. El gráfico de la figura 3 muestra la relación entre el rendimiento y temperatura en una reacción química. Aparecen unos valores claramente anómalos, ¿qué hacer con estos valores? ¿eliminarlos y olvidarse de ellos?\n\n\n\n\n\n\nFigura 3: Rendimiento en función de la temperatura\n\n\n\nSi lo hiciéramos así nos perderíamos la oportunidad de incorporar información valiosa a nuestro conocimiento del proceso. Lo más adecuado sería preguntarnos: ¿Por qué se han dado estas situaciones?, ¿qué ha ocurrido a 185 grados para que se hayan producido unos rendimientos tan anormalmente altos?, ¿por qué una vez a 205 grados y se obtuvo un rendimiento tan bajo? Es posible que la respuesta a estas preguntas aporte una información que puede ser muy útil para tener un mayor dominio del proceso.\nEn definitiva, ante un valor atípico lo que hay que hacer es intentar averiguar el por qué se ha producido. Si está claro que la causa es un error se elimina y asunto resuelto. Si no es un error habrá que valorar la conveniencia de incluirlo en el estudio, según sea la razón por la cual se ha producido y la frecuencia con que se esperan valores similares.\nTambién es verdad que en algunos casos uno no sabe si mantener el valor atípico o quitarlo. Cuando se da esta situación una buena idea es realizar el análisis con y sin la presunta anomalía. Si se obtienen las mismas conclusiones la disyuntiva deja de tener importancia. En caso contrario el resultado va a ser dudoso hagamos lo que hagamos, a no ser que podamos recoger más datos.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué hay que hacer cuando nos encontramos con valores atípicos?"
    ]
  },
  {
    "objectID": "0210_Curtosis.html",
    "href": "0210_Curtosis.html",
    "title": "¿Para qué sirve la curtosis?",
    "section": "",
    "text": "La curtosis es una medida de las llamadas “de forma” que cuantifica lo esbelta o aplanada que es una distribución de probabilidad (versión poblacional) o su equivalente cuando se refiere a un conjunto de datos (versión muestral). Se toma como referencia el valor que corresponde a la distribución Normal. Si una distribución tiene una curtosis mayor que la Normal hay que interpretarlo como que su parte central es más picuda (con más “apuntamiento”), y si el valor es menor será más plana, lo cual se traduce en que sus colas son más “pesadas”, es decir, que es más probable encontrar valores alejados de la media.\nSobre cual es el valor de la curtosis para la distribución Normal existen dos criterios. Su fórmula definida de forma natural es: \\(E(X-\\mu)^4]/\\mu^4\\) y para la Normal, con independencia del valor de sus parámetros, da un valor igual a 3. Para tomar este valor como referencia, también se define como la expresión anterior menos 3, de forma que para la Normal es igual a cero. Cuando se dan valores de la curtosis, no siempre está claro cual es el criterio con que se ha calculado. Algunos textos se refieren a la curtosis como el resultado de aplicar la expresión anterior y al como ese valor menos 3.\nA pesar de que la curtosis está relacionada con la forma de la distribución, no es una medida de variabilidad. Una distribución uniforme definida en el intervalo (\\(-\\sqrt{3};\\; \\sqrt{3}\\)) tiene \\(\\mu\\) = 0 y \\(\\sigma\\) = 1, al igual que una N(0; 1), pero la uniforme tiene una curtosis de 9/5, mientras que en la Normal es igual a 3.\nEn la mayoría de paquetes estadísticos cuando se piden las estadísticas descriptivas, además de las típicas medidas de tendencia central y de dispersión se obtiene la curtosis y su inseparable compañero, el coeficiente de asimetría (en inglés ), que seguramente son las medidas menos atendidas.\n¿Para que sirven? Ambas son útiles para caracterizar las distribuciones de probabilidad a nivel teórico, especialmente en campos como los mercados financieros, o en hidrología, donde los valores extremos se dan con mayor probabilidad que en la distribución Normal y pueden tener consecuencias muy importantes. También juegan un papel destacado en algunas situaciones en las que para evaluar la robustez de un método o de un estimador, conviene probar con distribuciones de colas livianas y de colas pesadas, es decir, con distinta curtosis.\nSin embargo, tienen poco interés para describir la forma que presentan los valores de una muestra. Es mejor hacer un gráfico, como un diagrama de puntos o un histograma. El gráfico no puede ser sustituido por estas medidas, que tampoco aportan nada relevante cuando ya se tiene.\nAdemás, son malos estimadores de los valores correspondientes a la población. La figura 1 muestra los valores de la curtosis obtenidos por simulación de muestras de tamaño 10, 20, 50 y 100, de una población exponencial con \\(\\lambda\\)=1, a la que corresponde una curtosis igual a 9. Ya se ve que la estimación es sesgada, especialmente con muestras pequeñas, pero incluso con muestras tan grandes como n=100, un porcentaje muy alto de las estimaciones subestiman la curtosis verdadera. También se observa mucha variabilidad en los resultados, ya que los valores extremos afectan mucho al aparecer en la fórmula elevados a la cuarta potencia.\n\n\n\n\n\n\n\nFigura 1: Valores de la curtosis en muestras del tamaño n que se indica obtenidas de una distribución exponencial (curtosis = 9).\n\n\n\n\nSi lo que pretendemos es utilizar los valores de la curtosis y el coeficiente de asimetría para predecir el tipo de distribución de que provienen los datos, también lo tenemos mal. La figura 2 muestra los valores de ambas medidas calculadas para 100 muestras de tamaño \\(n = 50\\) de la misma distribución exponencial que hemos usado antes. Los verdaderos valores de la distribución (Curtosis = 9; Asimetría = 2) están marcados con un cuadrado rojo. Ya se ve que los valores muestrales no permiten identificar este punto como aquel que representa los parámetros que se están estimando.\n\n\n\n\n\n\nFigura 2: Valores de la curtosis y del coeficiente de asimetría de 100 muestras de tamaño 50 de una distribución exponencial. Los valores de la población están marcados con un cuadrado rojo.\n\n\n\n\nEn resumen tanto la curtosis como el coeficiente de asimetría forman parte de las señas de identidad de una distribución de probabilidad y tienen interés en el marco de la caracterización de los modelos teóricos, pero como medidas descriptivas son muy poco fiables.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Para qué sirve la curtosis?"
    ]
  },
  {
    "objectID": "0211_Graficos_usar.html",
    "href": "0211_Graficos_usar.html",
    "title": "¿Qué gráfico debo usar para representar mis datos?",
    "section": "",
    "text": "Naturalmente, depende del tipo de datos y de las características que queramos observar. Veamos algunas recomendaciones para las situaciones más habituales.\n\nVariabilidad\nEl histograma es una buena opción cuando el interés se centra en la variabilidad de los datos, la forma de su distribución, el valor en que están centrados y el rango en que se mueven. La figura 1 compara la producción de dos máquinas que elaboran un producto con un peso que debe estar en el intervalo 210 \\(\\pm\\) 10 g. Se han añadido unas líneas que muestran el valor objetivo y los límites de tolerancia. Se ve muy claro que se debería ajustar la máquina 1.\n\n\n\n\n\n\nFigura 1: Histogramas de los pesos producidos por dos máquinas\n\n\n\nSi se tienen pocos datos, un diagrama de puntos puede ser más adecuado. La figura 2 muestra que los valores del grupo A se sitúan en torno a 10 mientras que en el grupo B tienden a ser mayores.\n\n\n\n\n\n\nFigura 2: Diagramas de puntos para comparar dos conjutos de datos\n\n\n\n\n\nEvolución\nEl diagrama en serie de tiempo es el más adecuado cuando interesa observar la evolución de una variable. La figura 3 muestra los diámetros de 180 piezas consecutivas fabricadas por dos tornos. Se han añadido los límites de tolerancia y se aprecia claramente que los valores del torno B presentan una tendencia que conduce a la producción de piezas defectuosas.\n\n\n\n\n\n\nFigura 3: Evolución del diámetro de las piezas producidas\n\n\n\n\n\nRelación entre dos variables cuantitativas\nLa mejor forma de visualizar esta relación es a través de un gráfico de dispersión, como los de la figura 4, que ilustran la relación entre la velocidad máxima y la potencia de un conjunto 30 coches.\n\n\n\n\n\n\nFigura 4: Diagramas de dispersión. Versión clásica e incluyendo también información sobre una tercera variable cuantitativa y otra cualitativa\n\n\n\nA la izquierda tenemos un diagrama clásico en el que todos los puntos son del mismo tamaño y color. En el de la derecha los puntos se han sustituido por círculos de área proporcional a una tercera variable cuantitativa, que en este caso son las emisiones de CO2. Además, cada círculo es de un color que depende de si el motor es de gasolina o diesel. Estos gráficos con círculos de diferente tamaño que incorporan una nueva variable a la representación, se suelen denominar diagramas de burbujas.\n\n\nRelación entre una variable cuantitativa y otra cualitativa\nSe pueden usar diagramas similares al de dispersión: para cada valor de la variable cualitativa -en el eje horiontal- se colocan los puntos que representan los valores de la variable cuantitativa (figura 5, izquierda). Para evitar que los puntos queden superpuestos y se pierda información sobre su cantidad, muchos programas incluyen la opción “jitter” que les da un cierto “temblor” sacrificando precisión en sus coordenadas pero ganando en visión de cantidad.\nUna alternativa, especialmente recomendable si se tienen muchos puntos, es representar boxplots como en la figura de la derecha.\n\n\n\n\n\n\nFigura 5: Variable cuantitativa en función de los de otra cualitativa\n\n\n\n\n\nFrecuencias para variables discretas o cualitativas\nEl uso de diagramas de barras suele ser la forma más clara de representar estos datos. Son similares al histograma pero las barras no se tocan, ya que no hay continuidad en la variable que representan. Los programas que realizan este tipo de gráficos también permiten estratificar las barras tal como se muestra en la figura 6 derecha.\n\n\n\n\n\n\nFigura 6: Volumen de ventas en distintas zonas del país. A la derecha, estratificado por tipo de producto.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué gráfico debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0212_Graficos_NO_usar.html",
    "href": "0212_Graficos_NO_usar.html",
    "title": "¿Qué gráfico NO debo usar para representar mis datos?",
    "section": "",
    "text": "Los gráficos que no se deben usar pueden ser muchos. Aquí comentamos algunas “tentaciones” que conviene evitar, especialmente en contextos científicos y técnicos donde el objetivo es transmitir la información de la forma más clara y fidedigna posible.\n\nGráficos con tres dimensiones\nDeben evitarse porque la profundidad no aporta ninguna información y en cambio dificulta la interpretación de las escalas. Algunas veces se utilizan en contextos publicitarios en que se prioriza el impacto visual.\n\n\n\n\n\n\n\n\n\n\n\nFigura 1: Gráficos con una tercera dimensión y sin ella. En estos últimos la información se percibe de forma más clara y directa.\n\n\n\n\n\nDiagramas de pastel, especialmente con tres dimensiones\nLos diagramas de pastel (circulares o de queso, o pizza, si lo prefiere) son representaciones muy utilizadas aunque no tan apreciadas en contextos científico-técnicos donde -en general- se prefieren los diagramas de barras. Si se representan en tres dimensiones y desgajando un sector que se quiere destacar ya entramos en el terreno de los gráficos tendenciosos. Una alternativa similar que transmite la información de forma más clara son los llamados gráficos donut.\n\n\n\n\n\n\nFigura 2: En el gráfico de la izquierda parece que el mayor sector corresponde a la sanidad, cuando en realidad no es así.\n\n\n\n\n\nGráficos que ocupan mucho espacio y contienen poca información\nDedicar media página de un informe, o toda la pantalla de una presentación, a un gráfico de pastel que solo da un porcentaje (de la población con acceso a internet, por ejemplo) no parece una buena forma de aprovechar el papel o las pantallas de la presentación. Es más grave si se van presentando este tipo de gráficos de forma repetitiva (un diagrama para cada región, por ejemplo).\n\n\nGráficos con escalas tendenciosas\nAdaptar la escala del eje vertical según convenga es un conocido recurso para influir en la impresión que da el gráfico. La figura 3 podría representar las medidas de audiencia de cuatro cadenas de televisión. En el gráfico de la izquierda se observan unas diferencias muy claras y TV1 parece tener la mitad de la audiencia que TV4. Sin embargo, si la escala parte de cero, que es lo correcto cuando se realizan comparaciones, apenas se aprecian esas diferencias.\n\n\n\n\n\n\nFigura 3: En las comparaciones, lo correcto es partir de cero.\n\n\n\nEn los gráficos en serie temporal, si la escala vertical cubre todo el rango de variación de los datos, dará la impresión de que se ha producido un gran cambio, pero si se parte de cero, puede ocurrir que ese cambio -poco o mucho- apenas se note. En este caso, un buen criterio es que el rango de variación ocupe unos \\(2/3\\) de la amplitud de la escala.\n\n\n\n\n\n\nFigura 4: En los diagramas temporales se recomienda que el rango de variación de los datos ocupe 2/3 de la amplitud de la escala.\n\n\n\n\n\nComparar situaciones usando distintas escalas\nObserve los histogramas de la figura 5. Parece que la máquina 2 produce con más variabilidad que la 1 pero no es así. Los dos histogramas se han construido con los mismos datos. El problema está en que las escalas son distintas.\n\n\n\n\n\n\nFigura 5: No es lo que parece. Ojo con las escalas.\n\n\n\n\n\nRectas de tendencia\nNo deben añadirse líneas de tendencia cuando la mayoría de los puntos están amontonados en poco espacio. En la figura 6 hay 50 puntos en el intervalo 1 \\(\\leq\\) X \\(\\leq\\) 10 que no muestran ninguna relación entre X e Y (gráfico de la derecha). Solo 3 puntos apartados del resto, que seguramente son valores singulares o anómalos, no pueden marcar la tendencia de todo el conjunto de datos.\n\n\n\n\n\n\nFigura 6: La recta no representa la relación entre X e Y.",
    "crumbs": [
      "Estadística descriptiva",
      "¿Qué gráfico NO debo usar para representar mis datos?"
    ]
  },
  {
    "objectID": "0301_Frecuencia_densidad.html",
    "href": "0301_Frecuencia_densidad.html",
    "title": "¿Cómo se pasa de la frecuencia a la densidad de probabilidad?",
    "section": "",
    "text": "Al construir un histograma lo habitual es colocar la frecuencia en el eje vertical, pero también se puede usar la densidad de frecuencia. Para cada intervalo \\(i\\), la densidad de frecuencia \\(f_i^*\\) es igual a su frecuencia relativa \\(f_i\\) dividida por su anchura \\(c_i\\). Es decir: \\(f_i^\\ast= f_i/c_i\\). De esta forma el área de cada barra \\((c_i\\cdot f_i/c_i)\\) es igual a la frecuencia relativa. Si todos los intervalos tienen la misma anchura usar la densidad de frecuencia es una complicación innecesaria ya que tanto la altura de las barras como su área son proporcionales a la frecuencia y es más directo fijarse en la altura. Sin embargo, si los intervalos tienen distinta anchura resulta más apropiado usar la densidad.\nVamos a suponer que una empresa toma una muestra de 500 empleados con el fin de analizar la antigüedad en su puesto de trabajo y que, por razones de índole administrativa, desea considerar los intervalos que se indican en la siguiente tabla (los años de antigüedad deben leerse como: de más de … hasta …).\n\n\n\n\n\n\n\n\n\n\n\nAños de antigüedad\nAnchura del intervalo \\(c_i\\)\nFrecuencia absoluta \\(n_i\\)\nFrecuencia relativa \\(f_i\\)\nDensidad de frecuencia \\(f_i/c_i\\)\n\n\n0 - 2  2 - 3  3 - 5  5 - 10  10 - 20\n2  1  2  5  10\n50  25  200  200  25\n0,10  0,05  0,40  0,40  0,05\n0,05  0,05  0,20  0,08  0,005\n\n\nTotal\n20\n500\n1\n\n\n\n\n\nRealizar el histograma con esos intervalos y las frecuencias absolutas (o relativas) no es una buena idea porque se tiende a comparar las frecuencias sin tener en cuenta la diferencia en la anchura de los intervalos. No es lo mismo tener 200 observaciones en un intervalo ancho (por ejemplo, de 5 a 10 años) que en otro más estrecho (de 3 a 5). Usar la densidad de frecuencia da una visión de los datos más acorde con la realidad.\nLa forma de calcular la densidad de frecuencia para cada intervalo es muy fácil, para el primer intervalo tenemos \\(f_1^\\ast=f_1/c_1=0,10/2 = 0,05\\) y así la calculamos para todos. El área del segundo intervalo deberá ser la mitad del área del primero porque tiene la mitad de observaciones, y el área sobre el tercero deberá ser cuatro veces el área sobre el primero.\n\n\n\n\n\n\nFigura 1: Histograma con intervalos desiguales\n\n\n\nEs intuitivamente claro que si el primer intervalo contiene el 10 % de los datos y estos están distribuidos en una anchura de 2 unidades, en promedio tenemos un 5 % en cada unidad. En el cuarto intervalo, por ejemplo, sus 5 años contienen el 40 % de los empleados, así que en promedio tenemos un 8% de los empleados cada año, o lo que es lo mismo: \\(f_4^*=0,08/año\\). En las ordenadas tenemos la frecuencia relativa por unidad de intervalo, por eso se denomina densidad de frecuencia.\nDe esta forma, la estimación de un porcentaje relacionado con la antigüedad se convierte en el cálculo de un área. Así, por ejemplo, si se está interesado en estimar el porcentaje de empleados con una antigüedad menor o igual a 4 años, digamos \\(P(X \\le 4)\\), bastará con calcular el área del histograma comprendida entre 0 y 4 tal como muestra la figura 2 (izquierda).\nObserve que el área sombreada se calcula sumando por un lado las áreas de los primeros rectángulos (0,10 + 0,05) y por otro lado la parte del tercer rectángulo comprendida entre 3 y 4. Como en este tercer rectángulo se conoce su densidad, que es de 0,20, y se requiere un año, el porcentaje de empleados entre 3 y 4 años será 0,20·1 = 0,20. Finalmente, tenemos que la proporción de empleados con una antigüedad de 4 años o menos se estima en: \\(P(X\\le4)=0,10+0,05+0,20=0,35\\).\nAnálogamente, si se desea estimar la proporción con una antigüedad entre 4 y 7,5 años habrá que calcular el área entre dichos valores, tal como muestra la figura 2 (derecha). Haciendo el cálculo se obtiene: \\(P(4\\le X\\le7.5)=0,40\\).\n\n\n\n\n\n\nFigura 2: Cálculo de frecuencias a través de áreas\n\n\n\n\nDe la densidad de frecuencias a la función densidad de probabilidad\nSupongamos ahora que tenemos una muestra de 10.000 valores de una cierta variable \\(X\\). En el lado izquierdo de la figura 3 tenemos su histograma y en el derecho ese mismo histograma pero con la densidad de frecuencias en el eje de ordenadas y superponiendo dos líneas que parece razonable considerar que representan a la población de la que provienen estos datos.\n\n\n\n\n\n\nFigura 3: Histograma con frecuencias absolutas (izquierda) y con densidad de frecuencia (derecha)\n\n\n\nLa función que describe esas líneas que hemos añadido es la función densidad de probabilidad. Respecto a las muestras hablamos de frecuencia, mientras que en el contexto de las poblaciones usamos el término probabilidad.\nEn este caso la función densidad de probabilidad \\(f(x)\\) es:\n\\[\\begin{equation*}\n\n   f(x) = \\left \\{\n\n   \\begin{aligned}\n\n       x\\;\\; & \\quad\\text{para}\\;\\; 0&lt;x \\leq 1 \\\\\n\n       2-x & \\quad\\text{para}\\;\\; 1&lt;x \\leq 2\n\n   \\end{aligned}\n\n   \\right.\n\n\\end{equation*}\\]\nEn la muestra, la frecuencia entre 0,5 y 1,5 será igual a la suma de las áreas de las barras que se encuentran en esos valores. Para la población, la probabilidad de que \\(x\\) se encuentre entre esos valores será igual al área que definen en el triángulo:\n\\[P(0,5 \\leq x \\leq 1,5) = \\int_{0,5}^1 x \\; dx + \\int_1^{1,5}(2-x) \\; dx =\\frac{3}{4}\\] \nSi en vez de una distribución triangular tenemos -por ejemplo- una distribución Normal, la expresión de \\(f(x)\\) es más complicada, pero el planteamiento es exactamente el mismo.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Cómo se pasa de la frecuencia a la densidad de probabilidad?"
    ]
  },
  {
    "objectID": "0302_Que_Distribucion.html",
    "href": "0302_Que_Distribucion.html",
    "title": "¿Cómo se sabe qué distribución sigue una variable aleatoria?",
    "section": "",
    "text": "Preámbulo: ¿qué es una distribución de probabilidad?\nParece que si un valor depende del azar poco se puede hacer para describir su comportamiento, depende del azar y listo. Azar suena a impredecible, a lotería. En un juego de azar solo afecta la suerte y no hay manera de prever qué resultado saldrá.\nPero no es cierto que al decir que un valor depende del azar ya esté todo dicho. El azar se puede clasificar en familias y cada una tiene un patrón de comportamiento específico (aunque también en este caso las grandes familias están emparentadas entre ellas). Los que no entendemos de carpintería decimos que un mueble es de madera sin entrar en más consideraciones, pero el carpintero sabe que maderas hay de muchos tipos, caras y baratas, con unas propiedades u otras, y que no todas sirven para todo. Los que nos dedicamos a la estadística no hace falta que sepamos de maderas, pero sí debemos conocer las clases de azar y si la variable que nos ocupa pertenece a una de las familias conocidas podemos aplicar sus propiedades -sin tenerlas que deducir- y todo se hace mucho más fácil. Claro que no hablamos de familias sino de distribuciones de probabilidad, o de distribuciones, sin más.\n\n\n¿Cómo seleccionar la distribución que mejor se adapta a nuestra variable?\nNo se trata de ir haciendo pruebas para ver cual encaja mejor en nuestros datos (si se tienen pocos encajarán casi todas) sino que hay que basarse en las características de esos datos y en la forma en que se han obtenido.\nSi la variable es continua (puede tomar cualquier valor dentro de un intervalo), presenta una distribución simétrica en torno a su valor central y a medida que nos alejamos de ese valor central -por encima y por debajo- disminuye el número de valores observados, como en el caso de las estaturas, seguramente su comportamiento se puede modelar a través de la distribución Normal. Si todos los valores son igualmente probables, entonces la distribución se llama uniforme. Este es el caso de los números aleatorios que genera Excel con la función =ALEATORIO(), pertenecen a una distribución uniforme entre 0 y 1.\nOtras variables continuas tienen una distribución no simétrica. Esta circunstancia se da cuando los valores se alejan con más libertad hacia un lado que hacia el otro, en el que normalmente hay un frontera que impide el paso. Por ejemplo, la redondez de una pieza se mide como la diferencia entre sus diámetros máximo y mínimo. Si intentamos que las piezas sean perfectamente redondas estos valores se amontonarán contra el cero sin que haya límite para los valores grandes, con lo que se obtiene una distribución asimétrica. En alguna de estas situaciones el logaritmo de los datos sigue una distribución que puede considerarse Normal, por lo que esa distribución se llama lognormal.\nSi la variable es discreta (solo pueden tomar valores a saltos -en general números enteros-) el caso más sencillo es cuando todos los valores tienen la misma probabilidad de aparecer, como el resultado de lanzar un dado, en cuyo caso se llama uniforme discreta}. Otro caso muy típico es el número de “éxitos” al realizar \\(n\\) experimentos siendo \\(p\\) la probabilidad de éxito, como el número de piezas defectuosas en un lote de 100 unidades si la probabilidad de que una pieza sea defectuosa es 0,05. También tenemos una distribución para contar ocurrencias como el número de veces que se estropea un ascensor en un año o el número de visitas diarias a una página web. La primera distribución recibe el nombre de binomial y la segunda es la distribución de Poisson.\nAl principio puede costar distinguir cuando una variable sigue una distribución binomial o de Poisson, pero es muy fácil fijándose en los detalles que se indican en la siguiente tabla.\n\n\n\n\n\n\n\n\n\n\nBinomial\nPoisson\n\n\nForma de contar\nSe pueden contar éxitos o fracasos, piezas correctas o piezas defectuosas\nSolo hay una forma de contar las ocurrencias. No se puede contar el número de veces que no se estropea un ascensor\n\n\nValor máximo\nExiste un máximo. En un lote de 100 piezas como máximo hay 100 defectuosas\nNo hay valor máximo (al menos en teoría). No hay máximo en el número de veces que se puede estropear el ascensor\n\n\n\n\n\nTambién existen distribuciones teóricas que se utilizan como referencia en los contrastes de hipótesis. Las más conocidas son la t-Student, la Chi-cuadrado y la F de Snedecor. Según sea el test que se realiza, la distribución adecuada será una u otra. En los libros también aparecen distribuciones “para hacer ejercicios”, que sólo son expresiones matemáticas en las que no se comenta cual es el fenómeno a que se refieren ni cual es el sentido físico de la variable en cuestión. Hay que entender estas distribuciones como instrumentos para practicar las propiedades de las distribuciones de probabilidad, aunque también es verdad que determinadas variables se pueden modelar con funciones específicas, “no catalogadas” como las que aparecen en ese tipo de ejercicios.\nEn cualquier caso, catalogado o no, no hay que confundir el modelo con la realidad. Uno de los ejemplos más socorridos es el de la estatura para ilustrar la distribución Normal, pero si tuviéramos las estaturas de los millones de habitantes adultos del planeta, podríamos comprobar que no se ajustan “exactamente” a la conocida campana de Gauss, y tampoco lo harían si estratificamos por sexo, raza, o lo que sea. Se trata, como en los otros casos, de un buen modelo que permite realizar estimaciones con suficiente precisión a efectos prácticos pero que no deja de ser un modelo teórico que no coincide exactamente con la realidad. Lo mismo ocurre con las otras distribuciones que, aun siendo modelos teóricos (lo de teórico para un modelo es un adjetivo innecesario) son muy útiles en la práctica.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Cómo se sabe qué distribución sigue una variable aleatoria?"
    ]
  },
  {
    "objectID": "0303_Media_var_aleatoria.html",
    "href": "0303_Media_var_aleatoria.html",
    "title": "¿Por qué se dice que la media es una variable aleatoria?",
    "section": "",
    "text": "Antes de hablar de medias hablaremos de observaciones individuales y utilizaremos el ejemplo de la distribución de las estaturas.\nLa estatura de una persona concreta es un número. Por ejemplo, Juan mide 1,73 metros, Antonio 1,82 y María 1,76. Estos valores son números fijos y concretos, puesto que Juan, al igual que Antonio y María, siempre miden lo mismo.\nOtra cosa es si nos referimos a la altura de una persona genérica, la que en este momento puede estar pasando delante de la puerta de su casa. ¿Qué estatura tiene? No lo sabemos. La estatura de una persona, así, a nivel general, es una variable aleatoria, que podemos modelar bastante bien a través de una distribución Normal.\nAlgo análogo ocurre con las medias de las muestras. La media de una muestra formada por unos individuos concretos es también un número concreto. Si la muestra está formada por Juan, Antonio y María, su estatura media es 1,77 metros. Pero si hablamos de una muestra de tres individuos tomados al azar, la media de esa muestra es una variable aleatoria, ya que está formada por observaciones individuales que a su vez son también variables aleatorias.\nLo más interesante de este tema es que la media muestral se distribuye siempre con la misma media que las observaciones individuales y con una varianza que es la enésima parte (siendo \\(n\\) el tamaño de la muestra) de la que tienen esas observaciones. Además, si \\(n\\) no es muy pequeño, su distribución es muy próxima a la Normal con independencia de la distribución de la población.\nPensemos, por ejemplo, en la estatura de 20 personas, si representamos sus valores en un diagrama de puntos, podemos obtener un gráfico como el de la figura 1.\n\n\n\n\n\n\nFigura 1: Estaturas de 20 personas\n\n\n\n\nSin embargo, si pensamos en la altura media de grupos de 25 personas, ya no podemos dar valores tan extremos, puesto que aunque es perfectamente posible que una persona mida 1,85 metros, es prácticamente imposible que esta sea la altura media de un grupo de 25 personas tomadas al azar, ya que en este grupo cabe esperar que haya un número parecido de personas por encima y por debajo de la media general, de forma que los valores de sus alturas se compensarán dando un valor medio cercano a la media de la población. En la figura 2 se muestra el diagrama de puntos de unos valores que podrían corresponder a las alturas medias de 20 grupos con 25 individuos cada uno. Estos valores se han obtenido por simulación suponiendo que las alturas individuales siguen una N(1,70 m; 0,07 m). Obsérvese como su dispersión es menor que para las alturas individuales.\n\n\n\n\n\n\nFigura 2: Estaturas medias de 20 grupos de 25 personas cada uno\n\n\n\n\nSi suponemos que la distribución de las estaturas sigue la distribución Normal que hemos comentado, podemos afirmar que las medias de muestras de $ n $ individuos seguirán también una distribución Normal, con la misma media que la población, \\(\\mu_{\\bar{x}}\\)=1,70, y una desviación típica que será: \\(\\sigma_{\\bar{x}}=\\sigma/\\sqrt{n}\\), en nuestro caso: \\(0,07/\\sqrt{25} = 0,014\\).\nEn definitiva, la media muestral, protagonista destacada en muchos estudios estadísticos, es una variable aleatoria nada misteriosa, con un comportamiento noble y fácil de prever.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Por qué se dice que la media es una variable aleatoria?"
    ]
  },
  {
    "objectID": "0304_formula_Normal.html",
    "href": "0304_formula_Normal.html",
    "title": "¿De dónde sale la fórmula de la distribución Normal?",
    "section": "",
    "text": "En los libros de estadística es fácil encontrarse con la famosa –y también curiosa, incluye los números \\(\\pi\\) y \\(e\\)– función densidad de probabilidad de la distribución Normal. Lo que no es tan fácil es encontrar una explicación de cómo se obtiene. Se puede llegar a ella de una manera formal por diferentes vías, pero ninguna es fácil y nosotros tampoco vamos emprender ese camino1. Jugando con la ventaja de saber donde queremos llegar, nos vamos a conformar con justificar que es muy razonable que esa función sea como es.\nPara ello hemos construido un histograma con 10.000 valores generados aleatoriamente de una distribución Normal con media \\(\\mu\\) =10 y desviación típica \\(\\sigma\\)=2 (estos valores son arbitrarios, podrían ser otros) y vamos a intentar llegar a la función que da el perfil suavizado de este histograma.\nLa primera observación que puede hacerse es que la forma de caída del histograma a ambos lados recuerda la función exponencial. La parte de la izquierda, en que la función es creciente, podría ser de la forma \\(f(x)=e^x\\) , pero para poder representar la parte derecha de forma simétrica, utilizaremos la función \\(f(x)=e^{x-10}\\) para la parte creciente de la izquierda y \\(f(x)=e^{10-x}\\) para la parte de la derecha.\nAhora debemos colocar en una sola función la parte creciente y la decreciente. Esto se consigue mediante la expresión \\(f(x)=e^{-\\vert x-10 \\vert}\\).\nYa tenemos una función que tiene una forma parecida a la Normal en las colas pero que presenta un pico en su máximo. Este pico, punto en que la función no tiene derivada, provoca el mal comportamiento característico de la función valor absoluto. Por tanto, si el problema está en la expresión \\(\\vert x-10 \\vert\\) es razonable pensar en sustituirla por el cuadrado de la diferencia: \\((x-10)^2\\).\nLa figura 4 muestra la función \\(f(x) = e^{-(x-10)^2}\\) superpuesta con el histograma de los datos. Vamos por buen camino, efectivamente el pico ha desaparecido y ya tenemos forma de campana, aunque ahora se trata de ensancharla.\nEnsanchar la campana significa aumentar el valor de las ordenadas para \\(x\\neq 10\\) manteniendo la forma de la función. Esto se consigue dividiendo el exponente por una constante que debe depender de la variabilidad de los datos y, por tanto, de \\(\\sigma\\). Se pueden hacer pruebas para deducir ese valor y resulta ser \\(2 \\sigma^{2}\\).\nEn la figura 5 tenemos la superposición de la función \\(f(x) = e^{- \\frac{(x - \\mu)^2}{2 \\sigma^2}}\\) (en la que \\(\\mu\\) = 10 y \\(\\sigma\\) = 2) con el histograma de los datos.\nEl ajuste es excelente, pero esta no es la función densidad de probabilidad de la distribución Normal. En realidad no es ni una función densidad de probabilidad. Para serlo es necesario que el área bajo la curva sea igual a 1 y en nuestra función esto no es así.\nSi el área es igual a \\(K\\) entonces \\(\\frac{1}{K}f(x)\\) mantendrá la misma forma y con las mismas proporciones, ya que solo cambia un factor de escala en el eje de ordenadas, y ahora el área sí será igual a 1.\nPara saber cuanto vale \\(K\\) solo hay que integrar nuestra función. Se puede hacer en una página web con calculadora de integrales (nosotros hemos usado calculadora-de-integrales.com) y se obtiene:\n\\[ \\int_{-\\infty}^{\\infty} e^{- \\frac{(x - \\mu)^2}{2 \\sigma^2}} = \\sigma \\sqrt{2 \\pi} \\]\nAhora sí hemos llegado a la fórmula que buscábamos:\n\\[ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}} \\]\nNo podemos acabar diciendo aquello de “como queríamos demostrar” pero esperamos que ahora esta expresión se vea más justificada.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿De dónde sale la fórmula de la distribución Normal?"
    ]
  },
  {
    "objectID": "0305_Solo_N01.html",
    "href": "0305_Solo_N01.html",
    "title": "¿Por qué para la distribución Normal solo se necesita la tabla de la N(0; 1)?",
    "section": "",
    "text": "Aunque las tablas estadísticas ya son algo del pasado, es interesante ver porqué habiendo infinitas distribuciones Normales (tantas como parejas \\(\\mu\\), \\(\\sigma\\)) basta la tabla de solo una para poder calcular probabilidades en todas ellas.\nLo veremos con razonamientos básicamente geométricos. Sea \\(X \\sim N(\\mu; \\sigma)\\) y deseamos calcular \\(P(X&gt;x)\\). Si definimos \\(Y = X - \\mu\\) está claro que \\(Y \\sim N(0; \\sigma)\\) y con ayuda de la figura 1 es fácil observar que \\(P(X&gt;x)=P(Y&gt;x-\\mu)\\) ya que la forma de las dos distribuciones es idéntica y al punto \\(x\\) en la distribución de \\(X\\) le corresponde \\(x-\\mu\\) en la de \\(Y\\).\n\n\n\n\n\n\nFigura 1: Transformación de \\(X \\sim N(\\mu; \\sigma)\\) en \\(Y \\sim N(0; \\sigma)\\)\n\n\n\nSi \\(Y \\sim N(0; \\sigma)\\) y \\(k\\) es una constante, entonces \\(kY \\sim N(0; k\\sigma)\\) ya que \\(E(kY) = kE(Y) = 0\\) y \\(V(kY) = k^2 \\sigma^2\\). Veamos ahora como representar la distribución de \\(kY\\).\nSi representamos \\(f(Y)\\) y \\(f(kY)\\) utilizando los mismos ejes, las formas de las distribuciones serán distintas, por tener distinto valor de \\(\\sigma\\), pero también podemos representarlas usando la misma forma para la distribución (misma campana) y cambiar las escalas de los ejes, tal como se indica en la figura 2.\nRecordando que la función densidad de probabilidad de \\(Y \\sim N(0; \\sigma)\\) es: \\(f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{- \\frac{y^2}{2\\sigma^2}}\\), se deduce que:\n\\[ f(ky) = \\frac{1}{k\\sigma \\sqrt{2 \\pi}}e^{- \\frac{k^2y^2}{2 k^2 \\sigma^2}} = \\frac{1}{k}f(y) \\]\n\n\n\n\n\n\nFigura 2: Distribución con \\(\\sigma\\) =1 o con \\(\\sigma = k\\) según la escala\n\n\n\nPor tanto, las campanas se pueden representar de forma idéntica multiplicando por \\(k\\) el eje de abscisas y dividiendo por el mismo valor el de ordenadas (que no hemos representado).\nSi hacemos \\(k= \\frac{1}{\\sigma}\\) tendremos \\(Z = \\frac{Y}{\\sigma}\\), o lo que es lo mismo: \\(Z = (X-\\mu)/ \\sigma\\). Por lo comentado anteriormente, la distribución de \\(Z\\) se puede representar con la misma campana que la utilizada para la distribución de $ Y $ (3).\n\n\n\n\n\n\nFigura 3: Transformación de \\(Y \\sim N(0; \\sigma)\\) en \\(Z \\sim N(0; 1)\\)}\n\n\n\nSi la forma de las campanas es la misma y solo hemos sustituido el punto \\(x - \\mu\\) por el \\(\\frac{x - \\mu}{\\sigma}\\) resulta claro que \\(P \\left( Z &gt; \\frac{x -\\mu}{\\sigma} \\right) = P\\left( Y &gt; X - \\mu \\right)\\) y, por tanto, \\(P\\left( X&gt;x\\right) = P\\left(Z&gt; \\frac{x-\\mu}{\\sigma}\\right)\\).",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Por qué para la distribución Normal solo se necesita la tabla de la N(0; 1)?"
    ]
  },
  {
    "objectID": "0306_Estatura_cero.html",
    "href": "0306_Estatura_cero.html",
    "title": "¿Por qué la probabilidad de tener mi estatura es igual a cero?",
    "section": "",
    "text": "Si usted mide 1,68 m y considerando que las estaturas siguen una distribución Normal calcula la probabilidad de que se dé ese valor, descubrirá que esa probabilidad es cero ¡pero usted existe! Esta paradoja, que se da -por supuesto- para todas las estaturas, es debida a que en la práctica tratamos como discretas a las variables que en realidad son continuas.\nCuando decimos que \\(X\\) sigue una distribución \\(N(\\mu; \\sigma)\\), estamos diciendo también que \\(X\\) es una variable continua que puede tomar infinitos valores. Sabemos que la probabilidad de que tome valores comprendidos entre \\(a\\) y \\(b\\) es igual al área definida por su función densidad de probabilidad entre estos valores, es decir: \\[ P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) dx \\] Por tanto: \\[ P(X=1,68) = P(1,68 \\leq X \\leq 1,68) = \\int_{1,68}^{1,68} f(x) dx = 0 \\] Pero cuando decimos que alguien mide 1,68 metros no queremos decir que mide exactamente 1,680000000… con infinitos ceros, sino que entendemos que el valor se ha redondeado y lo que queremos decir es que su altura está comprendida entre 1,675 y 1,685 (si fuera menor de 1,675 lo habríamos aproximado a 1,67 y si mayor de 1,685 a 1,69)\nSuponiendo que las alturas se distribuyen según una Normal con media \\(\\mu\\)=1,70 m y desviación típica \\(\\sigma\\)=0,07 m, la probabilidad de que una persona mida 1,68 m (entendido como valor redondeado, que es como hablamos), es de 0,0547 (figura 1).\n\n\n\n\n\n\nFigura 1: Probabilidad de tener valores entre 1,675 y 1,685\n\n\n\nTodas las variables continuas se discretizan para tratar con ellas en la práctica. Casi siempre se redondea, como en el caso de la estatura, aunque en algunos casos se trunca, como hacemos con las edades. Si hoy es día de elecciones y usted cumple los 18 años mañana, hoy tiene 17+364/365 = 17,997 años, pero no le dejarán votar.\n\nObservación final\nUn argumento falaz, pero muchas veces convincente haciendo mención a aquello de los casos favorables partido por los casos posibles, es considerar que si la variable puede tomar infinitos valores, la probabilidad de que tome uno en concreto es cero. Esto es falso porque la regla de casos favorables partido por casos posibles solo vale cuando todos los sucesos tienen la misma probabilidad de ocurrir y este no es nuestro caso. Por otra parte, es perfectamente posible que una variable pueda tomar infinitos valores y que ninguno de ellos tenga probabilidad cero. Piense, por ejemplo, en la distribución de Poisson.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Por qué la probabilidad de tener mi estatura es igual a cero?"
    ]
  },
  {
    "objectID": "0307_Contrario_Normal.html",
    "href": "0307_Contrario_Normal.html",
    "title": "¿Existen variables con comportamiento contrario a la distribución Normal?",
    "section": "",
    "text": "Entendemos por ``contrario a la Normal’’ que la mayor frecuencia se da en los extremos, en vez de en torno al valor medio.\nPor ejemplo, la edad al morir sigue una distribución con picos en los extremos. Si siguiera una distribución Normal la mayoría de personas moriría en torno a los 40 años y sabemos que esto no es así. Actualmente la distribución de la edad al morir tiene forma de J, es decir, el pico alto se da en los valores más altos aunque también hay un pico pequeño (cada vez más pequeño) que tiene que ver con la mortalidad infantil. Con la duración de los productos tecnológicos pasa algo parecido, y también existe una cierta “mortalidad infantil”, para eso está la garantía.\nOtro ejemplo que se suele citar es el de la distribución del porcentaje de cielo cubierto. Parece que en general es más frecuente que el cielo esté totalmente cubierto o totalmente despejado a que esté cubierto en torno al 50 %. La cobertura de las nubes se mide en octas (u octavas) pero no es fácil encontrar datos sobre esta variable. Las webs de estaciones meteorológicas que hemos consultado, no lo registran o no informan.\nEn el terreno de los modelos teóricos este fenómeno se da en la distribución del coeficiente de correlación entre variables independientes con muestras de tamaño \\(n=3\\). Si \\(n=1\\) solo se tiene un punto y no es posible calcular ninguna correlación. Si \\(n=2\\) solo puede tomar los valores 1 y -1, es decir, solo los valores extremos. Cuando \\(n=3\\) ya puede tomar cualquier valor entre -1 y 1 pero es más probable que tome valores cerca de los extremos. Si \\(n=4\\) todos los valores tienen la misma densidad de probabilidad (y como \\(r\\) está definido entre -1 y 1, seguro que será 0,5 para que el área sea 1). A medida que \\(n\\) aumenta va apareciendo la típica forma de campana.\nUtilizando la fórmula de la función densidad de probabilidad de \\(r\\) (coeficiente de correlación muestral) cuando en la población es igual a cero (\\(\\rho\\) =0) hemos construido la figura 1 donde se puede observar la forma de la \\(f(r)\\) para diversos valores de \\(n\\). Para \\(n=30\\) se ha superpuesto una distribución Normal con la misma media y desviación típica. Para ese valor de $ n $ las dos distribuciones ya son casi idénticas pero no llega a ser Normal porque \\(f(r)\\) está definida en el intervalo \\((-1, 1)\\) mientras que en una Normal el rango de variación no está acotado.\n\n\n\n\n\n\nFigura 1: Función densidad de probabilidad del coeficiente de correlación para variables independientes según el tamaño de muestra",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Existen variables con comportamiento contrario a la distribución Normal?"
    ]
  },
  {
    "objectID": "0308_Formula_Poisson.html",
    "href": "0308_Formula_Poisson.html",
    "title": "¿De dónde sale la fórmula de la distribución de Poisson?",
    "section": "",
    "text": "Vamos a partir de la distribución binomial cuando el número de pruebas \\(n\\) tiende a infinito y la probabilidad de éxito \\(p\\) tiende a cero, manteniéndose constante el valor \\(np\\) al que llamamos \\(\\lambda\\).\nSabemos que si \\(X\\) sigue una distribución binomial con parámetros \\(n\\), \\(p\\):\n\\[\\begin{equation*}\n    \\begin{split}\n    P(X=x) &=\\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x} \\\\\n        &= \\frac{n!}{x!(n-x)!} \\left(\\frac{\\lambda}{n} \\right )^{x} \\left(1-\\frac{\\lambda}{n} \\right )^{n-x}\\\\\n        &=\\frac{n(n-1) \\ldots (n-x+1)}{x!} \\cdot \\frac{\\lambda^{x}}{n^x} \\cdot \\left(1-\\frac{\\lambda}{n} \\right )^{n} \\left(1-\\frac{\\lambda}{n} \\right)^{-x}\\\\\n        &= \\underbrace{\\vphantom{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}} \\frac{n(n-1)\\ldots(n-x+1)}{n^x} }_1 \\cdot\n            \\underbrace{\\vphantom{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}} {\\frac{\\lambda^x}{x!}}}_2 \\cdot      \n        \\underbrace{\\left(1-\\frac{\\lambda}{n} \\right )^{n}}_3  \\underbrace{\\left(1-\\frac{\\lambda}{n} \\right )^{-x}}_4\n\\end{split}\n\\end{equation*}\\]\nEn el primer paso simplemente se ha sustituido \\(p\\) por \\(\\lambda/n\\). A continuación se simplifica la expresión del número combinatorio y se realizan cambios evidentes. Finalmente se intercambian los valores de \\(n^x\\) y \\(x!\\) en los denominadores de los 2 primeros términos y dividimos la expresión en 4 partes que analizamos a continuación:\n\nParte 1:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\frac{n(n-1)\\ldots(n-x+1)}{n^x} &=\\frac{n}{n} \\cdot \\frac{n-1}{n} \\cdot \\frac{n-2}{n}\\ldots\\frac{n-x+1}{n}= \\\\\n        &=1 \\cdot\\left(1-\\frac{1}{n} \\right) \\left(1-\\frac{2}{n} \\right) \\ldots \\left(1-\\frac{x-1}{n} \\right)\n    \\end{split}\n\\end{equation*}\\]\nEstá claro que si \\(n \\to \\infty\\) manteniéndose \\(x\\) constante, cada uno de los términos tiende a 1 y, por tanto: \\[\\displaystyle\\lim_{n \\to \\infty} \\frac{n(n-1) \\ldots (n-x+1)}{n^x} =1 \\]\n\n\nParte 2:\nLa expresión \\(\\frac{\\lambda^x}{x!}\\) la dejamos tal como está.\n\n\nParte 3:\nEl análisis de esta tercera parte va a ser un poco más largo. Partiremos de la definición del número \\(e\\) como \\(\\displaystyle\\lim_{n \\to \\infty} \\left( 1+\\frac{1}{n} \\right)^n\\) e intentaremos poner nuestra expresión de una forma parecida a esta.\nPara empezar puede comprobarse que se verifica: \\[\\left( 1-\\frac{\\lambda}{n} \\right)^n =  \\left [\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} \\right ]^{-\\lambda}\\] Operando solo con la expresión del interior del corchete: \\[\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}}=\\left( \\frac{n/\\lambda}{n/\\lambda}-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} =  \\left( \\frac{n/\\lambda-1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} = \\left( \\frac{n/\\lambda}{n/\\lambda-1} \\right )^{\\frac{n}{\\lambda}}\\] y también podemos hacer:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\left(\\frac{n/\\lambda}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}}&=\\left(1+\\frac{1}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}} =\\\\\n        &= \\left(1+\\frac{1}{n/\\lambda-1} \\right)^{\\frac{n}{\\lambda}-1} \\cdot \\left(1+\\frac{1}{n/\\lambda-1} \\right)\n    \\end{split}\n\\end{equation*}\\]\nObsérvese que siendo \\(\\lambda\\) una constante, cuando \\(n \\to\\infty\\) también \\((n/\\lambda-1) \\to\\infty\\). Por tanto el primer factor de la última expresión es igual a \\(e\\) cuando \\(n \\to\\infty\\). El segundo factor evidentemente es igual a 1 cuando \\(n \\to\\infty\\), por tanto:\n\\[ \\displaystyle\\lim_{n \\to \\infty} \\left( 1-\\frac{\\lambda}{n} \\right)^n  = \\displaystyle\\lim_{n \\to \\infty} \\left [\\left( 1-\\frac{1}{n/\\lambda} \\right)^{\\frac{-n}{\\lambda}} \\right ]^{-\\lambda} = e^{-\\lambda} \\]\n\n\nParte 4:\nEn esta última parte resulta claro que \\(\\displaystyle\\lim_{n \\to \\infty} \\left( 1-\\frac{\\lambda}{n} \\right)^{-x}  =1.\\)\nRecopilando, tenemos que en las condiciones indicadas de \\(n \\to\\infty\\), \\(p \\to 0\\) con \\(np\\) constante e igual a \\(\\lambda\\), se verifica que:\n\\[P(X=x)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\]",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿De dónde sale la fórmula de la distribución de Poisson?"
    ]
  },
  {
    "objectID": "0309_Varianza_Chi_cuadrado.html",
    "href": "0309_Varianza_Chi_cuadrado.html",
    "title": "¿Cómo se relaciona la varianza muestral con la distribución Chi-cuadrado?",
    "section": "",
    "text": "Utilizaremos la definición de \\(\\chi^2\\) con \\(\\nu\\) grados de libertad como \\(\\sum_{i=1}^{\\nu} z_{i}^2\\) siendo las \\(z_i\\) variables aleatorias independientes con distribución \\(N(0; 1)\\). Respecto a la notación utilizada consideraremos que \\(X \\sim N(\\mu;\\sigma)\\) y que \\(\\bar{X}\\) y \\(S^2\\) son la media y la varianza de muestras aleatorias de tamaño \\(n\\). Tenemos:\n\\[\\begin{equation*}\n    \\begin{split}\n        \\sum_{i=1}^n (X_i-\\mu)^2 &= \\sum_{i=1}^n \\left[ (X_i-\\bar{X})+(\\bar{X}-\\mu) \\right]^2\\\\\n        &= \\sum_{i=1}^n (X_i-\\bar{X})^2+2(\\bar{X}-\\mu) \\sum_{i=1}^n (X_i-\\bar{X})+ \\sum_{i=1}^n (\\bar{X}-\\mu)^2 \\\\\n    \\end{split}\n\\end{equation*}\\]\ny como \\(\\sum_{i=1}^n (X_i-\\bar{X})=0\\) y \\((\\bar{X}-\\mu)^2\\) es una constante: \\[\\sum_{i=1}^n (X_i-\\mu)^2 = \\sum_{i=1}^n (X_i-\\bar{X})^2 + n(\\bar{X}-\\mu)^2\\]\nComo \\(S^2= \\frac{\\sum_{i=1}^n (X_i-\\bar{X})^2}{n-1}\\) podemos escribir:\n\\[\\sum_{i=1}^n (X_i-\\bar{X})^2 = S^2(n-1)\\]\nSustituyendo en la expresión anterior y dividiéndolo todo por \\(\\sigma^2\\):\n\\[\\frac{\\sum_{i=1}^n(X_i-\\mu)^2}{\\sigma^2} = \\frac{S^2(n-1)}{\\sigma^2}+ \\frac{(\\bar{X}-\\mu)^2}{\\sigma^2/n} \\]\nAceptando que los dos sumandos que aparecen a la derecha corresponden a variables aleatorias independientes, tenemos:\n\\[\\sum_{i=1}^{n} z_{i}^2 = \\frac{S^2(n-1)}{\\sigma^2}+z^2\\]\nY dado que la suma de variables aleatorias independientes distribuidas según \\(\\chi^2\\) sigue también esta misma distribución con un número de grados de libertad igual a la suma de los grados de libertad de las distribuciones sumadas, se espera que si \\(\\sum_{i=1}^{n} z_{i}^2 \\sim \\chi_{n}^2\\) y \\(z^2 \\sim \\chi_{1}^2\\), entonces:\n\\[\\frac{S^2(n-1)}{\\sigma^2} \\sim \\chi_{n-1}^2\\]",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Cómo se relaciona la varianza muestral con la distribución Chi-cuadrado?"
    ]
  },
  {
    "objectID": "0310_Sumark_Multiplicark.html",
    "href": "0310_Sumark_Multiplicark.html",
    "title": "¿Por qué no es lo mismo sumar \\(k\\) veces una variable aleatoria que multiplicarla por \\(k\\)?",
    "section": "",
    "text": "El resultado es el mismo cuando las cantidades a que nos referimos son magnitudes constantes. Para saber cuántos huevos hay en 8 docenas, como el número de huevos en una docena es una constante, podemos sumar 12 huevos 8 veces o multiplicar 12 por 8 (¡evidente!). Pero si lo que tenemos es una variable aleatoria, como el peso de un huevo, esto ya no es verdad.\nNo es lo mismo el peso de una docena de huevos que el peso de un huevo multiplicado por 12 porque aunque estas dos variables tienen el mismo valor medio no tienen la misma variabilidad y, por tanto, no podemos decir que son iguales.\nPara entender porque esto es así, aclararemos en primer lugar el significado de la notación que vamos a utilizar. Llamaremos \\(X\\) a la variable aleatoria que consideramos (en nuestro ejemplo es el peso de un huevo), podríamos decir que \\(X\\) se distribuye según una Normal, pero no necesitamos hacer referencia a ninguna distribución en concreto, sólo hay que tener claro que no es un valor fijo, sino una variable aleatoria. Si tomamos una docena, designaremos los pesos como \\(X_1, X_2, \\ldots, X_{12}\\). Cada una de las \\(X_i\\) es una variable aleatoria con la misma distribución que \\(X\\). En realidad son extracciones de la misma población, el subíndice sólo indica el orden en que extraen.\nEchando mano de las fórmulas correspondientes y suponiendo que los 12 pesos son independientes, tendremos que la esperanza matemática y la varianza del peso de una docena será:\n\\[E(X_1+X_2+\\ldots+X_{12})=E(X_1)+\\ldots+E(X_{12})=12 \\cdot E(X)\\] \\[V(X_1+X_2\\ldots+X_{12})=V(X_1)+ \\ldots+V(X_{12})=12 \\cdot V(X)\\]\nPensemos ahora en la variable “peso de un huevo multiplicado por 12”, es decir, la variable \\(12X\\). Ahora tendremos:\n\\[E(12X)=12 \\cdot E(X)\\]\n\\[V(12X)=12^2 \\cdot V(X)=144 \\cdot V(X)\\]\nVamos a ver que estas fórmulas reflejan lo que ocurre en la realidad a través una mirada intuitiva al problema. Cuando formamos una docena de huevos, aunque tomemos uno singularmente pequeño no hay que temer que esta docena salga con un peso muy por debajo del valor medio, ya que seguramente también habrá otros con un peso por encima de lo normal de forma que los más grandes compensarán el peso de los más pequeños y viceversa.\n\n\n\n\n\n\nFigura 1: Una docena de huevos (exagerando las diferencias)\n\n\n\nSin embargo, en la variable “peso de un huevo multiplicado por 12”, si el huevo elegido resulta ser pequeño, es como tener una docena de huevos pequeños, y si es grande sería como una docena de huevos grandes, con lo que tendremos pesos totales con más dispersión que en el caso anterior (en este caso no se compensan los grandes con los pequeños).\n\n\n\n\n\n\nFigura 2: Un huevo multiplicado por 12. Si es pequeño es como tener una docena de huevos pequeños. Igual si es grande.\n\n\n\nPor tanto, tiene más dispersión la variable aleatoria “peso de un huevo multiplicado por 12” que la variable “peso de una docena”. Y si la variabilidad es distinta, evidentemente las variables son distintas.",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿Por qué no es lo mismo sumar $k$ veces una variable aleatoria que multiplicarla por $k$?"
    ]
  },
  {
    "objectID": "0304_formula_Normal.html#footnotes",
    "href": "0304_formula_Normal.html#footnotes",
    "title": "¿De dónde sale la fórmula de la distribución Normal?",
    "section": "",
    "text": "Si está interesado en un enfoque más formal, aunque también en tono de divulgación, le gustará el artículo: “The Evolution of the Normal Distribution” de Sal Stahl, en Mathematics Magazine Vol. 79, núm. 2, abril de 2006.}.↩︎",
    "crumbs": [
      "Distribuciones de probabilidad",
      "¿De dónde sale la fórmula de la distribución Normal?"
    ]
  }
]